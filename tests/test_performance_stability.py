"""
ì„±ëŠ¥ ë° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
ëŒ€ìš©ëŸ‰ ë°ì´í„°, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ì²˜ë¦¬ ì†ë„, ì•ˆì •ì„±ì„ í…ŒìŠ¤íŠ¸
"""
import pytest
import pandas as pd
import time
import psutil
import threading
import concurrent.futures
import tempfile
import os
import gc
from unittest.mock import Mock, patch
from memory_profiler import profile


class TestPerformance:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def test_large_dataset_processing(self):
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("âš¡ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„± (10,000 ì‘ë‹µ)
        large_data_sizes = [1000, 5000, 10000]

        for size in large_data_sizes:
            start_time = time.time()

            # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„±
            large_data = pd.DataFrame({
                'Q1': [4, 3, 5, 4, 3] * (size // 5),
                'Q2': [3, 4, 4, 5, 3] * (size // 5),
                'Q3': [5, 4, 3, 4, 5] * (size // 5),
                'NO40': ['í˜ì‹ ì ', 'í˜‘ë ¥ì ', 'ì•ˆì •ì ', 'ë„ì „ì ', 'ì„±ì¥ì§€í–¥'] * (size // 5),
                'NO41': ['íŒ€ì›Œí¬', 'ì†Œí†µ', 'ë¦¬ë”ì‹­', 'ì „ë¬¸ì„±', 'ì°½ì˜ì„±'] * (size // 5),
                'NO42': ['ì†Œí†µê°œì„ ', 'í”„ë¡œì„¸ìŠ¤ì •ë¹„', 'êµìœ¡ê°•í™”', 'ì‹œìŠ¤í…œê°œì„ ', 'ì¸ë ¥ì¶©ì›'] * (size // 5),
                'NO43': ['ì‹œê°„ë¶€ì¡±', 'ìì›ì œì•½', 'ê¶Œí•œì œí•œ', 'ì •ë³´ë¶€ì¡±', 'ì ˆì°¨ë³µì¡'] * (size // 5),
                'TEAM': [f'íŒ€{i%50}' for i in range(size)]  # 50ê°œ íŒ€
            })

            # ë°ì´í„° ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
            processing_start = time.time()

            # íŒ€ë³„ ê·¸ë£¹í•‘
            team_groups = large_data.groupby('TEAM')
            team_count = len(team_groups)

            # ê¸°ë³¸ í†µê³„ ê³„ì‚°
            stats = {
                'q1_mean': large_data['Q1'].mean(),
                'q2_mean': large_data['Q2'].mean(),
                'q3_mean': large_data['Q3'].mean(),
                'total_responses': len(large_data)
            }

            processing_time = time.time() - processing_start
            total_time = time.time() - start_time

            # ì„±ëŠ¥ ê²€ì¦
            assert processing_time < 5.0  # 5ì´ˆ ì´ë‚´ ì²˜ë¦¬
            assert team_count == 50
            assert stats['total_responses'] == size

            print(f"âœ… {size:,}ê°œ ì‘ë‹µ ì²˜ë¦¬ ì™„ë£Œ:")
            print(f"   - ì´ ì²˜ë¦¬ì‹œê°„: {total_time:.2f}ì´ˆ")
            print(f"   - ë°ì´í„° ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
            print(f"   - íŒ€ ìˆ˜: {team_count}ê°œ")

        print("ğŸ‰ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

    def test_memory_usage_monitoring(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸"""
        print("âš¡ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        # ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
        memory_data = []

        for i in range(10):
            # ëŒ€ìš©ëŸ‰ DataFrame ìƒì„±
            large_df = pd.DataFrame({
                'data': range(100000),
                'text': [f'sample_text_{j}' for j in range(100000)]
            })

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
            current_memory = process.memory_info().rss / 1024 / 1024
            memory_data.append(current_memory)

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del large_df
            gc.collect()

        # ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        final_memory = process.memory_info().rss / 1024 / 1024

        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²€ì¦ (ì¦ê°€ëŸ‰ì´ 50MB ì´í•˜ì—¬ì•¼ í•¨)
        memory_increase = final_memory - initial_memory
        assert memory_increase < 50

        print(f"âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
        print(f"   - ì´ˆê¸° ë©”ëª¨ë¦¬: {initial_memory:.2f}MB")
        print(f"   - ìµœì¢… ë©”ëª¨ë¦¬: {final_memory:.2f}MB")
        print(f"   - ë©”ëª¨ë¦¬ ì¦ê°€: {memory_increase:.2f}MB")
        print(f"   - ìµœëŒ€ ë©”ëª¨ë¦¬: {max(memory_data):.2f}MB")

    @patch('streamlit_app.generate_ai_interpretation')
    def test_ai_processing_performance(self, mock_ai_generation):
        """AI ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("âš¡ AI ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        import sys
        sys.path.append('/Users/crystal/flask-report')
        from streamlit_app import generate_ai_interpretation

        # Mock AI ì‘ë‹µ (ë¹ ë¥¸ ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜)
        mock_ai_generation.return_value = "AI ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."

        # ë‹¤ì–‘í•œ í¬ê¸°ì˜ ì…ë ¥ ë°ì´í„°ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        input_sizes = [
            (100, 'small'),
            (500, 'medium'),
            (1000, 'large')
        ]

        performance_results = []

        for size, label in input_sizes:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
            test_data = {
                'no40_text': ' '.join(['í˜ì‹ ì ì¸ ì¡°ì§'] * size),
                'no41_text': ' '.join(['ë›°ì–´ë‚œ íŒ€ì›Œí¬'] * size),
                'no42_text': ' '.join(['ì†Œí†µ ê°œì„  í•„ìš”'] * size),
                'no43_text': ' '.join(['ì‹œê°„ ë¶€ì¡±'] * size),
                'respondents': size * 10,
                'org_units': f'{size}ê°œ íŒ€'
            }

            # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            result = generate_ai_interpretation(test_data)
            processing_time = time.time() - start_time

            performance_results.append({
                'size': size,
                'label': label,
                'time': processing_time,
                'success': result is not None
            })

            # ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦ (Mockì´ë¯€ë¡œ ë§¤ìš° ë¹ ë¥´ê²Œ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨)
            assert processing_time < 1.0
            assert result is not None

            print(f"âœ… {label} ë°ì´í„° ({size}) ì²˜ë¦¬: {processing_time:.3f}ì´ˆ")

        print("ğŸ‰ AI ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

    def test_concurrent_processing(self):
        """ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("âš¡ ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        def process_team_data(team_id):
            """íŒ€ ë°ì´í„° ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜"""
            # íŒ€ë³„ ë°ì´í„° ìƒì„±
            team_data = pd.DataFrame({
                'Q1': [4, 3, 5] * 100,
                'Q2': [3, 4, 4] * 100,
                'TEAM': [f'íŒ€{team_id}'] * 300
            })

            # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            stats = {
                'team_id': team_id,
                'count': len(team_data),
                'q1_mean': team_data['Q1'].mean(),
                'q2_mean': team_data['Q2'].mean()
            }

            time.sleep(0.1)  # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
            return stats

        # ìˆœì°¨ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        sequential_results = []
        for i in range(10):
            result = process_team_data(i)
            sequential_results.append(result)
        sequential_time = time.time() - start_time

        # ë³‘ë ¬ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            parallel_results = list(executor.map(process_team_data, range(10)))
        parallel_time = time.time() - start_time

        # ì„±ëŠ¥ ê°œì„  ê²€ì¦
        improvement = sequential_time / parallel_time
        assert improvement > 1.5  # ìµœì†Œ 50% ì„±ëŠ¥ í–¥ìƒ

        print(f"âœ… ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
        print(f"   - ìˆœì°¨ ì²˜ë¦¬: {sequential_time:.2f}ì´ˆ")
        print(f"   - ë³‘ë ¬ ì²˜ë¦¬: {parallel_time:.2f}ì´ˆ")
        print(f"   - ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}ë°°")

    def test_file_processing_performance(self):
        """íŒŒì¼ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("âš¡ íŒŒì¼ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        # ë‹¤ì–‘í•œ í¬ê¸°ì˜ íŒŒì¼ ìƒì„± ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        file_sizes = [1000, 5000, 10000]

        for size in file_sizes:
            # ì„ì‹œ Excel íŒŒì¼ ìƒì„±
            data = pd.DataFrame({
                'Q1': range(size),
                'Q2': range(size, size * 2),
                'TEAM': [f'íŒ€{i%10}' for i in range(size)]
            })

            with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as tmp:
                data.to_excel(tmp.name, index=False)
                temp_file = tmp.name

            try:
                # íŒŒì¼ ì½ê¸° ì„±ëŠ¥ ì¸¡ì •
                start_time = time.time()
                df = pd.read_excel(temp_file)
                read_time = time.time() - start_time

                # ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ì¸¡ì •
                start_time = time.time()
                grouped = df.groupby('TEAM')
                team_count = len(grouped)
                process_time = time.time() - start_time

                # ì„±ëŠ¥ ê²€ì¦
                assert read_time < 5.0  # íŒŒì¼ ì½ê¸° 5ì´ˆ ì´ë‚´
                assert process_time < 2.0  # ë°ì´í„° ì²˜ë¦¬ 2ì´ˆ ì´ë‚´
                assert len(df) == size

                print(f"âœ… {size:,}í–‰ íŒŒì¼ ì²˜ë¦¬:")
                print(f"   - ì½ê¸° ì‹œê°„: {read_time:.2f}ì´ˆ")
                print(f"   - ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ")
                print(f"   - íŒ€ ìˆ˜: {team_count}ê°œ")

            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                os.unlink(temp_file)

        print("ğŸ‰ íŒŒì¼ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


class TestStability:
    """ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def test_long_running_stability(self):
        """ì¥ì‹œê°„ ì‹¤í–‰ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸"""
        print("âš¡ ì¥ì‹œê°„ ì‹¤í–‰ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")

        start_time = time.time()
        iteration_count = 100
        error_count = 0

        for i in range(iteration_count):
            try:
                # ë°˜ë³µì ì¸ ë°ì´í„° ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
                data = pd.DataFrame({
                    'Q1': [4, 3, 5] * 100,
                    'Q2': [3, 4, 4] * 100,
                    'TEAM': ['AíŒ€', 'BíŒ€', 'CíŒ€'] * 100
                })

                # ê·¸ë£¹í•‘ ë° í†µê³„ ê³„ì‚°
                grouped = data.groupby('TEAM')
                stats = grouped.agg({
                    'Q1': ['mean', 'std'],
                    'Q2': ['mean', 'std']
                })

                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del data, grouped, stats
                gc.collect()

                if i % 20 == 0:
                    print(f"   - {i+1}/{iteration_count} ì™„ë£Œ")

            except Exception as e:
                error_count += 1
                print(f"   âš ï¸ ì˜¤ë¥˜ ë°œìƒ ({i+1}ë²ˆì§¸): {e}")

        total_time = time.time() - start_time
        success_rate = ((iteration_count - error_count) / iteration_count) * 100

        # ì•ˆì •ì„± ê²€ì¦
        assert success_rate >= 95.0  # 95% ì´ìƒ ì„±ê³µë¥ 
        assert error_count <= 5  # ìµœëŒ€ 5ê°œ ì˜¤ë¥˜

        print(f"âœ… ì¥ì‹œê°„ ì‹¤í–‰ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
        print(f"   - ì´ ì‹¤í–‰ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"   - ì„±ê³µë¥ : {success_rate:.1f}%")
        print(f"   - ì˜¤ë¥˜ ìˆ˜: {error_count}ê°œ")

    def test_memory_leak_detection(self):
        """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        print("âš¡ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024

        memory_readings = []

        # ë°˜ë³µì ì¸ ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì‘ì—…
        for i in range(50):
            # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„±
            large_data = pd.DataFrame({
                'col1': range(10000),
                'col2': [f'text_{j}' for j in range(10000)],
                'col3': [j * 1.5 for j in range(10000)]
            })

            # ë³µì¡í•œ ì—°ì‚°
            result = large_data.groupby(large_data['col1'] % 10).agg({
                'col1': 'sum',
                'col3': 'mean'
            })

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡
            current_memory = process.memory_info().rss / 1024 / 1024
            memory_readings.append(current_memory)

            # ì •ë¦¬
            del large_data, result
            gc.collect()

        final_memory = process.memory_info().rss / 1024 / 1024

        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë¶„ì„
        memory_increase = final_memory - initial_memory
        max_memory = max(memory_readings)
        avg_memory = sum(memory_readings) / len(memory_readings)

        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²€ì¦ (ì¦ê°€ëŸ‰ì´ 100MB ì´í•˜ì—¬ì•¼ í•¨)
        assert memory_increase < 100

        print(f"âœ… ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
        print(f"   - ì´ˆê¸° ë©”ëª¨ë¦¬: {initial_memory:.2f}MB")
        print(f"   - ìµœì¢… ë©”ëª¨ë¦¬: {final_memory:.2f}MB")
        print(f"   - ë©”ëª¨ë¦¬ ì¦ê°€: {memory_increase:.2f}MB")
        print(f"   - ìµœëŒ€ ë©”ëª¨ë¦¬: {max_memory:.2f}MB")
        print(f"   - í‰ê·  ë©”ëª¨ë¦¬: {avg_memory:.2f}MB")

    def test_resource_cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í…ŒìŠ¤íŠ¸"""
        print("âš¡ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        # íŒŒì¼ í•¸ë“¤ ê´€ë¦¬ í…ŒìŠ¤íŠ¸
        temp_files = []

        try:
            # ì—¬ëŸ¬ ì„ì‹œ íŒŒì¼ ìƒì„±
            for i in range(10):
                df = pd.DataFrame({'data': range(1000)})
                temp_file = tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False)
                df.to_excel(temp_file.name, index=False)
                temp_files.append(temp_file.name)
                temp_file.close()

            # íŒŒì¼ ì½ê¸° ë° ì²˜ë¦¬
            for temp_file in temp_files:
                with open(temp_file, 'rb') as f:
                    data = f.read()
                    assert len(data) > 0

            print("âœ… íŒŒì¼ í•¸ë“¤ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼")

        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            for temp_file in temp_files:
                if os.path.exists(temp_file):
                    os.unlink(temp_file)

        print("âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

    def test_error_recovery(self):
        """ì˜¤ë¥˜ ë³µêµ¬ í…ŒìŠ¤íŠ¸"""
        print("âš¡ ì˜¤ë¥˜ ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        success_count = 0
        recovery_count = 0

        # ì˜ë„ì  ì˜¤ë¥˜ ë°œìƒ ë° ë³µêµ¬ í…ŒìŠ¤íŠ¸
        for i in range(20):
            try:
                if i % 5 == 0:
                    # ì˜ë„ì  ì˜¤ë¥˜ ë°œìƒ
                    raise ValueError(f"ì˜ë„ì  ì˜¤ë¥˜ {i}")

                # ì •ìƒ ì²˜ë¦¬
                data = pd.DataFrame({'test': [1, 2, 3]})
                result = data.sum()
                success_count += 1

            except ValueError:
                # ì˜¤ë¥˜ ë³µêµ¬ ì‹œë®¬ë ˆì´ì…˜
                try:
                    # ëŒ€ì²´ ì²˜ë¦¬
                    backup_data = pd.DataFrame({'test': [0, 0, 0]})
                    backup_result = backup_data.sum()
                    recovery_count += 1
                except:
                    pass

        recovery_rate = (recovery_count / 4) * 100  # 4ë²ˆì˜ ì˜ë„ì  ì˜¤ë¥˜
        success_rate = (success_count / 16) * 100   # 16ë²ˆì˜ ì •ìƒ ì‹œë„

        # ë³µêµ¬ ëŠ¥ë ¥ ê²€ì¦
        assert recovery_rate >= 75.0  # 75% ì´ìƒ ë³µêµ¬ìœ¨
        assert success_rate >= 90.0   # 90% ì´ìƒ ì„±ê³µë¥ 

        print(f"âœ… ì˜¤ë¥˜ ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
        print(f"   - ì„±ê³µë¥ : {success_rate:.1f}%")
        print(f"   - ë³µêµ¬ìœ¨: {recovery_rate:.1f}%")


class TestScalability:
    """í™•ì¥ì„± í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def test_team_scaling(self):
        """íŒ€ ìˆ˜ í™•ì¥ì„± í…ŒìŠ¤íŠ¸"""
        print("âš¡ íŒ€ ìˆ˜ í™•ì¥ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")

        team_counts = [10, 50, 100, 200]

        for team_count in team_counts:
            start_time = time.time()

            # ë‹¤ìˆ˜ íŒ€ ë°ì´í„° ìƒì„±
            data = pd.DataFrame({
                'Q1': [4, 3, 5] * (team_count * 10),
                'Q2': [3, 4, 4] * (team_count * 10),
                'TEAM': [f'íŒ€{i}' for i in range(team_count)] * 30
            })

            # íŒ€ë³„ ì²˜ë¦¬
            teams = data.groupby('TEAM')
            team_stats = {}

            for team_name, team_data in teams:
                team_stats[team_name] = {
                    'count': len(team_data),
                    'q1_mean': team_data['Q1'].mean(),
                    'q2_mean': team_data['Q2'].mean()
                }

            processing_time = time.time() - start_time

            # í™•ì¥ì„± ê²€ì¦
            assert len(team_stats) == team_count
            assert processing_time < 10.0  # 10ì´ˆ ì´ë‚´ ì²˜ë¦¬

            print(f"âœ… {team_count}ê°œ íŒ€ ì²˜ë¦¬: {processing_time:.2f}ì´ˆ")

        print("ğŸ‰ íŒ€ ìˆ˜ í™•ì¥ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

    def test_data_volume_scaling(self):
        """ë°ì´í„° ë³¼ë¥¨ í™•ì¥ì„± í…ŒìŠ¤íŠ¸"""
        print("âš¡ ë°ì´í„° ë³¼ë¥¨ í™•ì¥ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")

        volumes = [1000, 10000, 50000, 100000]

        for volume in volumes:
            start_time = time.time()

            # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„±
            data = pd.DataFrame({
                'Q1': [4, 3, 5, 4, 3] * (volume // 5),
                'Q2': [3, 4, 4, 5, 3] * (volume // 5),
                'TEAM': [f'íŒ€{i%20}' for i in range(volume)]
            })

            # ë°ì´í„° ì²˜ë¦¬
            summary = {
                'total_count': len(data),
                'q1_mean': data['Q1'].mean(),
                'q2_mean': data['Q2'].mean(),
                'team_count': data['TEAM'].nunique()
            }

            processing_time = time.time() - start_time

            # ì„ í˜•ì  í™•ì¥ì„± ê²€ì¦ (ì‹œê°„ì´ ë°ì´í„°ëŸ‰ì— ë¹„ë¡€í•´ì„œ ì¦ê°€)
            time_per_1k = (processing_time / volume) * 1000

            assert summary['total_count'] == volume
            assert time_per_1k < 0.1  # 1000ê°œë‹¹ 0.1ì´ˆ ì´ë‚´

            print(f"âœ… {volume:,}ê°œ ë°ì´í„° ì²˜ë¦¬:")
            print(f"   - ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
            print(f"   - 1Kë‹¹ ì‹œê°„: {time_per_1k:.3f}ì´ˆ")

        print("ğŸ‰ ë°ì´í„° ë³¼ë¥¨ í™•ì¥ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


def run_performance_tests():
    """ì„±ëŠ¥ ë° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("âš¡ ì„±ëŠ¥ ë° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)

    # pytest ì‹¤í–‰
    pytest.main([
        __file__,
        "-v",
        "--tb=short",
        "--no-header",
        "--disable-warnings"
    ])


if __name__ == "__main__":
    run_performance_tests()