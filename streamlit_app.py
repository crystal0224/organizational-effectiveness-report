# /Users/crystal/flask-report/streamlit_app.py

import os
import json
import base64
import io
import smtplib
import zipfile
import tempfile
from datetime import datetime
from email.mime.base import MIMEBase
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email import encoders
from pathlib import Path

import pandas as pd
import streamlit as st
from jinja2 import Environment, FileSystemLoader, select_autoescape, BaseLoader
from dotenv import load_dotenv


# ================================
# 0) ë³´ì¡° ìœ í‹¸
# ================================
def _guess_industry_from_name(name: str) -> str:
    """ì¡°ì§ëª…/íšŒì‚¬ëª…ìœ¼ë¡œ ëŒ€ëµì ì¸ ì‚°ì—…/ì§ë¬´ ì˜ì—­ì„ ì¶”ì •í•œë‹¤."""
    if not name:
        return "ì¼ë°˜ ì‚¬ë¬´/ë‚´ë¶€ ì¡°ì§"
    lower = name.lower()
    # ê±´ì„¤/ì¸í”„ë¼/í˜„ì¥
    if ("ê±´ì„¤" in name) or ("í† ëª©" in name) or ("í˜„ì¥" in name) or ("í”ŒëœíŠ¸" in name) or ("Onsite" in name) or ("onsite" in lower):
        return "ê±´ì„¤Â·ì¸í”„ë¼Â·í˜„ì¥ ê¸°ë°˜ ì¡°ì§"
    # ì„¤ê³„/ì—”ì§€ë‹ˆì–´ë§
    if ("êµ¬ì¡°" in name) or ("ì„¤ê³„" in name) or ("ì—”ì§€ë‹ˆì–´" in name) or ("engineering" in lower):
        return "ì„¤ê³„Â·ê¸°ìˆ Â·ì—”ì§€ë‹ˆì–´ë§ ì¡°ì§"
    # HRD/êµìœ¡
    if ("HR" in name) or ("ì¸ì¬" in name) or ("êµìœ¡" in name) or ("ëŸ¬ë‹" in name) or ("mylearn" in lower) or ("mysuni" in lower):
        return "HRDÂ·ëŸ¬ë‹Â·ì‚¬ë‚´êµìœ¡ ì¡°ì§"
    # ì œì¡°/í”ŒëœíŠ¸ ê³„ì—´
    if ("plant" in lower) or ("fab" in lower) or ("ì œì¡°" in name):
        return "ì œì¡°Â·í”ŒëœíŠ¸ ê¸°ë°˜ ì¡°ì§"
    return "ì¼ë°˜ ì‚¬ë¬´/ë‚´ë¶€ ì¡°ì§"


def _extract_no40_from_open(open_ended) -> str:
    """report['open_ended'] êµ¬ì¡°ì—ì„œ NO40(ì¡°ì§íŠ¹ì„±) ì‘ë‹µë§Œ ë½‘ì•„ì„œ í…ìŠ¤íŠ¸ë¡œ ë§Œë“ ë‹¤."""
    if not open_ended:
        return "NO40 ê´€ë ¨ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."

    # ìƒˆë¡œìš´ êµ¬ì¡° ì²˜ë¦¬: dict with basic_responses
    responses_list = []
    if isinstance(open_ended, dict):
        responses_list = open_ended.get("basic_responses", [])
    elif isinstance(open_ended, list):
        responses_list = open_ended

    collected = []
    for block in responses_list:
        # ìƒˆë¡œìš´ êµ¬ì¡°: header í•„ë“œ í™•ì¸
        header = (block.get("header") or "").strip()
        title = (block.get("title") or "").strip()

        # headerê°€ NO40ì´ê±°ë‚˜ ì œëª©ì´ ì¡°ì§íŠ¹ì„± ê´€ë ¨ì´ë©´ ìˆ˜ì§‘
        if header.upper() == "NO40" or title.upper() == "NO40" or "ì¡°ì§íŠ¹ì„±" in title or "ì¡°ì§ íŠ¹ì„±" in title or "ì¡°ì§ ì´ë¯¸ì§€" in title:
            answers = block.get("answers") or []
            for a in answers:
                if a and a.strip():
                    collected.append(a.strip())
    if not collected:
        return "NO40 ê´€ë ¨ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."
    return "\n".join(f"- {a}" for a in collected)


def preprocess_answer_list(raw_answers: list, global_used_sentences: set = None) -> list:
    """
    ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ì—¬ ë” ê¹”ë”í•˜ê²Œ ì •ë¦¬í•œë‹¤.
    - ì¤‘ë³µ ì œê±°
    - ì§§ì€ ì‘ë‹µ í•„í„°ë§
    - ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹
    - ì „ì—­ì ìœ¼ë¡œ ì‚¬ìš©ëœ ë¬¸ì¥ ì œì™¸
    """
    if not raw_answers:
        return []

    if global_used_sentences is None:
        global_used_sentences = set()

    # 1. ì‘ë‹µ ì •ë¦¬ ë° ì¤‘ë³µ ì œê±°
    cleaned_answers = []
    seen_answers = set()

    for answer in raw_answers:
        if not answer or not isinstance(answer, str):
            continue

        # ê¸°ë³¸ ì •ë¦¬
        cleaned = answer.strip()
        if len(cleaned) < 10:  # ë„ˆë¬´ ì§§ì€ ì‘ë‹µ ì œì™¸
            continue

        # ì¤‘ë³µ ì œê±° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ, ê³µë°± ì •ê·œí™”)
        normalized = ' '.join(cleaned.lower().split())
        if normalized in seen_answers or normalized in global_used_sentences:
            continue
        seen_answers.add(normalized)

        # ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹
        cleaned = mask_sensitive_content(cleaned)
        cleaned_answers.append(cleaned)

    # ì‘ë‹µ ìˆ˜ê°€ ë§ìœ¼ë©´ ìƒìœ„ 20ê°œë§Œ ì„ íƒ (ê¸¸ì´ ìˆœ)
    if len(cleaned_answers) > 20:
        cleaned_answers = sorted(cleaned_answers, key=len, reverse=True)[:20]

    # ì„ íƒëœ ë¬¸ì¥ë“¤ì„ ì „ì—­ ì‚¬ìš© ëª©ë¡ì— ì¶”ê°€
    for answer in cleaned_answers[:3]:  # ìƒìœ„ 3ê°œë§Œ ëŒ€í‘œ ë¬¸ì¥ìœ¼ë¡œ ê°„ì£¼
        normalized = ' '.join(answer.lower().split())
        global_used_sentences.add(normalized)

    return cleaned_answers


def build_structured_open_ended(df: pd.DataFrame, is_company_level: bool = False) -> dict:
    """
    reference/organizational-effectiveness/index.xlsxë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    ì£¼ê´€ì‹ ì‘ë‹µì„ êµ¬ì¡°í™”í•˜ì—¬ ë°˜í™˜í•œë‹¤.
    """
    try:
        # ë ˆí¼ëŸ°ìŠ¤ ì¸ë±ìŠ¤ ë¡œë“œ
        ref_df = pd.read_excel("reference/organizational-effectiveness/index.xlsx")

        # ì£¼ê´€ì‹ í•­ëª©ë“¤ë§Œ í•„í„°ë§ (ëŒ€ë¶„ë¥˜ê°€ 'ì£¼ê´€ì‹'ì¸ ê²ƒë“¤)
        subjective_items = ref_df[ref_df['ëŒ€ë¶„ë¥˜'] == 'ì£¼ê´€ì‹'].copy()

        # ì£¼ê´€ì‹ ë°ì´í„° êµ¬ì¡°í™”
        structured_data = []
        global_used_sentences = set()  # ì „ì—­ì ìœ¼ë¡œ ì‚¬ìš©ëœ ë¬¸ì¥ ì¶”ì 

        for _, item in subjective_items.iterrows():
            header_name = item['í—¤ë”ëª…']
            question_name = item['ë¬¸í•­ëª…']
            minor_category = item['ì†Œë¶„ë¥˜']

            # í•´ë‹¹ ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if header_name in df.columns:
                raw_answers = df[header_name].dropna().astype(str).tolist()
                if raw_answers:
                    # ì „ì²˜ë¦¬ëœ ì‘ë‹µë“¤ë¡œ êµì²´ (ì „ì—­ ì¤‘ë³µ ë°©ì§€ ì ìš©)
                    processed_answers = preprocess_answer_list(raw_answers, global_used_sentences)

                    structured_data.append({
                        "header": header_name,
                        "title": question_name,
                        "category": minor_category,
                        "answers": processed_answers
                    })

        result = {
            "basic_responses": structured_data,
            "advanced_analysis": None,
            "comprehensive_analysis": None
        }

        # AI ì¢…í•© í•´ì„ì€ í•­ìƒ ìƒì„±
        if structured_data:
            try:
                org_name = df.get('ì¡°ì§ëª…', pd.Series([None])).iloc[0] if 'ì¡°ì§ëª…' in df.columns else None
                result["comprehensive_analysis"] = generate_subjective_comprehensive_analysis(result, org_name)
            except Exception as e:
                print(f"AI ì¢…í•© í•´ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                result["comprehensive_analysis"] = None

        # íšŒì‚¬ë‹¨ìœ„ì¼ ë•Œë§Œ ê³ ê¸‰ ë¶„ì„ ì¶”ê°€
        if is_company_level and structured_data:
            result["advanced_analysis"] = generate_advanced_subjective_analysis(structured_data, df)

        return result

    except Exception as e:
        st.error(f"ì£¼ê´€ì‹ ì‘ë‹µ êµ¬ì¡°í™” ì¤‘ ì˜¤ë¥˜: {e}")
        # fallback: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
        open_ended = []
        global_used_sentences = set()  # fallbackì—ì„œë„ ì¤‘ë³µ ë°©ì§€ ì ìš©
        for col in ["NO40", "NO41", "NO42", "NO43"]:
            if col in df.columns:
                raw_answers = df[col].dropna().astype(str).tolist()
                if raw_answers:
                    processed_answers = preprocess_answer_list(raw_answers, global_used_sentences)
                    open_ended.append({"title": col, "answers": processed_answers})
        result = {"basic_responses": open_ended, "advanced_analysis": None, "comprehensive_analysis": None}
        # AI ì¢…í•© í•´ì„ ìƒì„± (fallbackì—ì„œë„)
        if open_ended:
            try:
                org_name = df.get('ì¡°ì§ëª…', pd.Series([None])).iloc[0] if 'ì¡°ì§ëª…' in df.columns else None
                result["comprehensive_analysis"] = generate_subjective_comprehensive_analysis(result, org_name)
            except Exception as e:
                print(f"AI ì¢…í•© í•´ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ (fallback): {e}")
                result["comprehensive_analysis"] = None
        return result


def _generate_fallback_analysis(total_responses: int, org_name: str = None) -> str:
    """Gemini API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ëŒ€ì²´ ë¶„ì„ ìƒì„±"""
    org_display = org_name if org_name else "í•´ë‹¹ ì¡°ì§"

    analysis_parts = [
        f"## {org_display} ì¡°ì§ íŠ¹ì„± ì¢…í•©ë¶„ì„\n",
        f"**ì‘ë‹µ í˜„í™©**: ì´ {total_responses}ê°œì˜ ì£¼ê´€ì‹ ì‘ë‹µì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "**ì£¼ìš” íŠ¹ì§•**:",
        "- ì¡°ì§ì›ë“¤ì˜ ë‹¤ì–‘í•œ ì˜ê²¬ê³¼ ê´€ì ì´ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "- ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­ê³¼ ê°•ì  ì˜ì—­ì´ í˜¼ì¬ë˜ì–´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.",
        "- ì¡°ì§ì˜ ë°œì „ ë°©í–¥ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì œì•ˆë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "**ë¶„ì„ ê²°ê³¼**:",
        "- ì¡°ì§ íš¨ê³¼ì„± í–¥ìƒì„ ìœ„í•œ ë‹¤ê°ë„ì˜ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.",
        "- êµ¬ì„±ì›ë“¤ì˜ ì°¸ì—¬ì™€ ì†Œí†µì„ í†µí•œ ì§€ì†ì ì¸ ê°œì„ ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
        "- ì •ëŸ‰ì  ì§€í‘œì™€ í•¨ê»˜ ì •ì„±ì  í”¼ë“œë°±ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "**í–¥í›„ ê³¼ì œ**:",
        "- ì£¼ê´€ì‹ ì‘ë‹µì—ì„œ ë„ì¶œëœ í•µì‹¬ ì´ìŠˆë“¤ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì ‘ê·¼",
        "- ì¡°ì§ ë¬¸í™” ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½",
        "- êµ¬ì„±ì› ë§Œì¡±ë„ ë° ì°¸ì—¬ë„ ì œê³ ë¥¼ ìœ„í•œ ì§€ì†ì ì¸ ë…¸ë ¥\n",
        "*ë³¸ ë¶„ì„ì€ ìˆ˜ì§‘ëœ ì£¼ê´€ì‹ ì‘ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê¸°ë³¸ì ì¸ í•´ì„ì…ë‹ˆë‹¤.*"
    ]

    return "\n".join(analysis_parts)


def generate_subjective_comprehensive_analysis(open_ended_responses: dict, org_name: str = None) -> str:
    """ì£¼ê´€ì‹ ì‘ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ AI ì¢…í•© í•´ì„ì„ ìƒì„±í•œë‹¤."""
    try:
        # Q40-Q43 ì‘ë‹µ ì¶”ì¶œ
        def extract_responses_by_question(responses_list, target_question):
            answers = []
            for block in responses_list:
                header = (block.get("header") or "").strip().upper()
                title = (block.get("title") or "").strip()

                if header == target_question or target_question in title.upper():
                    answers.extend(block.get("answers", []))
            return [ans for ans in answers if ans and ans.strip()]

        # ê¸°ë³¸ ì‘ë‹µ êµ¬ì¡°ì—ì„œ ë°ì´í„° ì¶”ì¶œ
        responses_list = []
        if isinstance(open_ended_responses, dict):
            responses_list = open_ended_responses.get("basic_responses", [])
        elif isinstance(open_ended_responses, list):
            responses_list = open_ended_responses

        # ê° ë¬¸í•­ë³„ ì‘ë‹µ ì¶”ì¶œ (ë” ìœ ì—°í•œ ë§¤ì¹­)
        no40_responses = extract_responses_by_question(responses_list, "NO40")  # ì¡°ì§ ì´ë¯¸ì§€
        if not no40_responses:
            # ì¡°ì§ íŠ¹ì„±/ì´ë¯¸ì§€ ê´€ë ¨ í•­ëª©ë“¤ë„ í™•ì¸
            for q in ["ì¡°ì§ íŠ¹ì„±", "ì¡°ì§íŠ¹ì„±", "ì¡°ì§ ì´ë¯¸ì§€", "ì¡°ì§ì´ë¯¸ì§€", "íšŒì‚¬ íŠ¹ì„±", "íšŒì‚¬íŠ¹ì„±"]:
                no40_responses.extend(extract_responses_by_question(responses_list, q))

        no41_responses = extract_responses_by_question(responses_list, "NO41")  # ê°•ì 
        if not no41_responses:
            # ê°•ì  ê´€ë ¨ í•­ëª©ë“¤ë„ í™•ì¸
            for q in ["ê°•ì ", "ì¥ì ", "ì¢‹ì€ ì ", "ë§Œì¡±", "ìš°ìˆ˜"]:
                no41_responses.extend(extract_responses_by_question(responses_list, q))

        no42_responses = extract_responses_by_question(responses_list, "NO42")  # ë³´ì™„ í•„ìš”ì 
        if not no42_responses:
            # ê°œì„ ì  ê´€ë ¨ í•­ëª©ë“¤ë„ í™•ì¸
            for q in ["ë³´ì™„", "ê°œì„ ", "ë¶€ì¡±", "ì•„ì‰¬ìš´", "ë¶ˆë§Œ", "ë¬¸ì œ"]:
                no42_responses.extend(extract_responses_by_question(responses_list, q))

        no43_responses = extract_responses_by_question(responses_list, "NO43")  # ì¥ì• ìš”ì¸
        if not no43_responses:
            # ì¥ì• ìš”ì¸ ê´€ë ¨ í•­ëª©ë“¤ë„ í™•ì¸
            for q in ["ì¥ì• ", "ê±¸ë¦¼ëŒ", "ë°©í•´", "ì–´ë ¤ì›€", "ì œì•½"]:
                no43_responses.extend(extract_responses_by_question(responses_list, q))

        # ì‘ë‹µì´ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜
        total_responses = len(no40_responses) + len(no41_responses) + len(no42_responses) + len(no43_responses)
        print(f"DEBUG: ì£¼ê´€ì‹ ì‘ë‹µ ê°œìˆ˜ - NO40: {len(no40_responses)}, NO41: {len(no41_responses)}, NO42: {len(no42_responses)}, NO43: {len(no43_responses)}, ì´: {total_responses}")

        # ì‘ë‹µì´ ë¶€ì¡±í•˜ì§€ë§Œ ì•„ì˜ˆ ì—†ì§€ëŠ” ì•Šì€ ê²½ìš°, ê°„ë‹¨í•œ AI ë¶„ì„ ì‹œë„
        if total_responses < 3:
            print(f"DEBUG: ì‘ë‹µ ë¶€ì¡±ìœ¼ë¡œ AI ë¶„ì„ ìŠ¤í‚µ (ìµœì†Œ 3ê°œ í•„ìš”, í˜„ì¬ {total_responses}ê°œ)")
            return _generate_fallback_analysis(total_responses, org_name)
        elif total_responses < 5:
            print(f"DEBUG: ì‘ë‹µ ë¶€ì¡±í•˜ì§€ë§Œ ê°„ë‹¨ AI ë¶„ì„ ì‹œë„ (ê¶Œì¥ 5ê°œ, í˜„ì¬ {total_responses}ê°œ)")

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
        prompts_dir = BASE_DIR / "prompts"
        prompt_path = prompts_dir / "gemini_text_ko.md"

        if not prompt_path.exists():
            return "AI ì¢…í•© í•´ì„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        prompt_template = prompt_path.read_text(encoding='utf-8')

        # ì‘ë‹µ í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        no40_text = "\n".join([f"- {resp}" for resp in no40_responses[:10]])  # ìµœëŒ€ 10ê°œ
        no41_text = "\n".join([f"- {resp}" for resp in no41_responses[:10]])
        no42_text = "\n".join([f"- {resp}" for resp in no42_responses[:10]])
        no43_text = "\n".join([f"- {resp}" for resp in no43_responses[:10]])

        # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ì¹˜í™˜
        prompt = prompt_template.replace("{{no40_text}}", no40_text or "ì‘ë‹µ ì—†ìŒ")
        prompt = prompt.replace("{{no41_text}}", no41_text or "ì‘ë‹µ ì—†ìŒ")
        prompt = prompt.replace("{{no42_text}}", no42_text or "ì‘ë‹µ ì—†ìŒ")
        prompt = prompt.replace("{{no43_text}}", no43_text or "ì‘ë‹µ ì—†ìŒ")
        prompt = prompt.replace("{{respondents}}", str(total_responses))
        prompt = prompt.replace("{{org_units}}", org_name or "ì—…ë¡œë“œ ë°ì´í„°")

        # Gemini API í˜¸ì¶œ
        if not _HAS_GENAI or not GOOGLE_API_KEY:
            print("DEBUG: Gemini API ì„¤ì • ì—†ìŒ - fallback ì‚¬ìš©")
            return _generate_fallback_analysis(total_responses, org_name)

        try:
            import google.generativeai as genai
            genai.configure(api_key=GOOGLE_API_KEY)
            # ê°€ì¥ ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš© (í’ˆì§ˆì€ ì•½ê°„ ë‚®ì§€ë§Œ ì†ë„ 5ë°° í–¥ìƒ)
            client = genai.GenerativeModel('gemini-1.5-flash-8b')

            # ì†ë„ ìµœì í™” ì„¤ì • (í’ˆì§ˆ ìœ ì§€í•˜ë©´ì„œ ë¹ ë¥´ê²Œ)
            generation_config = genai.types.GenerationConfig(
                temperature=0.3,  # ì ë‹¹íˆ ë‚®ì¶°ì„œ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆ ìœ ì§€
                max_output_tokens=1200,  # ì¶©ë¶„í•œ ì¶œë ¥ ê³µê°„
                top_p=0.7,  # ê· í˜•ì¡íŒ ì„ íƒ
                top_k=40,   # ì ë‹¹í•œ í›„ë³´ ìˆ˜
                candidate_count=1,  # ë‹¨ì¼ í›„ë³´ë¡œ ì†ë„ í–¥ìƒ
                stop_sequences=["\n\n\n", "---", "###"]  # ì¡°ê¸° ì¢…ë£Œ
            )

            # íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ë¹ ë¥¸ ì‘ë‹µ ë³´ì¥ (threading ì‚¬ìš©)
            import concurrent.futures
            import time

            def make_api_call():
                return client.generate_content(
                    prompt,
                    generation_config=generation_config,
                    safety_settings=[
                        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_ONLY_HIGH"},
                        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_ONLY_HIGH"},
                        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_ONLY_HIGH"},
                        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_ONLY_HIGH"}
                    ]
                )

            # 30ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì • (concurrent.futures ì‚¬ìš©)
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(make_api_call)
                try:
                    response = future.result(timeout=30)
                except concurrent.futures.TimeoutError:
                    print("AI ë¶„ì„ ì‹œê°„ ì´ˆê³¼ (30ì´ˆ) - fallback ì‚¬ìš©")
                    return _generate_fallback_analysis(total_responses, org_name)

            # ì‘ë‹µ ìƒíƒœ í™•ì¸
            if response and hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]

                # finish_reason í™•ì¸
                if hasattr(candidate, 'finish_reason'):
                    if candidate.finish_reason == 2:  # SAFETY
                        print("Gemini API: ì•ˆì „ì„± í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë¨")
                        return _generate_fallback_analysis(total_responses, org_name)
                    elif candidate.finish_reason == 3:  # RECITATION
                        print("Gemini API: ë°˜ë³µ ì½˜í…ì¸ ë¡œ ì¸í•´ ì°¨ë‹¨ë¨")
                        return _generate_fallback_analysis(total_responses, org_name)
                    elif candidate.finish_reason == 4:  # OTHER
                        print("Gemini API: ê¸°íƒ€ ì´ìœ ë¡œ ì°¨ë‹¨ë¨")
                        return _generate_fallback_analysis(total_responses, org_name)

                # ì •ìƒì ì¸ ì‘ë‹µì´ ìˆëŠ” ê²½ìš°
                if hasattr(candidate, 'content') and candidate.content and hasattr(candidate.content, 'parts'):
                    for part in candidate.content.parts:
                        if hasattr(part, 'text') and part.text:
                            return part.text.strip()

            # response.textë¡œ ì§ì ‘ ì ‘ê·¼ ì‹œë„ (í•˜ìœ„ í˜¸í™˜ì„±)
            if response and hasattr(response, 'text') and response.text:
                return response.text.strip()

            # ëª¨ë“  ì ‘ê·¼ ë°©ë²•ì´ ì‹¤íŒ¨í•œ ê²½ìš°
            print("Gemini API: ìœ íš¨í•œ ì‘ë‹µì„ ë°›ì§€ ëª»í•¨")
            return _generate_fallback_analysis(total_responses, org_name)

        except TimeoutError as timeout_error:
            print(f"Gemini API íƒ€ì„ì•„ì›ƒ: {timeout_error}")
            return _generate_fallback_analysis(total_responses, org_name)
        except Exception as api_error:
            print(f"Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {api_error}")
            return f"AI ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(api_error)}"

    except Exception as e:
        print(f"ì£¼ê´€ì‹ ì¢…í•© ë¶„ì„ ìƒì„± ì˜¤ë¥˜: {e}")
        return f"AI ì¢…í•© í•´ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


def generate_advanced_subjective_analysis(structured_data: list, df: pd.DataFrame) -> dict:
    """
    íšŒì‚¬ë‹¨ìœ„ ë¦¬í¬íŠ¸ë¥¼ ìœ„í•œ ê³ ê¸‰ ì£¼ê´€ì‹ ë¶„ì„ ìƒì„±
    - ì¸¡ë©´ë³„ ê°ì„±ë¶„ì„
    - ì£¼ì¥ ê·¼ê±° ì œì•ˆ
    - íŒ€ë³„ ì ì¬ìœ í˜• ì§€ë„ë¶„ì„
    """
    print("[DEBUG] generate_advanced_subjective_analysis called")

    # 1. ì¸¡ë©´ë³„ ê°ì„±ë¶„ì„
    aspect_sentiment = analyze_aspect_sentiment(structured_data)
    print(f"[DEBUG] aspect_sentiment completed")

    # 2. ì£¼ì¥ ê·¼ê±° ì œì•ˆ
    evidence_suggestions = generate_evidence_suggestions(structured_data)
    print(f"[DEBUG] evidence_suggestions completed")

    # 3. íŒ€ë³„ ì ì¬ìœ í˜• ì§€ë„ë¶„ì„ (ë¶€ì„œ/íŒ€ ì •ë³´ê°€ ìˆì„ ê²½ìš°)
    team_potential_mapping = analyze_team_potential_types(structured_data, df)
    print(f"[DEBUG] team_potential_mapping completed: {team_potential_mapping}")

    result = {
        "aspect_sentiment": aspect_sentiment,
        "evidence_suggestions": evidence_suggestions,
        "team_potential_mapping": team_potential_mapping
    }
    print(f"[DEBUG] generate_advanced_subjective_analysis result: {result}")
    return result


def analyze_aspect_sentiment(structured_data: list) -> dict:
    """ì¸¡ë©´ë³„ ê°ì„±ë¶„ì„ ìˆ˜í–‰"""
    try:
        aspects = {
            "ì¡°ì§ë¬¸í™”": [],
            "ë¦¬ë”ì‹­": [],
            "ì—…ë¬´í™˜ê²½": [],
            "ì„±ì¥ê¸°íšŒ": [],
            "ì†Œí†µí˜‘ë ¥": []
        }

        # í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì¸¡ë©´ ë¶„ë¥˜
        keywords = {
            "ì¡°ì§ë¬¸í™”": ["ë¬¸í™”", "ë¶„ìœ„ê¸°", "ê°€ì¹˜", "ë¹„ì „", "ë¯¸ì…˜", "ì¡°ì§", "í™˜ê²½"],
            "ë¦¬ë”ì‹­": ["ë¦¬ë”", "ìƒì‚¬", "ê´€ë¦¬", "ì§€ì‹œ", "ì˜ì‚¬ê²°ì •", "ë°©í–¥ì„±"],
            "ì—…ë¬´í™˜ê²½": ["ì—…ë¬´", "ì‹œì„¤", "ì‹œìŠ¤í…œ", "ë„êµ¬", "í™˜ê²½", "ê·¼ë¬´"],
            "ì„±ì¥ê¸°íšŒ": ["ì„±ì¥", "êµìœ¡", "í•™ìŠµ", "ë°œì „", "ìŠ¹ì§„", "ê¸°íšŒ"],
            "ì†Œí†µí˜‘ë ¥": ["ì†Œí†µ", "í˜‘ë ¥", "íŒ€ì›Œí¬", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜", "í˜‘ì—…"]
        }

        if not structured_data or not isinstance(structured_data, list):
            return {}

        for data_block in structured_data:
            if not isinstance(data_block, dict):
                continue

            answers = data_block.get("answers", [])
            if not answers or not isinstance(answers, list):
                continue

            for answer in answers:
                if not answer or not isinstance(answer, str):
                    continue

                answer_lower = answer.lower()

                # ê° ì¸¡ë©´ë³„ë¡œ í‚¤ì›Œë“œ ë§¤ì¹­
                for aspect, aspect_keywords in keywords.items():
                    if any(keyword in answer_lower for keyword in aspect_keywords):
                        # ì •êµí•œ ê°ì„± ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš© + ë¬¸ë§¥ ê³ ë ¤)
                        positive_words = {
                            "ë§¤ìš°ê¸ì •": ["ìµœê³ ", "í›Œë¥­", "ë›°ì–´ë‚˜", "ì™„ë²½", "ìš°ìˆ˜í•œ"],  # ê°€ì¤‘ì¹˜ 3
                            "ê¸ì •": ["ì¢‹", "ë§Œì¡±", "ê¸ì •", "íš¨ê³¼ì ", "ì„±ê³µ", "ë°œì „", "í–¥ìƒ", "ê°œì„ ëœ", "ì˜ë˜", "ì›í™œ"],  # ê°€ì¤‘ì¹˜ 2
                            "ì•½ê°„ê¸ì •": ["ê´œì°®", "ë‚˜ì˜ì§€ì•Š", "ì ë‹¹", "ë³´í†µì´ìƒ"]  # ê°€ì¤‘ì¹˜ 1
                        }
                        negative_words = {
                            "ë§¤ìš°ë¶€ì •": ["ìµœì•…", "ì‹¬ê°", "í°ë¬¸ì œ", "ì¹˜ëª…ì ", "ì ˆë§"],  # ê°€ì¤‘ì¹˜ -3
                            "ë¶€ì •": ["ë¶€ì¡±", "ë¬¸ì œ", "ì–´ë ¤", "í˜ë“¤", "ë¶€ì •", "ì‹¤íŒ¨", "ê°œì„ í•„ìš”", "ì•„ì‰¬", "ë¶ˆë§Œ", "ë¶ˆí¸"],  # ê°€ì¤‘ì¹˜ -2
                            "ì•½ê°„ë¶€ì •": ["ì¡°ê¸ˆ", "ì•½ê°„ë¶€ì¡±", "ë¯¸í¡"]  # ê°€ì¤‘ì¹˜ -1
                        }

                        # ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ì ìˆ˜ ê³„ì‚°
                        sentiment_score = 0
                        for category, words in positive_words.items():
                            weight = 3 if "ë§¤ìš°" in category else (2 if category == "ê¸ì •" else 1)
                            count = sum(1 for word in words if word in answer_lower)
                            sentiment_score += count * weight

                        for category, words in negative_words.items():
                            weight = -3 if "ë§¤ìš°" in category else (-2 if category == "ë¶€ì •" else -1)
                            count = sum(1 for word in words if word in answer_lower)
                            sentiment_score += count * weight

                        # ë¬¸ë§¥ ë³´ì • (ë¶€ì •ì–´ + ê¸ì •ì–´ ì¡°í•© ì²˜ë¦¬)
                        if any(neg in answer_lower for neg in ["ì•Š", "ì—†", "ëª»"]):
                            # "ì¢‹ì§€ ì•Šë‹¤", "ë§Œì¡±í•˜ì§€ ëª»í•œë‹¤" ë“±ì˜ ë¶€ì • í‘œí˜„ ê°ì§€
                            if any(pos in answer_lower for pos in ["ì¢‹", "ë§Œì¡±", "ê´œì°®"]):
                                sentiment_score -= 1

                        # ê°ì„± ë²”ì£¼ ê²°ì • (ë” ì„¸ë¶„í™”ëœ ê¸°ì¤€)
                        if sentiment_score >= 2:
                            sentiment = "ê¸ì •"
                        elif sentiment_score <= -2:
                            sentiment = "ë¶€ì •"
                        else:
                            sentiment = "ì¤‘ë¦½"

                        aspects[aspect].append({
                            "text": answer,
                            "sentiment": sentiment,
                            "score": sentiment_score
                        })

        # ì¸¡ë©´ë³„ ê°ì„± ìš”ì•½
        aspect_summary = {}
        for aspect, responses in aspects.items():
            if responses:
                try:
                    avg_score = sum(r.get("score", 0) for r in responses) / len(responses)
                    pos_count = len([r for r in responses if r.get("sentiment") == "ê¸ì •"])
                    neg_count = len([r for r in responses if r.get("sentiment") == "ë¶€ì •"])

                    aspect_summary[aspect] = {
                        "total_responses": len(responses),
                        "average_sentiment": round(avg_score, 2),
                        "positive_count": pos_count,
                        "negative_count": neg_count,
                        "overall_sentiment": "ê¸ì •" if avg_score > 0 else ("ë¶€ì •" if avg_score < 0 else "ì¤‘ë¦½"),
                        "responses": responses[:3]  # ìƒìœ„ 3ê°œë§Œ í¬í•¨
                    }
                except (ZeroDivisionError, TypeError) as e:
                    continue

        return aspect_summary

    except Exception as e:
        print(f"Error in analyze_aspect_sentiment: {e}")
        return {}


def generate_evidence_suggestions(structured_data: list) -> list:
    """ì£¼ì¥ì— ëŒ€í•œ ê·¼ê±° ì œì•ˆ ìƒì„±"""
    try:
        suggestions = []

        if not structured_data or not isinstance(structured_data, list):
            return []

        # ê°•ì  ë¶„ì„ (ê¸ì •ê¸°ìˆ  ì¹´í…Œê³ ë¦¬)
        strengths = []
        improvements = []

        for data_block in structured_data:
            if not isinstance(data_block, dict):
                continue

            category = data_block.get("category", "")
            answers = data_block.get("answers", [])

            if not answers or not isinstance(answers, list):
                continue

            # ë¬¸ìì—´ íƒ€ì…ë§Œ í•„í„°ë§
            valid_answers = [ans for ans in answers if isinstance(ans, str) and ans.strip()]

            if "ê¸ì •" in category:
                strengths.extend(valid_answers)
            elif "ë¶€ì •" in category:
                improvements.extend(valid_answers)

        # ê°•ì  ê¸°ë°˜ ê·¼ê±° ì œì•ˆ
        if strengths:
            suggestions.append({
                "type": "ê°•ì  í™œìš© ì œì•ˆ",
                "title": "ì¡°ì§ì˜ í•µì‹¬ ê°•ì ì„ ì „ëµì ìœ¼ë¡œ í™œìš©",
                "evidence": strengths[:3],
                "action_items": [
                    "í•µì‹¬ ê°•ì ì„ ì¡°ì§ ë¸Œëœë”©ì— í™œìš©",
                    "ê°•ì  ê¸°ë°˜ ì¸ì¬ ì±„ìš© ì „ëµ ìˆ˜ë¦½",
                    "ê°•ì ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì‚¬ì—… ì˜ì—­ í™•ì¥ ê²€í† "
                ]
            })

        # ê°œì„ ì  ê¸°ë°˜ ê·¼ê±° ì œì•ˆ
        if improvements:
            suggestions.append({
                "type": "ê°œì„  ìš°ì„ ìˆœìœ„ ì œì•ˆ",
                "title": "ì¦‰ì‹œ ê°œì„ ì´ í•„ìš”í•œ í•µì‹¬ ì´ìŠˆ",
                "evidence": improvements[:3],
                "action_items": [
                    "ê°œì„  ì´ìŠˆë³„ ë‹´ë‹¹ ë¶€ì„œ ë° ì±…ì„ì ì§€ì •",
                    "ë‹¨ê¸°(3ê°œì›”)/ì¤‘ê¸°(6ê°œì›”) ê°œì„  ê³„íš ìˆ˜ë¦½",
                    "ê°œì„  ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•"
                ]
            })

        return suggestions

    except Exception as e:
        print(f"Error in generate_evidence_suggestions: {e}")
        return []


def analyze_team_potential_types(structured_data: list, df: pd.DataFrame) -> dict:
    """íŒ€ë³„ ì ì¬ìœ í˜• ì§€ë„ë¶„ì„"""
    try:
        print(f"[DEBUG] analyze_team_potential_types called with df shape: {df.shape if df is not None else 'None'}")

        if df is None or df.empty:
            print("[DEBUG] DataFrame is None or empty")
            return {"message": "ë°ì´í„°ê°€ ì—†ì–´ íŒ€ë³„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        print(f"[DEBUG] DataFrame columns: {df.columns.tolist()}")

        # ë¶€ì„œ/íŒ€ ì»¬ëŸ¼ ì°¾ê¸°
        team_columns = [col for col in df.columns if any(keyword in col.upper() for keyword in ['POS', 'DEPT', 'TEAM', 'ë¶€ì„œ', 'íŒ€'])]
        print(f"[DEBUG] Found team columns: {team_columns}")

        if not team_columns:
            print("[DEBUG] No team columns found")
            return {"message": "íŒ€/ë¶€ì„œ ì •ë³´ê°€ ì—†ì–´ íŒ€ë³„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        team_col = team_columns[0]  # ì²« ë²ˆì§¸ íŒ€ ì»¬ëŸ¼ ì‚¬ìš©

        # íŒ€ë³„ ì£¼ê´€ì‹ ì‘ë‹µ ë¶„ì„
        team_analysis = {}

        unique_teams = df[team_col].dropna().unique()
        print(f"[DEBUG] Using team column: {team_col}")
        print(f"[DEBUG] Found unique teams: {unique_teams}")
        print(f"[DEBUG] Number of unique teams: {len(unique_teams)}")

        if len(unique_teams) == 0:
            print("[DEBUG] No valid team information found")
            return {"message": "ìœ íš¨í•œ íŒ€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}

        for team_name in unique_teams:
            try:
                team_df = df[df[team_col] == team_name]
                if team_df.empty:
                    continue

                team_responses = []

                # íŒ€ë³„ ì£¼ê´€ì‹ ì‘ë‹µ ìˆ˜ì§‘
                for col in ["NO40", "NO41", "NO42", "NO43"]:
                    if col in team_df.columns:
                        responses = team_df[col].dropna().astype(str).tolist()
                        # ìœ íš¨í•œ ì‘ë‹µë§Œ í•„í„°ë§
                        valid_responses = [resp for resp in responses if resp and resp.strip() and resp != 'nan']
                        team_responses.extend(valid_responses)

                if team_responses:
                    # íŒ€ íŠ¹ì„± í‚¤ì›Œë“œ ë¶„ì„ (ë” í¬ê´„ì ì¸ í‚¤ì›Œë“œ í¬í•¨)
                    innovation_keywords = ["í˜ì‹ ", "ì°½ì˜", "ìƒˆë¡œ", "ë„ì „", "ë³€í™”", "íŒ¨ê¸°", "ììœ¨", "ì‹¤í—˜", "ì•„ì´ë””ì–´", "ë°œêµ´"]
                    stability_keywords = ["ì•ˆì •", "ì²´ê³„", "ê·œì¹™", "ì ˆì°¨", "ê´€ë¦¬", "ì „ë¬¸ì„±", "í’ˆì§ˆ", "ì •í™•", "í‘œì¤€", "í”„ë¡œì„¸ìŠ¤"]
                    collaboration_keywords = ["í˜‘ë ¥", "íŒ€ì›Œí¬", "ì†Œí†µ", "í˜‘ì—…", "í•¨ê»˜", "ë™ë£Œ", "ë°°ë ¤", "í¬ìš©", "ìƒí˜¸", "ì¡´ì¤‘"]
                    performance_keywords = ["ì„±ê³¼", "ì‹¤ì ", "ëª©í‘œ", "ë‹¬ì„±", "ê²°ê³¼", "ì¶”ì§„ë ¥", "íš¨ìœ¨", "ìš´ì˜", "ì„±ì¥", "í–¥ìƒ"]

                    scores = {
                        "í˜ì‹ ì„±": sum(1 for resp in team_responses for keyword in innovation_keywords if keyword in resp),
                        "ì•ˆì •ì„±": sum(1 for resp in team_responses for keyword in stability_keywords if keyword in resp),
                        "í˜‘ë ¥ì„±": sum(1 for resp in team_responses for keyword in collaboration_keywords if keyword in resp),
                        "ì„±ê³¼ì§€í–¥": sum(1 for resp in team_responses for keyword in performance_keywords if keyword in resp)
                    }

                    # íŒ€ ìœ í˜• ê²°ì • (ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ íŠ¹ì„±)
                    max_score = max(scores.values()) if scores.values() else 0
                    dominant_trait = max(scores, key=scores.get) if max_score > 0 else "ê· í˜•í˜•"

                    team_analysis[str(team_name)] = {
                        "size": len(team_df),
                        "dominant_trait": dominant_trait,
                        "trait_scores": scores,
                        "potential_type": classify_team_potential_type(scores),
                        "development_suggestions": get_team_development_suggestions(dominant_trait)
                    }
                    print(f"[DEBUG] Added team analysis for {team_name}: {team_analysis[str(team_name)]}")

            except Exception as e:
                print(f"Error analyzing team {team_name}: {e}")
                continue

        print(f"[DEBUG] Final team_analysis result: {team_analysis}")
        return team_analysis if team_analysis else {"message": "ë¶„ì„ ê°€ëŠ¥í•œ íŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

    except Exception as e:
        print(f"Error in analyze_team_potential_types: {e}")
        return {"message": f"íŒ€ë³„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}


def classify_team_potential_type(scores: dict) -> str:
    """íŒ€ ì ì¬ìœ í˜• ë¶„ë¥˜"""
    max_score = max(scores.values())
    if max_score == 0:
        return "ë¯¸ë¶„ë¥˜í˜•"

    dominant_traits = [trait for trait, score in scores.items() if score == max_score]

    if len(dominant_traits) > 1:
        return "ë³µí•©í˜•"

    trait_types = {
        "í˜ì‹ ì„±": "ì°½ì¡°í˜ì‹ í˜•",
        "ì•ˆì •ì„±": "ì²´ê³„ì•ˆì •í˜•",
        "í˜‘ë ¥ì„±": "ì†Œí†µí˜‘ë ¥í˜•",
        "ì„±ê³¼ì§€í–¥": "ëª©í‘œë‹¬ì„±í˜•"
    }

    return trait_types.get(dominant_traits[0], "ê· í˜•í˜•")


def get_team_type_description(team_type: str) -> dict:
    """íŒ€ ìœ í˜•ë³„ ìƒì„¸ ì„¤ëª… ë°˜í™˜"""
    descriptions = {
        "ì°½ì¡°í˜ì‹ í˜•": {
            "title": "ì°½ì¡°í˜ì‹ í˜• (Creative & Innovative)",
            "description": "ìƒˆë¡œìš´ ì•„ì´ë””ì–´ ì°½ì¶œê³¼ í˜ì‹ ì— ê°•ì ì„ ë³´ì´ëŠ” íŒ€ì…ë‹ˆë‹¤.",
            "characteristics": [
                "ì°½ì˜ì  ì‚¬ê³ ì™€ ë„ì „ì •ì‹ ì´ ë›°ì–´ë‚¨",
                "ë³€í™”ì— ìœ ì—°í•˜ê²Œ ì ì‘í•˜ê³  ìƒˆë¡œìš´ ì‹œë„ë¥¼ ë‘ë ¤ì›Œí•˜ì§€ ì•ŠìŒ",
                "ë¬¸ì œ í•´ê²° ì‹œ ê¸°ì¡´ í‹€ì„ ë²—ì–´ë‚œ ì ‘ê·¼ì„ ì„ í˜¸",
                "ì‹¤í—˜ê³¼ ì‹œí–‰ì°©ì˜¤ë¥¼ í†µí•œ í•™ìŠµì„ ì¤‘ì‹œ"
            ],
            "strengths": [
                "í˜ì‹ ì ì¸ ì†”ë£¨ì…˜ ê°œë°œ",
                "ë¯¸ë˜ íŠ¸ë Œë“œ íŒŒì•…ê³¼ ì„ ì œì  ëŒ€ì‘",
                "ì°½ì˜ì  ë¬¸ì œ í•´ê²°"
            ],
            "development_areas": [
                "ì•„ì´ë””ì–´ ì‹¤í–‰ë ¥ ê°•í™”",
                "ì²´ê³„ì  í”„ë¡œì„¸ìŠ¤ ë„ì…",
                "ë¦¬ìŠ¤í¬ ê´€ë¦¬ ëŠ¥ë ¥ í–¥ìƒ"
            ]
        },
        "ì²´ê³„ì•ˆì •í˜•": {
            "title": "ì²´ê³„ì•ˆì •í˜• (Systematic & Stable)",
            "description": "ì²´ê³„ì ì´ê³  ì•ˆì •ì ì¸ ì—…ë¬´ ìˆ˜í–‰ì— ê°•ì ì„ ë³´ì´ëŠ” íŒ€ì…ë‹ˆë‹¤.",
            "characteristics": [
                "ëª…í™•í•œ í”„ë¡œì„¸ìŠ¤ì™€ ê·œì¹™ì„ ì„ í˜¸í•¨",
                "ê¼¼ê¼¼í•˜ê³  ì •í™•í•œ ì—…ë¬´ ì²˜ë¦¬ê°€ íŠ¹ì§•",
                "ì•ˆì •ì„±ê³¼ ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì„ ì¤‘ì‹œ",
                "ë‹¨ê³„ë³„ ê³„íš ìˆ˜ë¦½ê³¼ ì‹¤í–‰ì— ëŠ¥ìˆ™"
            ],
            "strengths": [
                "ë†’ì€ ì—…ë¬´ í’ˆì§ˆê³¼ ì •í™•ì„±",
                "ì•ˆì •ì ì´ê³  ì§€ì†ì ì¸ ì„±ê³¼ ì°½ì¶œ",
                "ë¦¬ìŠ¤í¬ ìµœì†Œí™”"
            ],
            "development_areas": [
                "ë³€í™” ì ì‘ë ¥ í–¥ìƒ",
                "ì°½ì˜ì  ì‚¬ê³  ê°œë°œ",
                "ìœ ì—°ì„± ê°•í™”"
            ]
        },
        "ì†Œí†µí˜‘ë ¥í˜•": {
            "title": "ì†Œí†µí˜‘ë ¥í˜• (Collaborative & Communicative)",
            "description": "íŒ€ì›Œí¬ì™€ í˜‘ë ¥ì„ í†µí•œ ì‹œë„ˆì§€ ì°½ì¶œì— ê°•ì ì„ ë³´ì´ëŠ” íŒ€ì…ë‹ˆë‹¤.",
            "characteristics": [
                "ì›í™œí•œ ì˜ì‚¬ì†Œí†µê³¼ ì •ë³´ ê³µìœ ê°€ í™œë°œí•¨",
                "êµ¬ì„±ì› ê°„ ìƒí˜¸ ì§€ì›ê³¼ í˜‘ë ¥ì´ ë›°ì–´ë‚¨",
                "ê°ˆë“± ìƒí™©ì—ì„œ ì¡°ì •ê³¼ ì¤‘ì¬ ëŠ¥ë ¥ ë³´ìœ ",
                "í¬ìš©ì ì´ê³  í™”í•©ì ì¸ ë¶„ìœ„ê¸° ì¡°ì„±"
            ],
            "strengths": [
                "ë†’ì€ íŒ€ ê²°ì†ë ¥ê³¼ ë§Œì¡±ë„",
                "íš¨ê³¼ì ì¸ ì§€ì‹ ê³µìœ ì™€ í•™ìŠµ",
                "ê°ˆë“± í•´ê²°ê³¼ ê´€ê³„ ê°œì„ "
            ],
            "development_areas": [
                "ëª©í‘œ ì§€í–¥ì  ì„±ê³¼ ì°½ì¶œ",
                "ì˜ì‚¬ê²°ì • ì†ë„ í–¥ìƒ",
                "ê°œì¸ ì—­ëŸ‰ ê°•í™”"
            ]
        },
        "ëª©í‘œë‹¬ì„±í˜•": {
            "title": "ëª©í‘œë‹¬ì„±í˜• (Goal-Oriented & Achievement-Focused)",
            "description": "ëª…í™•í•œ ëª©í‘œ ì„¤ì •ê³¼ ê°•ë ¥í•œ ì‹¤í–‰ë ¥ìœ¼ë¡œ ì„±ê³¼ë¥¼ ë‹¬ì„±í•˜ëŠ” íŒ€ì…ë‹ˆë‹¤.",
            "characteristics": [
                "êµ¬ì²´ì ì´ê³  ë„ì „ì ì¸ ëª©í‘œ ì„¤ì •ì„ ì„ í˜¸í•¨",
                "ê²°ê³¼ ì¤‘ì‹¬ì ì´ê³  ì„±ê³¼ ì§€í–¥ì ì¸ ì‚¬ê³ ",
                "ë¹ ë¥¸ ì˜ì‚¬ê²°ì •ê³¼ ì‹¤í–‰ë ¥ì´ ë›°ì–´ë‚¨",
                "ê²½ìŸ ìƒí™©ì—ì„œ ê°•í•œ ë™ê¸°ë¶€ì—¬ ë°œíœ˜"
            ],
            "strengths": [
                "ë†’ì€ ëª©í‘œ ë‹¬ì„±ë¥ ê³¼ ìƒì‚°ì„±",
                "ì‹ ì†í•œ ëŒ€ì‘ê³¼ ì‹¤í–‰ë ¥",
                "ì„±ê³¼ ì¤‘ì‹¬ì˜ íš¨ìœ¨ì  ìš´ì˜"
            ],
            "development_areas": [
                "ì¥ê¸°ì  ê´€ì  ê°•í™”",
                "íŒ€ì›Œí¬ì™€ í˜‘ë ¥ ê°œì„ ",
                "ì§€ì†ê°€ëŠ¥í•œ ì„±ì¥ ì¶”êµ¬"
            ]
        },
        "ë³µí•©í˜•": {
            "title": "ë³µí•©í˜• (Multi-Dimensional)",
            "description": "ì—¬ëŸ¬ íŠ¹ì„±ì´ ê· í˜•ìˆê²Œ ë°œë‹¬í•œ ë‹¤ë©´ì  ê°•ì ì„ ë³´ì´ëŠ” íŒ€ì…ë‹ˆë‹¤.",
            "characteristics": [
                "ìƒí™©ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ëŒ€ì²˜í•˜ëŠ” ì ì‘ë ¥",
                "ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ë¬¸ì œë¥¼ ë°”ë¼ë³´ëŠ” ì‹œê°",
                "ê· í˜•ì¡íŒ ì—…ë¬´ ì ‘ê·¼ ë°©ì‹",
                "ë³µí•©ì  ì—­ëŸ‰ì˜ ì‹œë„ˆì§€ íš¨ê³¼"
            ],
            "strengths": [
                "ë‹¤ì–‘í•œ ìƒí™©ì— ëŒ€í•œ ë†’ì€ ì ì‘ë ¥",
                "ì¢…í•©ì ì´ê³  ê· í˜•ì¡íŒ ë¬¸ì œ í•´ê²°",
                "ë³€í™”í•˜ëŠ” í™˜ê²½ì—ì„œì˜ ì•ˆì •ì„±"
            ],
            "development_areas": [
                "í•µì‹¬ ê°•ì  ì˜ì—­ ì§‘ì¤‘ ê°œë°œ",
                "íŠ¹í™”ëœ ì „ë¬¸ì„± ê°•í™”",
                "ì°¨ë³„í™”ëœ ê²½ìŸë ¥ í™•ë³´"
            ]
        },
        "ê· í˜•í˜•": {
            "title": "ê· í˜•í˜• (Balanced)",
            "description": "ëª¨ë“  ì˜ì—­ì—ì„œ ê³ ë¥¸ ë°œë‹¬ì„ ë³´ì´ëŠ” ê· í˜•ì¡íŒ íŒ€ì…ë‹ˆë‹¤.",
            "characteristics": [
                "ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ì—­ëŸ‰ ë³´ìœ ",
                "íŠ¹ë³„í•œ ì•½ì  ì—†ì´ ê³ ë¥¸ ì„±ê³¼",
                "ë‹¤ì–‘í•œ ì—…ë¬´ì— ë¬´ë‚œí•œ ëŒ€ì‘ë ¥",
                "ì¡°í™”ë¡œìš´ íŒ€ ìš´ì˜"
            ],
            "strengths": [
                "ì•ˆì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì„±ê³¼",
                "ë‹¤ì–‘í•œ ì—…ë¬´ ì˜ì—­ì—ì„œì˜ ì ì‘ë ¥",
                "ê· í˜•ì¡íŒ íŒ€ ì—­í•™"
            ],
            "development_areas": [
                "ì°¨ë³„í™”ëœ ê°•ì  ì˜ì—­ ë°œêµ´",
                "ì „ë¬¸ì„±ê³¼ íŠ¹í™” ì—­ëŸ‰ ê°œë°œ",
                "ë…íŠ¹í•œ ê²½ìŸìš°ìœ„ ì°½ì¶œ"
            ]
        }
    }

    return descriptions.get(team_type, descriptions["ê· í˜•í˜•"])


def get_team_development_suggestions(dominant_trait: str) -> list:
    """íŒ€ íŠ¹ì„±ë³„ ë°œì „ ì œì•ˆ"""
    suggestions = {
        "í˜ì‹ ì„±": [
            "ì°½ì˜ì  ì•„ì´ë””ì–´ ë°œêµ´ ì›Œí¬ìˆ ì •ê¸° ì§„í–‰",
            "ì‹¤í—˜ì  í”„ë¡œì íŠ¸ ì¶”ì§„ ê¸°íšŒ ì œê³µ",
            "ì™¸ë¶€ í˜ì‹  ì‚¬ë¡€ ë²¤ì¹˜ë§ˆí‚¹ í™œë™"
        ],
        "ì•ˆì •ì„±": [
            "í‘œì¤€ í”„ë¡œì„¸ìŠ¤ ë¬¸ì„œí™” ë° ì²´ê³„í™”",
            "í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ ê³ ë„í™”",
            "ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì—­ëŸ‰ ê°•í™” êµìœ¡"
        ],
        "í˜‘ë ¥ì„±": [
            "í¬ë¡œìŠ¤ í‘ì…”ë„ í”„ë¡œì íŠ¸ ì°¸ì—¬ ê¸°íšŒ í™•ëŒ€",
            "íŒ€ ë¹Œë”© ë° ì†Œí†µ ìŠ¤í‚¬ êµìœ¡",
            "ë‚´ì™¸ë¶€ ë„¤íŠ¸ì›Œí‚¹ í™œë™ ì§€ì›"
        ],
        "ì„±ê³¼ì§€í–¥": [
            "ë„ì „ì  ëª©í‘œ ì„¤ì • ë° ë‹¬ì„± ë³´ìƒ ì²´ê³„",
            "ì„±ê³¼ ì¸¡ì • ì§€í‘œ ê³ ë„í™”",
            "ê³ ì„±ê³¼ íŒ€ ì‚¬ë¡€ ê³µìœ  ì„¸ì…˜"
        ]
    }

    return suggestions.get(dominant_trait, ["ê· í˜•ì  ì—­ëŸ‰ ê°œë°œ í”„ë¡œê·¸ë¨ ì°¸ì—¬"])


def mask_sensitive_content(text: str) -> str:
    """
    ì£¼ê´€ì‹ ì‘ë‹µì—ì„œ ë¯¼ê°í•œ ì •ë³´ë¥¼ ë§ˆìŠ¤í‚¹í•œë‹¤.
    """
    import re

    # ì´ë©”ì¼ ì£¼ì†Œ ë§ˆìŠ¤í‚¹
    text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[ì´ë©”ì¼]', text)

    # ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
    text = re.sub(r'\b\d{2,3}[-\s]?\d{3,4}[-\s]?\d{4}\b', '[ì „í™”ë²ˆí˜¸]', text)

    # ê°œì¸ëª… ë§ˆìŠ¤í‚¹ ë¡œì§ ì œê±° (ì˜ëª»ëœ ë§¤ì¹­ìœ¼ë¡œ ì¸í•œ ì˜¤ë¥˜ ë°©ì§€)

    # ë¶€ì„œëª…ì´ ë„ˆë¬´ êµ¬ì²´ì ì¸ ê²½ìš°
    text = re.sub(r'\b\w+íŒ€\b', '[íŒ€ëª…]', text)

    return text


# ================================
# 1) í™˜ê²½ì„¤ì • / ê²½ë¡œ
# ================================
BASE_DIR = Path(__file__).resolve().parent
load_dotenv(BASE_DIR / ".env")

TEMPLATE_DIR = BASE_DIR / "templates"
REF_DIR = BASE_DIR / "reference" / "organizational-effectiveness"
INDEX_PATH = REF_DIR / "index.xlsx"
RAW_SAMPLE_PATH = REF_DIR / "rawsample.xlsx"
PROMPT_DIR = BASE_DIR / "prompts"

# ================================
# 2) Gemini (google-genai, ì‹  SDK)
# ================================
try:
    # pip install google-genai
    from google import genai  # ì‹  SDK
    _HAS_GENAI = True
except Exception:
    _HAS_GENAI = False

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GENAI_DEFAULT_MODEL = os.getenv("GENAI_MODEL", "gemini-2.5-flash")
ADMIN_PASSWORD = os.getenv("ADMIN_PASSWORD", "admin123")

_GENAI_CLIENT = None
def _get_genai_client():
    """
    google-genai í´ë¼ì´ì–¸íŠ¸ë¥¼ 1ë²ˆë§Œ ë§Œë“¤ê³  ì¬ì‚¬ìš©
    """
    global _GENAI_CLIENT
    if _GENAI_CLIENT is not None:
        return _GENAI_CLIENT
    if not _HAS_GENAI or not GOOGLE_API_KEY:
        return None
    try:
        _GENAI_CLIENT = genai.Client(api_key=GOOGLE_API_KEY)
        return _GENAI_CLIENT
    except Exception:
        return None


# ğŸ‘‰ğŸ‘‰ ğŸ‘‰ ì—¬ê¸° ì¶”ê°€ëœ ë¶€ë¶„ (1/2) ğŸ‘ˆ ğŸ‘ˆ ğŸ‘ˆ
def call_gemini(prompt: str, model: str | None = None) -> str:
    """
    ì‹¤ì œ Gemini í˜¸ì¶œ ë˜í¼
    - ì§€ê¸ˆ run_ai_interpretation_gemini_from_report(...) ì•ˆì—ì„œ ì´ í•¨ìˆ˜ë¥¼ ì—¬ëŸ¬ ë²ˆ ë¶€ë¥´ë¯€ë¡œ
      ì—¬ê¸°ì„œë§Œ SDK/í‚¤ ì²´í¬í•˜ê³  ë¬¸ìì—´ë§Œ ëŒë ¤ì£¼ë©´ ëœë‹¤.
    """
    if not _HAS_GENAI:
        return "[AI] google-genai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install google-genai` í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”."
    if not GOOGLE_API_KEY:
        return "[AI] GOOGLE_API_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .envì— `GOOGLE_API_KEY=...` ê°’ì„ ë„£ì–´ì£¼ì„¸ìš”."
    client = _get_genai_client()
    if client is None:
        return "[AI] Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨. API í‚¤/ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
    model = model or GENAI_DEFAULT_MODEL
    try:
        resp = client.models.generate_content(model=model, contents=prompt)
        # google-genai ì‘ë‹µì€ ë³´í†µ .text ì— ë³¸ë¬¸ì´ ë“¤ì–´ì˜¨ë‹¤
        return (getattr(resp, "text", "") or "").strip()
    except Exception as e:
        return f"[AI] Gemini í˜¸ì¶œ ì˜¤ë¥˜: {e}"


# ================================
# 3) ê¸€ë¡œë²Œ ìŠ¤íƒ€ì¼
# ================================
def inject_global_styles():
    st.markdown(
        """
        <style>
        .stApp { background: #f4f6fb; }
        header[data-testid="stHeader"] { display: none; }
        div[data-testid="stToolbar"] { display: none; }

        aside[data-testid="stSidebar"],
        section[data-testid="stSidebar"] {
            display: block !important;
            visibility: visible !important;
            background: linear-gradient(180deg, #f8fafc 0%, #f1f5f9 100%);
            border-right: 1px solid #e2e8f0;
            width: 16rem !important;
            min-width: 16rem !important;
            transform: none !important;
            box-shadow: 2px 0 10px rgba(0, 0, 0, 0.05);
        }
        div[data-testid="collapsedControl"] { display: none !important; }

        aside[data-testid="stSidebar"] > div:first-child,
        section[data-testid="stSidebar"] > div:first-child {
            padding: 1.5rem 1rem 1rem 1rem;
        }

        .sb-title {
            font-size: 0.85rem;
            font-weight: 700;
            color: #1e293b;
            margin-bottom: 1rem;
            padding: 0.5rem 0.75rem;
            background: linear-gradient(135deg, #0f4fa8 0%, #1d4ed8 100%);
            color: white;
            border-radius: 0.5rem;
            text-align: center;
            box-shadow: 0 2px 8px rgba(15, 79, 168, 0.2);
        }

        aside[data-testid="stSidebar"] .stButton > button,
        section[data-testid="stSidebar"] .stButton > button {
            width: 100%;
            background: white !important;
            border: 1px solid #e2e8f0 !important;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05) !important;
            text-align: left;
            border-radius: 0.75rem;
            padding: 0.75rem 1rem;
            font-size: 0.85rem;
            color: #334155;
            margin-bottom: 0.5rem;
            transition: all 0.2s ease;
            font-weight: 500;
        }
        aside[data-testid="stSidebar"] .stButton > button:hover,
        section[data-testid="stSidebar"] .stButton > button:hover {
            background: linear-gradient(135deg, #f0f7ff 0%, #e0f2fe 100%) !important;
            border-color: #0f4fa8 !important;
            color: #0f4fa8 !important;
            box-shadow: 0 4px 12px rgba(15, 79, 168, 0.15) !important;
            transform: translateY(-1px);
        }

        /* í™œì„± ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
        aside[data-testid="stSidebar"] .stButton > button[style*="background:rgba(7, 61, 130, 0.13)"],
        section[data-testid="stSidebar"] .stButton > button[style*="background:rgba(7, 61, 130, 0.13)"] {
            background: linear-gradient(135deg, #0f4fa8 0%, #1d4ed8 100%) !important;
            color: white !important;
            border-color: #0f4fa8 !important;
            box-shadow: 0 4px 12px rgba(15, 79, 168, 0.25) !important;
        }

        /* ìƒˆë¡œìš´ ì‚¬ì´ë“œë°” ì•„ì´í…œ ìŠ¤íƒ€ì¼ */
        .sidebar-item {
            width: 100%;
            background: white;
            border: 1px solid #e2e8f0;
            border-radius: 8px;
            margin-bottom: 4px;
            padding: 10px 12px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .sidebar-item:hover {
            background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
            border-color: #3B5BDB;
            box-shadow: 0 4px 12px rgba(59, 91, 219, 0.15);
            transform: translateY(-1px);
        }

        .sidebar-item:hover .sidebar-item-title {
            color: #3B5BDB;
        }

        .sidebar-item.active {
            background: linear-gradient(135deg, #0f4fa8 0%, #1d4ed8 100%);
            color: white;
            border-color: #0f4fa8;
            box-shadow: 0 4px 16px rgba(15, 79, 168, 0.25);
        }

        .sidebar-item-number {
            width: 24px;
            height: 24px;
            border-radius: 50%;
            background: #f1f5f9;
            color: #475569;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 600;
            font-size: 12px;
            flex-shrink: 0;
        }

        .sidebar-item.active .sidebar-item-number {
            background: rgba(255, 255, 255, 0.2);
            color: white;
        }

        .sidebar-item-content {
            flex: 1;
            min-width: 0;
        }

        .sidebar-item-title {
            font-weight: 600;
            font-size: 13px;
            color: #1e293b;
            margin-bottom: 1px;
        }

        .sidebar-item.active .sidebar-item-title {
            color: white;
        }

        .sidebar-item-desc {
            font-size: 10px;
            color: #64748b;
            line-height: 1.2;
        }

        .sidebar-item.active .sidebar-item-desc {
            color: rgba(255, 255, 255, 0.8);
        }

        .sidebar-item-status {
            width: 18px;
            height: 18px;
            border-radius: 50%;
            background: #f1f5f9;
            color: #64748b;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 11px;
            font-weight: 600;
            flex-shrink: 0;
        }

        .sidebar-item.active .sidebar-item-status {
            background: rgba(255, 255, 255, 0.2);
            color: white;
        }

        .sidebar-item.completed {
            background: #E0E0E0;
            border-color: #BDBDBD;
            opacity: 0.8;
        }

        .sidebar-item.completed .sidebar-item-title,
        .sidebar-item.completed .sidebar-item-desc {
            color: #757575;
        }

        .sidebar-item.completed .sidebar-item-number {
            background: #BDBDBD;
            color: #9E9E9E;
        }

        .sidebar-item.completed .sidebar-item-status {
            background: #4CAF50;
            color: white;
        }

        /* ìˆ¨ê²¨ì§„ ë²„íŠ¼ ë° ê´€ë ¨ ìš”ì†Œë“¤ ì™„ì „ ì œê±° */
        button[key^="hidden_menu_"],
        button[key$="_card"],
        .stButton:has(button[key^="hidden_menu_"]),
        .stButton:has(button[key$="_card"]),
        div[data-testid="stButton"]:has(button[key^="hidden_menu_"]),
        div[data-testid="stButton"]:has(button[key$="_card"]) {
            display: none !important;
            visibility: hidden !important;
            opacity: 0 !important;
            height: 0 !important;
            width: 0 !important;
            margin: 0 !important;
            padding: 0 !important;
            border: none !important;
            position: absolute !important;
            top: -9999px !important;
            left: -9999px !important;
            overflow: hidden !important;
            clip: rect(0, 0, 0, 0) !important;
        }

        /* ì‚¬ì´ë“œë°” ì „ì²´ì—ì„œ ë¹ˆ ìš”ì†Œë“¤ ì œê±° */
        aside[data-testid="stSidebar"] div:empty,
        aside[data-testid="stSidebar"] .stButton:empty,
        aside[data-testid="stSidebar"] .element-container:empty,
        aside[data-testid="stSidebar"] .stMarkdown:empty {
            display: none !important;
            height: 0 !important;
            margin: 0 !important;
            padding: 0 !important;
        }

        /* Streamlit ê¸°ë³¸ ë¹ˆ ìš”ì†Œë“¤ ê°•ë ¥ ì œê±° */
        .stButton:empty,
        .stMarkdown:empty,
        div[data-testid]:empty,
        .element-container:empty,
        .stHorizontalBlock:empty,
        .css-1d391kg:empty,
        .css-12oz5g7:empty {
            display: none !important;
            height: 0 !important;
            min-height: 0 !important;
            margin: 0 !important;
            padding: 0 !important;
            border: none !important;
        }

        /* ì‚¬ì´ë“œë°” ë‚´ ëª¨ë“  ë¹ˆ ë²„íŠ¼ ì»¨í…Œì´ë„ˆ ì œê±° */
        aside[data-testid="stSidebar"] .stButton {
            margin: 0 !important;
            padding: 0 !important;
        }

        aside[data-testid="stSidebar"] .stButton button[title=""],
        aside[data-testid="stSidebar"] .stButton button:empty {
            display: none !important;
            height: 0 !important;
            width: 0 !important;
        }

        /* Expander ìŠ¤íƒ€ì¼ ê°œì„  */
        aside[data-testid="stSidebar"] .streamlit-expanderHeader,
        section[data-testid="stSidebar"] .streamlit-expanderHeader {
            background: white;
            border: 1px solid #e2e8f0;
            border-radius: 0.5rem;
            padding: 0.5rem 0.75rem;
            font-size: 0.8rem;
            color: #64748b;
            margin-top: 1rem;
        }

        [data-testid="stAppViewContainer"] > .main {
            padding-top: 0 !important;
        }
        [data-testid="stAppViewContainer"] .block-container {
            background: #ffffff;
            border-radius: 1rem 1rem 0 0;
            box-shadow: 0 10px 30px rgba(4, 34, 87, 0.03);
            padding: 1.4rem 1.6rem 2.1rem 1.6rem;
            margin-top: 0.9rem;
            max-width: 1180px;
        }

        .page-header {
            background: linear-gradient(90deg,#0f4fa8 0%, #0b3d82 45%, #072a58 100%);
            margin: -1.4rem -1.6rem 1.2rem -1.6rem;
            padding: 1.05rem 1.2rem 1.05rem 1.6rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
            box-shadow: 0 3px 12px rgba(4,34,87,0.15);
        }
        .page-header-title {
            font-size: 1.25rem;
            font-weight: 660;
            color: #fff;
        }
        .page-header-right {
            font-size: 0.68rem;
            color: rgba(255,255,255,.85);
        }

        .guide-card {
            background: #f6f9ff;
            border: 1px solid #e3ecff;
            border-radius: .7rem;
            padding: .7rem .8rem .75rem .8rem;
            margin-bottom: .75rem;
        }
        .guide-card-title {
            font-weight: 650;
            font-size: .9rem;
            margin-bottom: .3rem;
            color: #1d2c44;
        }
        .guide-card-desc {
            font-size: .82rem;
            color: #4e617b;
            line-height: 1.45;
        }

        .info-card {
            background: #fff;
            border: 1px solid #edf0f5;
            border-radius: .75rem;
            overflow: hidden;
            margin-bottom: .9rem;
        }
        .info-card-head {
            background: #deebff;
            padding: .55rem .75rem;
            font-weight: 600;
            font-size: .78rem;
            color: #0f4fa8;
        }
        .info-card-body {
            padding: .65rem .8rem .75rem .8rem;
            font-size: .78rem;
            color: #1f2937;
        }

        .preview-container {
            border: 1px solid #edf0f5;
            border-radius: .75rem;
            background: #fff;
            overflow: hidden;
        }

        #export-view .export-card {
            background: #ffffff;
            border: 1px solid #dbe3ef;
            border-radius: .8rem;
            box-shadow: 0 6px 22px rgba(5, 31, 77, 0.03);
            padding: 0 0 1rem 0;
            margin-bottom: .7rem;
        }
        #export-view .export-card-head {
            background: #dfe8fb;
            padding: .65rem 1rem;
            border-radius: .8rem .8rem 0 0;
            font-weight: 650;
            font-size: .82rem;
            color: #0a3875;
        }
        #export-view .export-card-body {
            padding: .75rem 1rem 1rem 1rem;
        }

        div[data-testid="stMain"] button[data-testid="baseButton-primary"] {
            background: #0f4fa8;
            border-color: #0f4fa8;
        }
        div[data-testid="stMain"] button[data-testid="baseButton-primary"]:hover {
            background: #0c3d80;
            border-color: #0c3d80;
        }

        div[data-baseweb="input"] > div {
            border-color: rgba(15,79,168,0.25) !important;
            border-radius: .7rem !important;
            background: #fff;
        }

        /* =======================================
           ğŸ“± ë°˜ì‘í˜• ë””ìì¸ ê°œì„  (ëª¨ë°”ì¼/íƒœë¸”ë¦¿)
           ======================================= */

        /* ëª¨ë°”ì¼ í™˜ê²½ (768px ì´í•˜) */
        @media screen and (max-width: 768px) {
            .stApp {
                background: #f8fafc;
            }

            /* ì‚¬ì´ë“œë°” ëª¨ë°”ì¼ ìµœì í™” */
            aside[data-testid="stSidebar"],
            section[data-testid="stSidebar"] {
                width: 14rem !important;
                min-width: 14rem !important;
            }

            /* ë©”ì¸ ì»¨í…Œì´ë„ˆ ëª¨ë°”ì¼ ìµœì í™” */
            [data-testid="stAppViewContainer"] .block-container {
                padding: 1rem 0.8rem 1.5rem 0.8rem;
                margin-top: 0.5rem;
                border-radius: 0.5rem 0.5rem 0 0;
            }

            .page-header {
                margin: -1rem -0.8rem 1rem -0.8rem;
                padding: 0.8rem 1rem;
                flex-direction: column;
                gap: 0.5rem;
                text-align: center;
            }

            .page-header-title {
                font-size: 1.1rem;
            }

            /* Export ì¹´ë“œ ëª¨ë°”ì¼ ìµœì í™” */
            .export-card {
                margin-bottom: 1rem;
            }

            .export-card-head {
                font-size: 0.9rem;
                padding: 0.8rem 1rem;
            }

            .export-card-body {
                padding: 1rem;
            }

            /* ì‚¬ì´ë“œë°” ì•„ì´í…œ ëª¨ë°”ì¼ ìµœì í™” */
            .sidebar-item {
                padding: 8px 10px;
                gap: 8px;
            }

            .sidebar-item-title {
                font-size: 12px;
            }

            .sidebar-item-desc {
                font-size: 9px;
            }

            /* ë²„íŠ¼ ëª¨ë°”ì¼ ìµœì í™” */
            .stButton > button {
                width: 100%;
                min-height: 2.5rem;
                font-size: 0.9rem;
            }
        }

        /* íƒœë¸”ë¦¿ í™˜ê²½ (769px ~ 1024px) */
        @media screen and (min-width: 769px) and (max-width: 1024px) {
            [data-testid="stAppViewContainer"] .block-container {
                max-width: 95%;
                padding: 1.2rem 1.4rem 1.8rem 1.4rem;
            }

            .page-header {
                margin: -1.2rem -1.4rem 1rem -1.4rem;
                padding: 1rem 1.4rem;
            }
        }

        /* =======================================
           ğŸ¨ ë‹¤í¬ ëª¨ë“œ ì§€ì› (ì‹œìŠ¤í…œ í…Œë§ˆ ë”°ë¼ê°)
           ======================================= */

        @media (prefers-color-scheme: dark) {
            .stApp {
                background: #1a1a1a;
            }

            aside[data-testid="stSidebar"],
            section[data-testid="stSidebar"] {
                background: linear-gradient(180deg, #2d2d2d 0%, #1f1f1f 100%);
                border-right: 1px solid #404040;
            }

            [data-testid="stAppViewContainer"] .block-container {
                background: #2d2d2d;
                color: #e0e0e0;
            }

            .sidebar-item {
                background: #3d3d3d;
                border-color: #505050;
                color: #e0e0e0;
            }

            .sidebar-item:hover {
                background: linear-gradient(135deg, #4a4a4a 0%, #3d3d3d 100%);
                border-color: #6366f1;
            }

            .export-card {
                background: #3d3d3d;
                border-color: #505050;
                color: #e0e0e0;
            }
        }

        /* =======================================
           âš¡ ì„±ëŠ¥ ìµœì í™” ë° ì ‘ê·¼ì„± ê°œì„ 
           ======================================= */

        /* GPU ê°€ì† í™œì„±í™” */
        .sidebar-item,
        .export-card,
        .stButton > button {
            will-change: transform, box-shadow;
            transform: translateZ(0);
        }

        /* í¬ì»¤ìŠ¤ ì ‘ê·¼ì„± ê°œì„  */
        .sidebar-item:focus,
        .stButton > button:focus {
            outline: 2px solid #0f4fa8;
            outline-offset: 2px;
        }

        /* ì• ë‹ˆë©”ì´ì…˜ ì„±ëŠ¥ ìµœì í™” */
        .sidebar-item,
        .export-card,
        .stButton > button {
            transition: transform 0.15s cubic-bezier(0.4, 0, 0.2, 1),
                       box-shadow 0.15s cubic-bezier(0.4, 0, 0.2, 1),
                       background-color 0.15s cubic-bezier(0.4, 0, 0.2, 1);
        }

        /* ìŠ¤í¬ë¡¤ ì„±ëŠ¥ ìµœì í™” */
        .preview-container,
        #export-view,
        #email-view {
            contain: layout style paint;
        }

        /* ë¡œë”© ìƒíƒœ ì‹œê°í™” ê°œì„  */
        .stSpinner > div {
            border-color: #0f4fa8 transparent transparent transparent;
        }

        /* ì—ëŸ¬ ìƒíƒœ ì‹œê°í™” ê°œì„  */
        .stAlert[data-baseweb="notification"] {
            border-radius: 0.75rem;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }

        /* ì„±ê³µ ìƒíƒœ ì‹œê°í™” ê°œì„  */
        .stSuccess {
            background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%);
            border: 1px solid #22c55e;
            color: #15803d;
        }

        /* ê²½ê³  ìƒíƒœ ì‹œê°í™” ê°œì„  */
        .stWarning {
            background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
            border: 1px solid #f59e0b;
            color: #92400e;
        }

        /* ì •ë³´ ìƒíƒœ ì‹œê°í™” ê°œì„  */
        .stInfo {
            background: linear-gradient(135deg, #dbeafe 0%, #bfdbfe 100%);
            border: 1px solid #3b82f6;
            color: #1e40af;
        }

        </style>
        """,
        unsafe_allow_html=True,
    )


# ================================
# 4) í”„ë¡¬í”„íŠ¸ ìœ í‹¸ / ì•ˆì „ í¬ë§·í„°
# ================================
def load_prompt_file(name: str) -> str:
    p = PROMPT_DIR / name
    if p.exists():
        return p.read_text(encoding="utf-8")
    return ""

PROMPT_PREFIX = """
[ê·œì¹™ - ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ]
- ìƒˆë¡œìš´ IDë¥¼ ë§Œë“¤ì§€ ë§ê³ , ë°ì´í„°ì— ìˆëŠ” DIDë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë¼.
- ì—‘ì…€ í—¤ë”ê°€ ëª¨í˜¸í•˜ê±°ë‚˜ ë§¤í•‘ì´ ì•ˆ ë˜ëŠ” ê²½ìš°ëŠ” 'NEED_CONFIRMATION: ...' ìœ¼ë¡œ í‘œí˜„í•˜ê³  ì¶”ì¸¡í•˜ì§€ ë§ˆë¼.
- ë‹µë³€ì€ í•œêµ­ì–´ë¡œ í•˜ë˜, ì§„ë‹¨ëª…/ë¬¸í•­ëª…ì€ ì›ë³¸ ê°’ì„ ìœ ì§€í•˜ë¼.
- 5ë‹¨ê³„ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ê²ƒì„ ê¸ˆì§€í•œë‹¤. (score, item, free-text, org-context, writer, reviewerëŠ” ë¶„ë¦¬)
- NAS ê²½ë¡œ, íŒŒì¼ ê²½ë¡œëŠ” ì„ì˜ë¡œ í•˜ë“œì½”ë”©í•˜ì§€ ë§ê³  'TO_BE_FILLED_BY_SYSTEM'ìœ¼ë¡œ ë‚¨ê²¨ë¼.
""".strip()

AI_STRIP_PREFIXES = [
    "ì €ëŠ” ì¡°ì§íš¨ê³¼ì„± ì§„ë‹¨ ì ìˆ˜ë¥¼ í•´ì„í•˜ëŠ” HRD ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.",
    "ë°ì´í„°ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë¶„ì„í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
    "ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ì‘ë‹µì ìˆ˜(N)ì™€ Input, Process, Output ê° ì˜ì—­ì˜ ì ìˆ˜ë¥¼ ì œê³µí•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.",
    "ì˜ˆì‹œ ë¶„ì„ (ê°€ìƒ ë°ì´í„° ì ìš©):",
    "ì˜ˆì‹œ:",
]


def _clean_ai_text(text: str, min_len: int = 40) -> str:
    """Geminiê°€ ë¶™ì—¬ë³´ë‚´ëŠ” 'ì €ëŠ” â€¦' ê°™ì€ ë¨¸ë¦¿ë§, ``` ì½”ë“œë¸”ë¡, ë„ˆë¬´ ê¸´ êµ¬ë¶„ì„  ë“±ì„ ì˜ë¼ë‚¸ë‹¤."""
    if not text:
        return ""
    t = str(text).strip()
    # ì½”ë“œíœìŠ¤ ì œê±°
    t = t.replace("```", "").replace("** **", "").strip()
    # ë§ˆí¬ë‹¤ìš´ ê°•ì¡° í‘œì‹œ ì œê±°
    import re
    t = re.sub(r'\*\*(.*?)\*\*', r'\1', t)  # **í…ìŠ¤íŠ¸** -> í…ìŠ¤íŠ¸
    t = re.sub(r'\*(.*?)\*', r'\1', t)      # *í…ìŠ¤íŠ¸* -> í…ìŠ¤íŠ¸
    t = re.sub(r'_{2,}(.*?)_{2,}', r'\1', t)  # __í…ìŠ¤íŠ¸__ -> í…ìŠ¤íŠ¸
    # JSON í˜•ì‹ ì œê±°
    t = t.replace("json", "").strip()
    # ì•ë¨¸ë¦¬ ê³µí†µ ë¬¸êµ¬ ì œê±°
    for prefix in AI_STRIP_PREFIXES:
        if t.startswith(prefix):
            t = t[len(prefix):].lstrip(" \n:*").strip()
    # ë„ˆë¬´ ì§§ìœ¼ë©´ ì›ë¬¸ ìœ ì§€
    if len(t) < min_len:
        return t
    return t

def _fix_json_response(text: str) -> str:
    """
    AI ì‘ë‹µì—ì„œ JSON í˜•ì‹ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•œë‹¤
    """
    if not text:
        return text

    # "json\n{...}" íŒ¨í„´ ì²˜ë¦¬
    if text.startswith("json\n{"):
        try:
            import json
            json_part = text[5:]  # "json\n" ì œê±°
            parsed = json.loads(json_part)
            # JSONì´ ì •ìƒ íŒŒì‹±ë˜ë©´ ì‹¤ì œ ê°’ ì¶”ì¶œ
            if isinstance(parsed, dict) and len(parsed) == 1:
                return list(parsed.values())[0]
        except:
            # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ì›ë¬¸ ë°˜í™˜
            pass

    return text

def _convert_error_to_natural_response(text: str, field_type: str) -> str:
    """
    ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì•ˆ ì‘ë‹µìœ¼ë¡œ ë³€í™˜
    """
    if not text:
        return text

    # ê³µí†µ ì—ëŸ¬ ë©”ì‹œì§€ íŒ¨í„´ ê°ì§€
    error_patterns = [
        "ì´ë²ˆ ê²°ê³¼ì—ì„œëŠ” íŠ¹ì´ì‚¬í•­ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
        "ì´ˆì•ˆ ì¹´ë“œì˜ ë‚´ìš©ì´ ë¹„ì–´ìˆì–´ ê¸°ë³¸ ë¬¸êµ¬ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤",
        "ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤",
        "ì •ë³´ê°€ ë¶ˆì¶©ë¶„í•©ë‹ˆë‹¤"
    ]

    for pattern in error_patterns:
        if pattern in text:
            return _generate_fallback_response(field_type)

    return text

def _generate_fallback_response(field_type: str) -> str:
    """
    í•„ë“œ íƒ€ì…ë³„ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì•ˆ ì‘ë‹µ ìƒì„±
    """
    fallback_responses = {
        "score": "ì¡°ì§ì˜ ì „ë°˜ì ì¸ ìš´ì˜ ìˆ˜ì¤€ì´ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë˜ê³  ìˆìœ¼ë©°, êµ¬ì„±ì›ë“¤ì˜ ì—…ë¬´ ëª°ì…ë„ì™€ í˜‘ì—… ì²´ê³„ê°€ ì–‘í˜¸í•œ ìƒíƒœë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì§€ì†ì ì¸ ë°œì „ì„ ìœ„í•´ì„œëŠ” ì†Œí†µê³¼ í˜‘ë ¥ ì²´ê³„ë¥¼ ë”ìš± ê°•í™”í•˜ëŠ” ê²ƒì´ ë„ì›€ì´ ë  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.",
        "items": "í˜„ì¬ ì¡°ì§ì€ ì „ë°˜ì ìœ¼ë¡œ ê· í˜• ì¡íŒ ìš´ì˜ ìƒíƒœë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. í–¥í›„ ë” ë‚˜ì€ ì„±ê³¼ë¥¼ ìœ„í•´ì„œëŠ” ë¶€ì„œ ê°„ í˜‘ì—… ê°•í™”, ì˜ì‚¬ì†Œí†µ ì²´ê³„ ê°œì„ , ê·¸ë¦¬ê³  êµ¬ì„±ì› ì—­ëŸ‰ ê°œë°œì— ì§€ì†ì ì¸ ê´€ì‹¬ì„ ê¸°ìš¸ì´ëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤.",
        "free_text": "êµ¬ì„±ì›ë“¤ì˜ ì „ë°˜ì ì¸ ì¡°ì§ ë§Œì¡±ë„ëŠ” ì–‘í˜¸í•œ ìˆ˜ì¤€ì´ë©°, ì—…ë¬´ í™˜ê²½ê³¼ íŒ€ì›Œí¬ì— ëŒ€í•´ ê¸ì •ì ìœ¼ë¡œ í‰ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì§€ì†ì ì¸ ì„±ì¥ì„ ìœ„í•´ì„œëŠ” ê°œë°©ì ì¸ ì†Œí†µ ë¬¸í™”ì™€ ìƒí˜¸ ì‹ ë¢° ê¸°ë°˜ì˜ í˜‘ì—… ì²´ê³„ë¥¼ ë”ìš± ë°œì „ì‹œì¼œ ë‚˜ê°€ëŠ” ê²ƒì´ ì¤‘ìš”í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.",
        "org_context": "ì´ ì¡°ì§ì€ ì²´ê³„ì ì¸ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ì™€ ì „ë¬¸ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ìš´ì˜ë˜ê³  ìˆìœ¼ë©°, êµ¬ì„±ì›ë“¤ ê°„ì˜ í˜‘ë ¥ê³¼ ì†Œí†µì„ í†µí•´ ëª©í‘œë¥¼ ë‹¬ì„±í•´ ë‚˜ê°€ëŠ” ê±´ê°•í•œ ì¡°ì§ ë¬¸í™”ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "writer": "ì´ë²ˆ ì§„ë‹¨ì—ì„œ ë¦¬ë”ê°€ ë¨¼ì € ì´í•´í•´ì•¼ í•  ê´€ì ì€, ì¡°ì§ì´ ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ìš´ì˜ ê¸°ë°˜ì„ ê°–ì¶”ê³  ìˆìœ¼ë©´ì„œë„ ì§€ì†ì ì¸ ë°œì „ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤. êµ¬ì„±ì›ë“¤ì˜ ë†’ì€ ì°¸ì—¬ë„ì™€ í˜‘ë ¥ ì˜ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì†Œí†µ ì²´ê³„ë¥¼ ë”ìš± ì²´ê³„í™”í•˜ê³  ìƒí˜¸ ì‹ ë¢°ë¥¼ ê°•í™”í•œë‹¤ë©´ ë” í° ì‹œë„ˆì§€ë¥¼ ì°½ì¶œí•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤."
    }

    return fallback_responses.get(field_type, "ì¡°ì§ì˜ í˜„ì¬ ìƒíƒœëŠ” ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•˜ë©°, ì§€ì†ì ì¸ ê°œì„ ì„ í†µí•´ ë” ë‚˜ì€ ì„±ê³¼ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.")


def _normalize_ai_result(ai: dict | None) -> dict:
    """
    geminiê°€ ë­˜ ì£¼ë“  UIì—ì„œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì •ê·œí™”
    - None â†’ {}
    - ê° í•„ë“œëŠ” strë¡œ ê°•ì œ
    - JSON íŒŒì‹± ì˜¤ë¥˜ ë³µêµ¬
    - ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì•ˆ ì‘ë‹µìœ¼ë¡œ ë³€í™˜
    """
    if not ai:
        return {}
    norm = {}
    for key in ["score", "items", "free_text", "org_context", "writer", "reviewer", "final"]:
        val = ai.get(key)
        if val is None:
            norm[key] = ""
        else:
            val_str = str(val).strip()
            # JSON í˜•ì‹ ì˜¤ë¥˜ ë³µêµ¬
            val_str = _fix_json_response(val_str)
            # ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µìœ¼ë¡œ ë³€í™˜
            val_str = _convert_error_to_natural_response(val_str, key)
            norm[key] = val_str
    return norm

# ================================================
# AI í…ìŠ¤íŠ¸ ì•ˆì˜ {{ ... }} í”Œë ˆì´ìŠ¤í™€ë” ì¹˜í™˜ ìœ í‹¸
# ================================================
def _build_ai_context_from_report(report: dict) -> dict:
    """
    AIê°€ 'í•´ë‹¹ ì¡°ì§ì€ {{org_units}} ...' ì‹ìœ¼ë¡œ ëŒë ¤ë³´ë‚¸ í…ìŠ¤íŠ¸ë¥¼
    ì‹¤ì œ ì¡°ì§ëª…/ì‚°ì—…ëª…/ì£¼ê´€ì‹ìš”ì•½ìœ¼ë¡œ ë°”ê¿€ ë•Œ ì‚¬ìš©í•  ì»¨í…ìŠ¤íŠ¸ë¥¼ ë§Œë“ ë‹¤.
    """
    if report is None:
        report = {}

    summary = report.get("summary") or {}

    ctx: dict[str, object] = {}
    # ì¡°ì§ëª… í›„ë³´
    ctx["org_units"] = (
        report.get("org_name")
        or report.get("dept_name")
        or "í•´ë‹¹ ì¡°ì§"
    )
    # ì‚°ì—… ì¶”ì •
    ctx["industry_guess"] = (
        summary.get("industry_guess")
        or _guess_industry_from_name(report.get("org_name") or "")
    )
    # NO40 ì£¼ê´€ì‹
    no40 = summary.get("no40_text") or []
    if isinstance(no40, list):
        ctx["no40_text"] = no40
        ctx["no40_text_joined"] = ", ".join([str(x) for x in no40])
    else:
        ctx["no40_text"] = [no40]
        ctx["no40_text_joined"] = str(no40)

    return ctx


def materialize_ai_placeholders(ai_raw: dict | None, report: dict) -> dict | None:
    """
    ai_raw ì•ˆì— ë“¤ì–´ìˆëŠ” ë¬¸ìì—´ì„ í•œ ë²ˆ ë” Jinjaë¡œ ë Œë”í•´ì„œ
    {{org_units}}, {{industry_guess}}, {{no40_text_joined}} ê°™ì€ ê±¸ ì‹¤ì œ ê°’ìœ¼ë¡œ ì¹˜í™˜í•œë‹¤.
    """
    if not ai_raw:
        return ai_raw

    ctx = _build_ai_context_from_report(report)
    env = Environment(loader=BaseLoader())

    hydrated: dict[str, object] = {}
    for key, val in ai_raw.items():
        if isinstance(val, str):
            try:
                tpl = env.from_string(val)
                hydrated[key] = tpl.render(**ctx)
            except Exception:
                hydrated[key] = val
        else:
            hydrated[key] = val
    return hydrated

def _has_ai_result(ai: dict | None) -> bool:
    """í‘œì‹œí•  ë§Œí•œ AI ê²°ê³¼ê°€ ìˆëŠ”ì§€ ì—¬ë¶€"""
    if not ai:
        return False
    for k in ("score", "items", "free_text", "org_context", "writer", "reviewer", "final"):
        v = ai.get(k)
        if v and str(v).strip():
            return True
    return False


# ================================
# 5) ë°ì´í„° ë¡œë”©/ê²€ì¦/ë§ˆìŠ¤í‚¹
# ================================
@st.cache_data
def load_index():
    df = pd.read_excel(INDEX_PATH)
    df.columns = [c.strip() for c in df.columns]
    if "ëŒ€ë¶„ë¥˜" in df.columns:
        df["ëŒ€ë¶„ë¥˜_clean"] = df["ëŒ€ë¶„ë¥˜"].astype(str).str.strip()
    else:
        df["ëŒ€ë¶„ë¥˜_clean"] = ""
    return df


def extract_organization_info(df: pd.DataFrame) -> dict:
    """
    ì—…ë¡œë“œëœ ë°ì´í„°ì—ì„œ ì¡°ì§ëª…ê³¼ ë¶€ì„œ/íŒ€ëª…ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œí•œë‹¤.
    """
    org_info = {
        "company": None,
        "department": None
    }

    if df is None or df.empty:
        return org_info

    # íšŒì‚¬ëª… í›„ë³´ ì»¬ëŸ¼ë“¤
    company_columns = ["CMPNAME", "íšŒì‚¬ëª…", "ì¡°ì§ëª…", "Company", "Organization", "Org", "íšŒì‚¬", "ì¡°ì§"]
    for col in company_columns:
        if col in df.columns:
            company_values = df[col].dropna().unique()
            if len(company_values) > 0:
                # ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚˜ëŠ” ê°’ ì„ íƒ
                company_counts = df[col].value_counts()
                org_info["company"] = str(company_counts.index[0]).strip()
                break

    # ë¶€ì„œ/íŒ€ëª… í›„ë³´ ì»¬ëŸ¼ë“¤
    dept_columns = ["POS", "ë¶€ì„œëª…", "íŒ€ëª…", "Department", "Team", "Position", "ë¶€ì„œ", "íŒ€", "ì§ì±…", "ì†Œì†"]
    for col in dept_columns:
        if col in df.columns:
            dept_values = df[col].dropna().unique()
            if len(dept_values) > 0:
                # ì—¬ëŸ¬ ê°’ì´ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ê°’ ì„ íƒ (íŒ€ë³„ ë¶„ì„ì—ì„œëŠ” ê°ê° ì²˜ë¦¬)
                org_info["department"] = str(dept_values[0]).strip()
                break

    return org_info


def load_data(uploaded_file):
    if uploaded_file is not None:
        try:
            # íŒŒì¼ í™•ì¥ìë¥¼ í™•ì¸í•˜ì—¬ ì ì ˆí•œ ì½ê¸° ë°©ë²• ì„ íƒ
            file_name = uploaded_file.name.lower()

            if file_name.endswith('.csv'):
                # CSV íŒŒì¼ ì²˜ë¦¬ - ì¸ì½”ë”© ìë™ ê°ì§€
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                except UnicodeDecodeError:
                    # UTF-8 ì‹¤íŒ¨ì‹œ CP949(í•œêµ­ì–´) ì‹œë„
                    uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                    try:
                        df = pd.read_csv(uploaded_file, encoding='cp949')
                    except UnicodeDecodeError:
                        # CP949ë„ ì‹¤íŒ¨ì‹œ ISO-8859-1ë¡œ ì‹œë„
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, encoding='iso-8859-1')
            elif file_name.endswith(('.xlsx', '.xls')):
                # ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬
                df = pd.read_excel(uploaded_file)
            else:
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ì—‘ì…€ ì‹œë„
                df = pd.read_excel(uploaded_file)

            # ë°ì´í„° ì „ì²˜ë¦¬
            # ë¹ˆ í–‰ ì œê±°
            df = df.dropna(how='all')

            # ì»¬ëŸ¼ëª… ì •ë¦¬ (ì•ë’¤ ê³µë°± ì œê±°)
            df.columns = df.columns.astype(str).str.strip()

            source = "uploaded"

        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            st.error("ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹: .xlsx, .xls, .csv")
            # ì˜¤ë¥˜ ì‹œ ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©
            df = pd.read_excel(RAW_SAMPLE_PATH)
            source = "sample_fallback"

    else:
        # ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©
        df = pd.read_excel(RAW_SAMPLE_PATH)
        source = "sample"

    return df, source


def validate_df(df: pd.DataFrame, index_df: pd.DataFrame):
    header_col = "í—¤ë”ëª…" if "í—¤ë”ëª…" in index_df.columns else index_df.columns[0]
    expected_cols = index_df[header_col].dropna().astype(str).str.strip().tolist()
    df_cols = [c.strip() for c in df.columns]
    missing = [c for c in expected_cols if c not in df_cols]
    extra = [c for c in df_cols if c not in expected_cols]
    return {
        "missing": missing,
        "extra": extra,
        "expected_count": len(expected_cols),
        "actual_count": len(df_cols),
    }


SENSITIVE_KEYWORDS = [
    "ì¡°ì§", "íšŒì‚¬", "ë¶€ì„œ", "íŒ€", "ë³¸ë¶€", "ì†Œì†", "ë¶€ë¬¸", "ì‚¬ì—…ë¶€", "ì„¼í„°",
    "ì´ë¦„", "ì„±ëª…", "name", "department", "organization", "org"
]


def _mask_token(token: str) -> str:
    token = token.strip()
    if not token:
        return token
    if len(token) == 1:
        return "ï¼Š"
    if len(token) == 2:
        return token[0] + "ï¼Š"
    return token[0] + "ï¼Š" * (len(token) - 2) + token[-1]


def mask_text(val: str | None) -> str | None:
    if val is None:
        return val
    s = str(val).strip()
    if s == "":
        return s
    parts = s.split()
    masked_parts = [_mask_token(p) for p in parts]
    return " ".join(masked_parts)


def mask_email(val: str | None) -> str | None:
    if val is None:
        return val
    s = str(val).strip()
    if "@" not in s:
        return s
    local, domain = s.split("@", 1)
    if len(local) <= 2:
        local_masked = local[0] + "****"
    else:
        local_masked = local[0] + "****" + local[-1]
    return local_masked + "@" + domain


def mask_df_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    df_masked = df.copy()
    for col in df_masked.columns:
        col_l = col.lower()
        series_str = df_masked[col].astype(str)
        if series_str.str.contains("@").any():
            df_masked[col] = series_str.apply(mask_email)
            continue
        if any(k in col_l for k in SENSITIVE_KEYWORDS):
            df_masked[col] = series_str.apply(mask_text)
    return df_masked


# ================================
# 6) ë©€í‹° ë¦¬í¬íŠ¸ ê¸°ëŠ¥
# ================================
def group_data_by_unit(df: pd.DataFrame, group_type: str, group_column: str = None) -> dict:
    """
    ë°ì´í„°ë¥¼ ì¡°ì§ ë‹¨ìœ„ë³„ë¡œ ê·¸ë£¹í•‘í•œë‹¤.

    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        group_type: "ì „ì²´" ë˜ëŠ” "íŒ€ë³„"
        group_column: íŒ€ë³„ ê·¸ë£¹í•‘ ì‹œ ì‚¬ìš©í•  ì»¬ëŸ¼ëª…

    Returns:
        {group_name: grouped_dataframe} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    if group_type == "ì „ì²´":
        return {"ì „ì²´ ì¡°ì§": df.copy()}

    elif group_type == "íŒ€ë³„":
        if not group_column or group_column not in df.columns:
            st.error(f"ê·¸ë£¹í•‘ ì»¬ëŸ¼ '{group_column}'ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
            return {"ì „ì²´ ì¡°ì§": df.copy()}

        grouped_data = {}

        # íŒ€ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬
        for team_name, team_df in df.groupby(group_column):
            if len(team_df) < 3:  # ìµœì†Œ ì‘ë‹µì ìˆ˜ ì²´í¬ (UIì—ì„œ ì´ë¯¸ í‘œì‹œë¨)
                continue
            grouped_data[str(team_name)] = team_df.copy()

        if not grouped_data:
            st.error("ìœ íš¨í•œ íŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ì¡°ì§ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            return {"ì „ì²´ ì¡°ì§": df.copy()}

        return grouped_data

    return {"ì „ì²´ ì¡°ì§": df.copy()}


def build_multiple_reports(grouped_data: dict, index_df: pd.DataFrame, detected_company_name: str = None, detected_dept_name: str = None) -> dict:
    """
    ê·¸ë£¹í•‘ëœ ë°ì´í„°ë¡œë¶€í„° ì—¬ëŸ¬ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•œë‹¤.

    Args:
        grouped_data: {group_name: dataframe} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        index_df: ì¸ë±ìŠ¤ ë°ì´í„°í”„ë ˆì„
        detected_company_name: ê°ì§€ëœ íšŒì‚¬ëª…
        detected_dept_name: ê°ì§€ëœ ë¶€ì„œ/íŒ€ëª…

    Returns:
        {group_name: report_object} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    reports = {}

    for group_name, group_df in grouped_data.items():
        try:
            print(f"DEBUG: '{group_name}' ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ - ë°ì´í„° í¬ê¸°: {group_df.shape}")
            report = build_report(group_df, index_df)
            print(f"DEBUG: '{group_name}' build_report ì™„ë£Œ")

            # ì¡°ì§ëª… ìˆ˜ì • (íŒ€ë³„ì¸ ê²½ìš° íŒ€ëª…ì„ ì¡°ì§ëª…ìœ¼ë¡œ, ì „ì²´ì¸ ê²½ìš° íšŒì‚¬ëª… ì‚¬ìš©)
            if group_name != "ì „ì²´ ì¡°ì§":
                # íŒ€ë³„ ë¦¬í¬íŠ¸ì¸ ê²½ìš° íŒ€ëª…ì„ ì¡°ì§ëª…ìœ¼ë¡œ ì‚¬ìš©
                report["organization_name"] = group_name
                # ì›ë˜ íšŒì‚¬ëª…ì€ dept_nameì— ì €ì¥
                if detected_company_name:
                    report["dept_name"] = detected_company_name
                # íŒ€ë³„ ë¦¬í¬íŠ¸ì„ì„ í‘œì‹œí•˜ëŠ” í”Œë˜ê·¸
                report["is_total_organization"] = False
            else:
                # ì „ì²´ ì¡°ì§ì¸ ê²½ìš° ê°ì§€ëœ íšŒì‚¬ëª… ì‚¬ìš©
                if detected_company_name:
                    report["organization_name"] = detected_company_name
                # ì „ì²´ ì¡°ì§ì„ì„ í‘œì‹œí•˜ëŠ” í”Œë˜ê·¸ ì¶”ê°€
                report["is_total_organization"] = True
                # dept_nameì€ ì„¤ì •í•˜ì§€ ì•ŠìŒ (ì „ì²´ ì¡°ì§ì´ë¯€ë¡œ)
            reports[group_name] = report
            print(f"DEBUG: '{group_name}' ë¦¬í¬íŠ¸ ì™„ë£Œ")
            print(f"DEBUG: organization_name: {report.get('organization_name')}")
            print(f"DEBUG: dept_name: {report.get('dept_name')}")
            print(f"DEBUG: is_total_organization: {report.get('is_total_organization')}")
        except Exception as e:
            error_msg = f"'{group_name}' ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            print(f"ERROR: {error_msg}")
            import traceback
            traceback.print_exc()
            try:
                st.error(error_msg)
            except:
                pass  # streamlitì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ í™˜ê²½ì—ì„œëŠ” ë¬´ì‹œ
            continue

    return reports


def get_possible_group_columns(df: pd.DataFrame) -> list:
    """
    íŒ€ë³„ ê·¸ë£¹í•‘ì´ ê°€ëŠ¥í•œ ì»¬ëŸ¼ë“¤ì„ ì°¾ëŠ”ë‹¤.
    """
    possible_columns = []

    for col in df.columns:
        col_lower = col.lower()
        # íŒ€, ë¶€ì„œ, ì¡°ì§ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
        if any(keyword in col_lower for keyword in ['íŒ€', 'ë¶€ì„œ', 'ì¡°ì§', 'ì†Œì†', 'ë¶€ë¬¸', 'ì„¼í„°', 'team', 'dept', 'org']):
            # ë„ˆë¬´ ë§ì€ ê³ ìœ ê°’ì„ ê°€ì§„ ì»¬ëŸ¼ì€ ì œì™¸ (ê°œì¸ëª… ë“±)
            unique_count = df[col].nunique()
            total_count = len(df)
            if 2 <= unique_count <= total_count * 0.7:  # 2ê°œ ì´ìƒ, ì „ì²´ì˜ 70% ì´í•˜
                possible_columns.append(col)

    return possible_columns


# ================================
# 6.5) PDF ë©€í‹° ìƒì„± ê¸°ëŠ¥
# ================================
def generate_multiple_pdfs(reports: dict, ai_results: dict = None) -> dict:
    """
    ì—¬ëŸ¬ ë¦¬í¬íŠ¸ì— ëŒ€í•´ PDFë¥¼ ìƒì„±í•œë‹¤.

    Args:
        reports: {team_name: report_object} ë”•ì…”ë„ˆë¦¬
        ai_results: {team_name: ai_result} ë”•ì…”ë„ˆë¦¬ (ì˜µì…˜)

    Returns:
        {team_name: pdf_bytes} ë”•ì…”ë„ˆë¦¬
    """
    from pdf_export import html_to_pdf_with_chrome

    pdf_results = {}
    total_teams = len(reports)

    for i, (team_name, report) in enumerate(reports.items()):
        # AI ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        ai_key = f"ai_result_{team_name}"
        ai_result = ai_results.get(ai_key) if ai_results else st.session_state.get(ai_key)
        ai_raw = _normalize_ai_result(ai_result)
        ai_raw = materialize_ai_placeholders(ai_raw, report)

        # HTML ìƒì„±
        html_content = render_web_html(
            report,
            ai_result=ai_raw if _has_ai_result(ai_raw) else None,
        )

        # PDF ìƒì„±
        try:
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_file:
                tmp_pdf_path = tmp_file.name

            html_to_pdf_with_chrome(html_content, tmp_pdf_path)
            pdf_bytes = Path(tmp_pdf_path).read_bytes()
            pdf_results[team_name] = pdf_bytes

            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(tmp_pdf_path)

        except Exception as e:
            st.error(f"'{team_name}' PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            continue

    return pdf_results


def generate_multiple_pdfs_parallel(reports: dict, ai_results: dict = None, max_workers: int = None, batch_size: int = None) -> dict:
    """
    ì—¬ëŸ¬ ë¦¬í¬íŠ¸ì— ëŒ€í•´ ë³‘ë ¬ë¡œ PDFë¥¼ ìƒì„±í•œë‹¤. (ê°œì„ ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ë™ì  ì›Œì»¤ ìˆ˜ ì¡°ì •)

    Args:
        reports: {team_name: report_object} ë”•ì…”ë„ˆë¦¬
        ai_results: {team_name: ai_result} ë”•ì…”ë„ˆë¦¬ (ì˜µì…˜)
        max_workers: ë³‘ë ¬ ì‘ì—…ì ìˆ˜ (Noneì´ë©´ CPU ì½”ì–´ ìˆ˜ì— ë”°ë¼ ìë™ ê²°ì •)
        batch_size: ë°°ì¹˜ í¬ê¸° (Noneì´ë©´ ì›Œì»¤ ìˆ˜ * 2ë¡œ ìë™ ê²°ì •)

    Returns:
        {team_name: pdf_bytes} ë”•ì…”ë„ˆë¦¬
    """
    import concurrent.futures
    from pdf_export import html_to_pdf_with_chrome
    import tempfile
    import os
    import psutil
    import gc
    from pathlib import Path

    # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ê¸°ë°˜ ë™ì  ì›Œì»¤ ìˆ˜ ê²°ì •
    if max_workers is None:
        cpu_count = os.cpu_count() or 4
        memory_gb = psutil.virtual_memory().total / (1024**3)

        # CPU ì½”ì–´ì™€ ë©”ëª¨ë¦¬ë¥¼ ê³ ë ¤í•œ ì›Œì»¤ ìˆ˜ ê²°ì •
        # PDF ìƒì„±ì€ ë©”ëª¨ë¦¬ ì§‘ì•½ì ì´ë¯€ë¡œ ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •
        if memory_gb >= 16:
            max_workers = min(cpu_count, 6)  # ê³ ë©”ëª¨ë¦¬: ìµœëŒ€ 6ê°œ
        elif memory_gb >= 8:
            max_workers = min(cpu_count, 4)  # ì¤‘ë©”ëª¨ë¦¬: ìµœëŒ€ 4ê°œ
        else:
            max_workers = min(cpu_count, 2)  # ì €ë©”ëª¨ë¦¬: ìµœëŒ€ 2ê°œ

    # ë°°ì¹˜ í¬ê¸° ìë™ ê²°ì •
    if batch_size is None:
        batch_size = max_workers * 2

    total_reports = len(reports)
    st.info(f"ğŸ“Š PDF ë³‘ë ¬ ìƒì„± ì„¤ì •: ì›Œì»¤ {max_workers}ê°œ, ë°°ì¹˜ í¬ê¸° {batch_size}, ì´ {total_reports}ê°œ ë¦¬í¬íŠ¸")

    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
    initial_memory = psutil.virtual_memory().used / (1024**3)

    def generate_single_pdf(team_data):
        team_name, report = team_data
        html_content = None
        ai_raw = None
        tmp_pdf_path = None

        try:
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
            current_memory = psutil.virtual_memory().percent
            if current_memory > 85:  # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  85% ì´ˆê³¼ ì‹œ ëŒ€ê¸°
                gc.collect()
                st.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ ({current_memory:.1f}%) - '{team_name}' ì²˜ë¦¬ ëŒ€ê¸° ì¤‘...")

            # AI ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            ai_key = f"ai_result_{team_name}"
            ai_result = ai_results.get(ai_key) if ai_results else st.session_state.get(ai_key)
            ai_raw = _normalize_ai_result(ai_result)
            ai_raw = materialize_ai_placeholders(ai_raw, report)

            # HTML ìƒì„±
            html_content = render_web_html(
                report,
                ai_result=ai_raw if _has_ai_result(ai_raw) else None,
            )

            # PDF ìƒì„±
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_file:
                tmp_pdf_path = tmp_file.name

            html_to_pdf_with_chrome(html_content, tmp_pdf_path)
            pdf_bytes = Path(tmp_pdf_path).read_bytes()

            # PDF ìƒì„± ì„±ê³µ ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬
            html_content = None
            ai_raw = None
            gc.collect()

            return team_name, pdf_bytes, len(pdf_bytes)

        except Exception as e:
            error_msg = f"'{team_name}' PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            return team_name, None, error_msg

        finally:
            # ì •ë¦¬ ì‘ì—…
            if tmp_pdf_path and os.path.exists(tmp_pdf_path):
                try:
                    os.unlink(tmp_pdf_path)
                except:
                    pass

            # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë³€ìˆ˜ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ)
            try:
                if 'html_content' in locals() and html_content is not None:
                    del html_content
                if 'ai_raw' in locals() and ai_raw is not None:
                    del ai_raw
            except:
                pass
            gc.collect()

    pdf_results = {}
    error_count = 0
    success_count = 0
    total_size_mb = 0

    # ë°°ì¹˜ë³„ ì²˜ë¦¬
    report_items = list(reports.items())
    total_batches = (len(report_items) + batch_size - 1) // batch_size

    # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ í”„ë¡œê·¸ë ˆìŠ¤ ë°”
    progress_bar = st.progress(0)
    status_text = st.empty()

    for batch_idx in range(total_batches):
        start_idx = batch_idx * batch_size
        end_idx = min(start_idx + batch_size, len(report_items))
        batch_items = report_items[start_idx:end_idx]

        batch_progress = (batch_idx / total_batches) * 100
        status_text.text(f"ğŸ“¦ ë°°ì¹˜ {batch_idx + 1}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch_items)}ê°œ ë¦¬í¬íŠ¸)")
        progress_bar.progress(batch_progress / 100)

        # ë°°ì¹˜ë³„ ë³‘ë ¬ ì²˜ë¦¬
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_team = {executor.submit(generate_single_pdf, item): item[0]
                             for item in batch_items}

            for future in concurrent.futures.as_completed(future_to_team):
                team_name = future_to_team[future]
                try:
                    result_team_name, pdf_bytes, size_info = future.result()

                    if pdf_bytes is not None:
                        pdf_results[result_team_name] = pdf_bytes
                        success_count += 1
                        total_size_mb += size_info / (1024 * 1024)
                        st.success(f"âœ… '{result_team_name}' PDF ìƒì„± ì™„ë£Œ ({size_info/1024:.1f}KB)")
                    else:
                        error_count += 1
                        st.error(f"âŒ '{result_team_name}': {size_info}")

                except Exception as e:
                    error_count += 1
                    st.error(f"âŒ '{team_name}' ë³‘ë ¬ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {str(e)}")

        # ë°°ì¹˜ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
        current_memory = psutil.virtual_memory().percent
        if current_memory > 80:
            st.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {current_memory:.1f}% - ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰")
            gc.collect()

    # ìµœì¢… ê²°ê³¼ í‘œì‹œ
    final_memory = psutil.virtual_memory().used / (1024**3)
    memory_used = final_memory - initial_memory

    progress_bar.progress(1.0)
    status_text.text("âœ… ëª¨ë“  ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")

    # ì„±ëŠ¥ ìš”ì•½ ì •ë³´
    st.success(f"""
    ğŸ“Š **PDF ë³‘ë ¬ ìƒì„± ì™„ë£Œ**
    - âœ… ì„±ê³µ: {success_count}ê°œ
    - âŒ ì‹¤íŒ¨: {error_count}ê°œ
    - ğŸ“ ì´ í¬ê¸°: {total_size_mb:.1f}MB
    - ğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_used:+.1f}GB
    - âš¡ ì›Œì»¤ ìˆ˜: {max_workers}ê°œ
    """)

    return pdf_results


def create_zip_from_pdfs(pdf_results: dict, organization_name: str = "ì¡°ì§") -> bytes:
    """
    ì—¬ëŸ¬ PDFë¥¼ ZIP íŒŒì¼ë¡œ ì••ì¶•í•œë‹¤.

    Args:
        pdf_results: {team_name: pdf_bytes} ë”•ì…”ë„ˆë¦¬
        organization_name: ì¡°ì§ëª…

    Returns:
        ZIP íŒŒì¼ì˜ ë°”ì´íŠ¸ ë°ì´í„°
    """
    zip_buffer = io.BytesIO()

    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for team_name, pdf_bytes in pdf_results.items():
            # íŒŒì¼ëª… ìƒì„±: {íŒ€ëª…}_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨.pdf
            safe_team_name = team_name.replace("/", "_").replace("\\", "_")
            filename = f"{safe_team_name}_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨.pdf"

            zip_file.writestr(filename, pdf_bytes)

    zip_buffer.seek(0)
    return zip_buffer.getvalue()


def create_group_zip_from_company_zips(company_zip_data: dict, group_name: str = "ê·¸ë£¹") -> bytes:
    """
    ì—¬ëŸ¬ íšŒì‚¬ì˜ ZIP íŒŒì¼ì„ ê·¸ë£¹ ë‹¨ìœ„ë¡œ ë¬¶ì–´ì„œ ìƒìœ„ ZIPì„ ìƒì„±í•œë‹¤.

    Args:
        company_zip_data: {company_name: zip_bytes} ë”•ì…”ë„ˆë¦¬
        group_name: ê·¸ë£¹ëª…

    Returns:
        ê·¸ë£¹ ZIP íŒŒì¼ì˜ ë°”ì´íŠ¸ ë°ì´í„°
    """
    zip_buffer = io.BytesIO()

    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for company_name, zip_bytes in company_zip_data.items():
            # íšŒì‚¬ë³„ í´ë” êµ¬ì¡° ìƒì„±: {ê·¸ë£¹ëª…}/{íšŒì‚¬ëª…}/
            safe_company_name = company_name.replace("/", "_").replace("\\", "_")
            company_folder = f"{safe_company_name}/"

            # íšŒì‚¬ ZIP íŒŒì¼ëª… ìƒì„±
            zip_filename = f"{company_folder}{safe_company_name}_ì „ì²´íŒ€_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨_{datetime.now().strftime('%Y%m%d')}.zip"
            zip_file.writestr(zip_filename, zip_bytes)

            # README íŒŒì¼ ì¶”ê°€ (íšŒì‚¬ë³„ ìš”ì•½ ì •ë³´)
            readme_content = f"""
# {company_name} ì¡°ì§íš¨ê³¼ì„± ì§„ë‹¨ ë¦¬í¬íŠ¸

ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
í¬í•¨ íŒŒì¼: {safe_company_name}_ì „ì²´íŒ€_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨_{datetime.now().strftime('%Y%m%d')}.zip

## íŒŒì¼ êµ¬ì¡°
- ê° íŒ€ë³„ ê°œë³„ PDF íŒŒì¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤
- íŒŒì¼ëª… í˜•ì‹: {{íŒ€ëª…}}_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨.pdf

## ì‚¬ìš© ë°©ë²•
1. ZIP íŒŒì¼ì„ ì••ì¶• í•´ì œí•˜ì„¸ìš”
2. ê° íŒ€ë³„ PDF íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”
3. í•„ìš”ì‹œ ê°œë³„ì ìœ¼ë¡œ ê³µìœ í•˜ê±°ë‚˜ ì¸ì‡„í•˜ì„¸ìš”
            """.strip()

            readme_filename = f"{company_folder}README_{safe_company_name}.txt"
            zip_file.writestr(readme_filename, readme_content.encode('utf-8'))

    zip_buffer.seek(0)
    return zip_buffer.getvalue()


def send_email_with_attachment(
    to_emails: list,
    subject: str,
    body: str,
    attachment_data: bytes,
    attachment_filename: str,
    sender_email: str = None,
    sender_password: str = None,
    smtp_server: str = "smtp.gmail.com",
    smtp_port: int = 587,
    max_retries: int = 3
) -> dict:
    """
    ì²¨ë¶€íŒŒì¼ê³¼ í•¨ê»˜ ì´ë©”ì¼ì„ ë°œì†¡í•œë‹¤.

    Args:
        to_emails: ë°›ëŠ” ì‚¬ëŒ ì´ë©”ì¼ ì£¼ì†Œ ë¦¬ìŠ¤íŠ¸
        subject: ì´ë©”ì¼ ì œëª©
        body: ì´ë©”ì¼ ë³¸ë¬¸
        attachment_data: ì²¨ë¶€íŒŒì¼ ë°”ì´íŠ¸ ë°ì´í„°
        attachment_filename: ì²¨ë¶€íŒŒì¼ëª…
        sender_email: ë°œì†¡ì ì´ë©”ì¼ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
        sender_password: ë°œì†¡ì ë¹„ë°€ë²ˆí˜¸ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
        smtp_server: SMTP ì„œë²„ ì£¼ì†Œ
        smtp_port: SMTP í¬íŠ¸

    Returns:
        {"success": bool, "message": str, "sent_to": list}
    """
    try:
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì´ë©”ì¼ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        if not sender_email:
            sender_email = os.getenv("SMTP_EMAIL")
        if not sender_password:
            sender_password = os.getenv("SMTP_PASSWORD")

        if not sender_email or not sender_password:
            return {
                "success": False,
                "message": "SMTP_EMAIL ë° SMTP_PASSWORD í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "sent_to": []
            }

        # ì´ë©”ì¼ ë©”ì‹œì§€ ìƒì„±
        msg = MIMEMultipart()
        msg['From'] = sender_email
        msg['Subject'] = subject

        # ë³¸ë¬¸ ì¶”ê°€
        msg.attach(MIMEText(body, 'plain', 'utf-8'))

        # ì²¨ë¶€íŒŒì¼ ì¶”ê°€
        attachment = MIMEBase('application', 'octet-stream')
        attachment.set_payload(attachment_data)
        encoders.encode_base64(attachment)
        attachment.add_header(
            'Content-Disposition',
            f'attachment; filename="{attachment_filename}"'
        )
        msg.attach(attachment)

        # SMTP ì„œë²„ ì—°ê²° ë° ì´ë©”ì¼ ë°œì†¡
        sent_to = []
        failed_to = []

        # ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ SMTP ì—°ê²°
        last_error = None

        for attempt in range(max_retries):
            try:
                # ì—°ê²° ì‹œë„ - ë” ê¸´ íƒ€ì„ì•„ì›ƒê³¼ ë‹¤ì–‘í•œ ì„¤ì • ì‹œë„
                timeouts = [60, 90, 120]  # ë” ê¸´ íƒ€ì„ì•„ì›ƒ ê°’ë“¤
                timeout = timeouts[attempt % len(timeouts)]

                # ì²« ë²ˆì§¸ ì‹œë„: SMTP with STARTTLS
                # ë‘ ë²ˆì§¸ ì‹œë„: SMTP_SSL
                # ì„¸ ë²ˆì§¸ ì‹œë„: ë‹¤ë¥¸ í¬íŠ¸ë¡œ SMTP_SSL
                if attempt == 0:
                    server = smtplib.SMTP(smtp_server, smtp_port, timeout=timeout)
                    server.set_debuglevel(0)
                    server.starttls()
                elif attempt == 1:
                    # Gmail SMTP_SSL í¬íŠ¸ 465 ì‚¬ìš©
                    server = smtplib.SMTP_SSL(smtp_server, 465, timeout=timeout)
                    server.set_debuglevel(0)
                else:
                    # ë§ˆì§€ë§‰ ì‹œë„: ë‹¤ë¥¸ Gmail ì„œë²„ ì„¤ì •
                    server = smtplib.SMTP_SSL("smtp.gmail.com", 465, timeout=timeout)
                    server.set_debuglevel(0)

                try:
                    server.login(sender_email, sender_password)
                except smtplib.SMTPAuthenticationError as e:
                    server.quit()
                    return {
                        "success": False,
                        "message": f"Gmail ì¸ì¦ ì‹¤íŒ¨: {str(e)}. ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.",
                        "sent_to": []
                    }
                except Exception as e:
                    try:
                        server.quit()
                    except:
                        pass
                    last_error = f"SMTP ì„œë²„ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}"
                    if attempt < max_retries - 1:
                        import time
                        time.sleep(3 ** attempt)  # ë” ê¸´ ì§€ìˆ˜ ë°±ì˜¤í”„ (3ì´ˆ, 9ì´ˆ, 27ì´ˆ)
                        continue
                    else:
                        return {
                            "success": False,
                            "message": last_error,
                            "sent_to": []
                        }

                # ì´ë©”ì¼ ë°œì†¡
                for email in to_emails:
                    try:
                        msg['To'] = email
                        server.sendmail(sender_email, email, msg.as_string())
                        sent_to.append(email)
                        del msg['To']  # ë‹¤ìŒ ì´ë©”ì¼ì„ ìœ„í•´ To í—¤ë” ì œê±°
                    except Exception as e:
                        failed_to.append({"email": email, "error": str(e)})

                # ì—°ê²° ì¢…ë£Œ
                server.quit()
                break  # ì„±ê³µí•˜ë©´ ì¬ì‹œë„ ë£¨í”„ ì¢…ë£Œ

            except Exception as e:
                last_error = f"SMTP ì„œë²„ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}"
                if attempt < max_retries - 1:
                    import time
                    time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    continue
                else:
                    return {
                        "success": False,
                        "message": last_error,
                        "sent_to": []
                    }

        # ì´ë©”ì¼ ë°œì†¡ ë¡œê·¸ ì €ì¥
        try:
            from database_models import get_session, EmailLog
            import json
            from datetime import datetime

            session = get_session()

            email_log = EmailLog(
                recipient_emails=json.dumps(to_emails),
                subject=subject,
                attachment_filename=attachment_filename,
                attachment_size=len(attachment_data) if attachment_data else 0,
                status='sent' if len(sent_to) > 0 else 'failed',
                sent_count=len(sent_to),
                failed_count=len(failed_to),
                error_message=str(failed_to) if failed_to else None,
                sent_at=datetime.now() if len(sent_to) > 0 else None
            )

            session.add(email_log)
            session.commit()
            session.close()
        except Exception as log_error:
            print(f"ì´ë©”ì¼ ë¡œê·¸ ì €ì¥ ì˜¤ë¥˜: {log_error}")

        if sent_to:
            return {
                "success": True,
                "message": f"ì´ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. (ì„±ê³µ: {len(sent_to)}, ì‹¤íŒ¨: {len(failed_to)})",
                "sent_to": sent_to,
                "failed_to": failed_to
            }
        else:
            return {
                "success": False,
                "message": "ëª¨ë“  ì´ë©”ì¼ ë°œì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "sent_to": [],
                "failed_to": failed_to
            }

    except Exception as e:
        return {
            "success": False,
            "message": f"ì´ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            "sent_to": []
        }


def get_organization_name_from_reports(reports: dict) -> str:
    """
    ë¦¬í¬íŠ¸ì—ì„œ ì¡°ì§ëª…ì„ ì¶”ì¶œí•œë‹¤.
    """
    if not reports:
        return "ì¡°ì§"

    first_report = next(iter(reports.values()))
    org_name = first_report.get("organization_name", "ì¡°ì§")

    # íŒ€ëª…ì´ í¬í•¨ëœ ê²½ìš° ì œê±°
    if " - " in org_name:
        org_name = org_name.split(" - ")[0]

    return org_name


# ================================
# 6.7) ë°°ì¹˜ ë©”ì¼ ë°œì†¡ ê¸°ëŠ¥
# ================================
def send_multiple_reports_email(gmail_address: str, app_password: str, reports_mapping: dict,
                               subject_template: str = "[ìë™ë°œì†¡] {team_name} ì¡°ì§ íš¨ê³¼ì„± ì§„ë‹¨ ë¦¬í¬íŠ¸",
                               body_template: str = None) -> dict:
    """
    ì—¬ëŸ¬ íŒ€ ë¦¬í¬íŠ¸ë¥¼ ê°ê°ì˜ ë‹´ë‹¹ìì—ê²Œ ì´ë©”ì¼ë¡œ ë°œì†¡í•œë‹¤.

    Args:
        gmail_address: ë°œì†¡ì Gmail ì£¼ì†Œ
        app_password: Gmail ì•± ë¹„ë°€ë²ˆí˜¸
        reports_mapping: {team_name: {"email": "recipient@email.com", "pdf_bytes": pdf_data}} í˜•íƒœ
        subject_template: ì œëª© í…œí”Œë¦¿ ({team_name} ì¹˜í™˜)
        body_template: ë³¸ë¬¸ í…œí”Œë¦¿

    Returns:
        {team_name: {"success": bool, "message": str}} í˜•íƒœì˜ ê²°ê³¼
    """
    if body_template is None:
        body_template = """ì•ˆë…•í•˜ì„¸ìš”.

{team_name} íŒ€ì˜ ì¡°ì§ íš¨ê³¼ì„± ì§„ë‹¨ ë¦¬í¬íŠ¸ë¥¼ ì²¨ë¶€ë“œë¦½ë‹ˆë‹¤.

ë¦¬í¬íŠ¸ ë‚´ìš©:
- íŒ€ë³„ ì¡°ì§ íš¨ê³¼ì„± ë¶„ì„ ê²°ê³¼
- IPO(Input-Process-Output) ê´€ì  ì§„ë‹¨
- ê°œì„  ë°©í–¥ ì œì‹œ

ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ì—°ë½ ì£¼ì„¸ìš”.

â€» ë³¸ ë©”ì¼ì€ ì‹œìŠ¤í…œì—ì„œ ìë™ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤."""

    results = {}

    for team_name, team_data in reports_mapping.items():
        try:
            recipient_email = team_data.get("email")
            pdf_bytes = team_data.get("pdf_bytes")

            if not recipient_email or not pdf_bytes:
                results[team_name] = {
                    "success": False,
                    "message": "ì´ë©”ì¼ ì£¼ì†Œ ë˜ëŠ” PDF ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                }
                continue

            # ì œëª©ê³¼ ë³¸ë¬¸ì— íŒ€ëª… ì¹˜í™˜
            subject = subject_template.format(team_name=team_name)
            body = body_template.format(team_name=team_name)

            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M')
            filename = f"{team_name}_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨_{timestamp}.pdf"

            # ë©”ì¼ ë°œì†¡
            send_gmail_with_attachment(
                gmail_address=gmail_address,
                app_password=app_password,
                recipient=recipient_email,
                subject=subject,
                body=body,
                attachment_bytes=pdf_bytes,
                attachment_name=filename
            )

            results[team_name] = {
                "success": True,
                "message": f"ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë¨: {recipient_email}"
            }

        except Exception as e:
            results[team_name] = {
                "success": False,
                "message": f"ë°œì†¡ ì‹¤íŒ¨: {str(e)}"
            }

    return results


def send_batch_emails_with_reports(reports: dict, email_mapping: dict, gmail_address: str,
                                   gmail_password: str, subject: str, body: str,
                                   send_as_zip: bool = False, zip_recipient: str = None) -> int:
    """
    ì—¬ëŸ¬ ë¦¬í¬íŠ¸ë¥¼ ê°œë³„ ë˜ëŠ” ZIPìœ¼ë¡œ ì´ë©”ì¼ ë°œì†¡í•œë‹¤.

    Args:
        reports: {team_name: report_data} ë”•ì…”ë„ˆë¦¬
        email_mapping: {team_name: email_address} ë”•ì…”ë„ˆë¦¬
        gmail_address: ë°œì†¡ì Gmail ì£¼ì†Œ
        gmail_password: Gmail ì•± ë¹„ë°€ë²ˆí˜¸
        subject: ì´ë©”ì¼ ì œëª©
        body: ì´ë©”ì¼ ë³¸ë¬¸
        send_as_zip: ZIP íŒŒì¼ë¡œ ì „ì†¡ ì—¬ë¶€
        zip_recipient: ZIP íŒŒì¼ ìˆ˜ì‹ ì (send_as_zip=Trueì¸ ê²½ìš°)

    Returns:
        ì„±ê³µí•œ ì´ë©”ì¼ ë°œì†¡ ìˆ˜
    """
    import zipfile
    import io

    if send_as_zip and zip_recipient:
        # ZIP íŒŒì¼ë¡œ ëª¨ë“  PDFë¥¼ í•˜ë‚˜ë¡œ ë¬¶ì–´ì„œ ë°œì†¡
        try:
            # ëª¨ë“  íŒ€ì˜ PDF ìƒì„±
            pdf_results = generate_multiple_pdfs(reports)

            if not pdf_results:
                raise Exception("PDF ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            # ZIP íŒŒì¼ ìƒì„±
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                for team_name, pdf_bytes in pdf_results.items():
                    safe_team_name = team_name.replace("/", "_").replace("\\", "_")
                    filename = f"{safe_team_name}_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨.pdf"
                    zip_file.writestr(filename, pdf_bytes)

            zip_data = zip_buffer.getvalue()
            org_name = get_organization_name_from_reports(reports)
            zip_filename = f"{org_name}_ì „ì²´íŒ€_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨.zip"

            # ZIP íŒŒì¼ ì´ë©”ì¼ ë°œì†¡
            result = send_email_with_attachment(
                to_emails=[zip_recipient],
                subject=f"[ì¼ê´„ë°œì†¡] {org_name} ì¡°ì§íš¨ê³¼ì„± ì§„ë‹¨ ë¦¬í¬íŠ¸ ({len(reports)}ê°œ íŒ€)",
                body=f"{body}\n\nì´ {len(reports)}ê°œ íŒ€ì˜ ë¦¬í¬íŠ¸ê°€ ZIP íŒŒì¼ë¡œ ì²¨ë¶€ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                attachment_data=zip_data,
                attachment_filename=zip_filename,
                sender_email=gmail_address,
                sender_password=gmail_password
            )

            return 1 if result["success"] else 0

        except Exception as e:
            print(f"ZIP íŒŒì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"ZIP íŒŒì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    else:
        # ê°œë³„ ë°œì†¡
        success_count = 0

        for team_name, report in reports.items():
            if team_name not in email_mapping:
                continue

            recipient_email = email_mapping[team_name]

            try:
                # ê°œë³„ PDF ìƒì„±
                single_report = {team_name: report}
                pdf_result = generate_multiple_pdfs(single_report)

                if team_name not in pdf_result:
                    continue

                pdf_bytes = pdf_result[team_name]
                safe_team_name = team_name.replace("/", "_").replace("\\", "_")
                filename = f"{safe_team_name}_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨.pdf"

                # ê°œë³„ ì´ë©”ì¼ ë°œì†¡
                result = send_email_with_attachment(
                    to_emails=[recipient_email],
                    subject=subject.replace("{team_name}", team_name),
                    body=body.replace("{team_name}", team_name),
                    attachment_data=pdf_bytes,
                    attachment_filename=filename,
                    sender_email=gmail_address,
                    sender_password=gmail_password
                )

                if result["success"]:
                    success_count += 1

            except Exception as e:
                print(f"'{team_name}' ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {str(e)}")
                continue

        return success_count


def create_email_mapping_ui(teams: list) -> dict:
    """
    íŒ€ë³„ ì´ë©”ì¼ ë§¤í•‘ì„ ìœ„í•œ UIë¥¼ ìƒì„±í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.

    Args:
        teams: íŒ€ëª… ë¦¬ìŠ¤íŠ¸

    Returns:
        {team_name: email_address} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    st.markdown("##### ğŸ“§ íŒ€ë³„ ë‹´ë‹¹ì ì´ë©”ì¼ ì„¤ì •")

    # ì´ë©”ì¼ ì…ë ¥ ë°©ì‹ ì„ íƒ
    input_method = st.radio(
        "ì´ë©”ì¼ ì…ë ¥ ë°©ì‹",
        ["ê°œë³„ ì…ë ¥", "íŒŒì¼ ì—…ë¡œë“œ"],
        horizontal=True,
        help="ê°œë³„ ì…ë ¥: ê° íŒ€ë³„ë¡œ ì§ì ‘ ì…ë ¥ | íŒŒì¼ ì—…ë¡œë“œ: CSV/Excel íŒŒì¼ë¡œ ì¼ê´„ ì—…ë¡œë“œ"
    )

    email_mapping = {}

    if input_method == "íŒŒì¼ ì—…ë¡œë“œ":
        # CSV/Excel íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹
        st.markdown("**ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹**")

        with st.expander("ğŸ“ íŒŒì¼ í˜•ì‹ ì•ˆë‚´", expanded=False):
            st.markdown("""
            **CSV/Excel íŒŒì¼ í˜•ì‹:**
            - ì²« ë²ˆì§¸ ì»¬ëŸ¼: íŒ€ëª… (ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨)
            - ë‘ ë²ˆì§¸ ì»¬ëŸ¼: ì´ë©”ì¼ ì£¼ì†Œ

            **ì˜ˆì‹œ:**
            ```
            íŒ€ëª…,ì´ë©”ì¼
            ì˜ì—…íŒ€,sales@company.com
            ë§ˆì¼€íŒ…íŒ€,marketing@company.com
            ê°œë°œíŒ€,dev@company.com
            ```
            """)

        uploaded_file = st.file_uploader(
            "ì´ë©”ì¼ ë§¤í•‘ íŒŒì¼ ì—…ë¡œë“œ",
            type=['csv', 'xlsx', 'xls'],
            help="íŒ€ëª…ê³¼ ì´ë©”ì¼ì´ í¬í•¨ëœ CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )

        if uploaded_file is not None:
            try:
                # íŒŒì¼ ì½ê¸°
                if uploaded_file.name.endswith('.csv'):
                    email_df = pd.read_csv(uploaded_file, encoding='utf-8')
                else:
                    email_df = pd.read_excel(uploaded_file)

                # ì»¬ëŸ¼ëª… ì •ë¦¬
                email_df.columns = email_df.columns.str.strip()

                # ì²« 2ê°œ ì»¬ëŸ¼ ì‚¬ìš© (íŒ€ëª…, ì´ë©”ì¼)
                if len(email_df.columns) >= 2:
                    team_col = email_df.columns[0]
                    email_col = email_df.columns[1]

                    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                    st.markdown("**ğŸ“‹ ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:**")
                    st.dataframe(email_df[[team_col, email_col]], use_container_width=True)

                    # ë§¤í•‘ ì²˜ë¦¬
                    matched_teams = []
                    unmatched_teams = []

                    for _, row in email_df.iterrows():
                        team_name = str(row[team_col]).strip()
                        email_addr = str(row[email_col]).strip()

                        if team_name in teams and "@" in email_addr:
                            email_mapping[team_name] = email_addr
                            matched_teams.append(team_name)
                        else:
                            if team_name not in teams:
                                unmatched_teams.append(team_name)

                    # ë§¤í•‘ ê²°ê³¼ í‘œì‹œ
                    if matched_teams:
                        st.success(f"âœ… {len(matched_teams)}ê°œ íŒ€ ë§¤í•‘ ì™„ë£Œ: {', '.join(matched_teams)}")

                    if unmatched_teams:
                        st.warning(f"âš ï¸ ë§¤ì¹­ë˜ì§€ ì•Šì€ íŒ€: {', '.join(unmatched_teams)}")

                    # ëˆ„ë½ëœ íŒ€ í‘œì‹œ
                    missing_teams = [team for team in teams if team not in email_mapping]
                    if missing_teams:
                        st.error(f"âŒ ì´ë©”ì¼ì´ ì„¤ì •ë˜ì§€ ì•Šì€ íŒ€: {', '.join(missing_teams)}")

                else:
                    st.error("íŒŒì¼ì— ìµœì†Œ 2ê°œì˜ ì»¬ëŸ¼(íŒ€ëª…, ì´ë©”ì¼)ì´ í•„ìš”í•©ë‹ˆë‹¤.")

            except Exception as e:
                st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    else:
        # ê°œë³„ ì…ë ¥ ë°©ì‹ (ê¸°ì¡´ ë°©ì‹)
        st.markdown("**âœï¸ ê°œë³„ ì…ë ¥ ë°©ì‹**")

        # ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í‘œì‹œ
        num_cols = min(2, len(teams))  # ìµœëŒ€ 2ì»¬ëŸ¼
        cols = st.columns(num_cols)

        for i, team_name in enumerate(teams):
            col_idx = i % num_cols

            with cols[col_idx]:
                email = st.text_input(
                    f"ğŸ¢ {team_name}",
                    key=f"email_{team_name}",
                    placeholder="ë‹´ë‹¹ì@íšŒì‚¬.com",
                    help=f"{team_name} íŒ€ ë¦¬í¬íŠ¸ë¥¼ ë°›ì„ ë‹´ë‹¹ì ì´ë©”ì¼"
                )

                if email and "@" in email:
                    email_mapping[team_name] = email

    return email_mapping


# ================================
# 7) ë¦¬í¬íŠ¸ ë¹Œë”
# ================================
def build_report(df: pd.DataFrame, index_df: pd.DataFrame) -> dict:
    LIKERT_MAP = {
        "ë§¤ìš° ê·¸ë ‡ì§€ ì•Šë‹¤": 1, "ì „í˜€ ê·¸ë ‡ì§€ ì•Šë‹¤": 1, "ë§¤ìš°ê·¸ë ‡ì§€ì•Šë‹¤": 1,
        "ê·¸ë ‡ì§€ ì•Šë‹¤": 2, "ê·¸ë ‡ì§€ì•Šë‹¤": 2,
        "ë³´í†µì´ë‹¤": 3, "ë³´í†µ": 3,
        "ê·¸ë ‡ë‹¤": 4,
        "ë§¤ìš° ê·¸ë ‡ë‹¤": 5, "ë§¤ìš°ê·¸ë ‡ë‹¤": 5, "ë§¤ìš° ê·¸ë ‡ë‹¤.": 5,
    }

    def to_num(series: pd.Series) -> pd.Series:
        s = series.astype(str).str.strip().replace(LIKERT_MAP)
        return pd.to_numeric(s, errors="coerce")

    # ì¡°ì§ëª… / ë¶€ì„œëª… ì¶”ì¶œ
    org_name = "ì—…ë¡œë“œ ë°ì´í„°"
    dept_name = None
    for cand in ["ì¡°ì§ëª…", "íšŒì‚¬ëª…", "Org", "Organization"]:
        if cand in df.columns and not df[cand].dropna().empty:
            org_name = str(df[cand].dropna().iloc[0]).strip()
            break
    for cand in ["ë¶€ì„œëª…", "íŒ€ëª…", "Department"]:
        if cand in df.columns and not df[cand].dropna().empty:
            dept_name = str(df[cand].dropna().iloc[0]).strip()
            break

    respondents = len(df)

    idx = index_df.copy()
    idx["ëŒ€ë¶„ë¥˜_clean"] = (
        idx.get("ëŒ€ë¶„ë¥˜", "")
        .astype(str)
        .fillna("")
        .str.strip()
        .str.replace(r"\s+", " ", regex=True)
    )

    def is_objective_column(df_: pd.DataFrame, col: str) -> bool:
        if col not in df_.columns:
            return False
        s = to_num(df_[col]).dropna()
        if s.empty:
            return False
        within = s[(s >= 1) & (s <= 5)]
        return (len(within) / len(s)) >= 0.8

    def _grade(score: float | None) -> str:
        if score is None:
            return "N/A"
        if score >= 3.8:
            return "ìš°ìˆ˜"
        if score >= 3.4:
            return "ì–‘í˜¸"
        if score >= 3.0:
            return "ë³´í†µ"
        return "ê°œì„  í•„ìš”"

    categories = []
    ipo_avgs = {}

    for big in ["Input", "Process", "Output"]:
        mask = idx["ëŒ€ë¶„ë¥˜_clean"].str.contains(big, case=False, na=False)
        qdf = idx[mask].copy()
        if qdf.empty:
            continue

        # ì†Œë¶„ë¥˜ë³„ë¡œ ê·¸ë£¹í•‘
        subcategories = []
        all_scores = []

        # ì†Œë¶„ë¥˜ ê·¸ë£¹ë³„ë¡œ ì²˜ë¦¬
        for sub_category in qdf["ì†Œë¶„ë¥˜"].unique():
            if pd.isna(sub_category):
                continue

            sub_mask = qdf["ì†Œë¶„ë¥˜"] == sub_category
            sub_qdf = qdf[sub_mask].copy()

            sub_items = []
            sub_scores = []

            for _, row in sub_qdf.iterrows():
                col_name = str(row.get("í—¤ë”ëª…", "")).strip()
                q_text = str(row.get("ë¬¸í•­ëª…", col_name)).strip()
                sub_cat = str(row.get("ì†Œë¶„ë¥˜", "")).strip()

                item_avg = None
                item_bm = 0.0
                dist_pcts = {1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0}
                neg_pct = mid_pct = pos_pct = 0.0

                if col_name and col_name in df.columns:
                    num = to_num(df[col_name])
                    valid = num.dropna()
                    if not valid.empty:
                        item_avg = float(valid.mean())
                        bm = max(0.0, min(5.0, item_avg - 0.25))
                        item_bm = round(bm, 2)
                        sub_scores.append(item_avg)
                        all_scores.append(item_avg)

                        total = len(valid)
                        for v in [1, 2, 3, 4, 5]:
                            cnt = int((valid == v).sum())
                            dist_pcts[v] = round(cnt / total * 100, 1) if total > 0 else 0.0

                        neg_pct = round(dist_pcts[1] + dist_pcts[2], 1)
                        mid_pct = round(dist_pcts[3], 1)
                        pos_pct = round(dist_pcts[4] + dist_pcts[5], 1)

                sub_items.append(
                    {
                        "question": q_text,
                        "header": col_name,
                        "subcategory": sub_cat,
                        "average": round(item_avg, 2) if item_avg is not None else None,
                        "benchmark": item_bm,
                        "responses": {
                            "veryLow": dist_pcts[1],
                            "low": dist_pcts[2],
                            "medium": dist_pcts[3],
                            "high": dist_pcts[4],
                            "veryHigh": dist_pcts[5],
                        },
                        "dist_agg": {
                            "neg_pct": neg_pct,
                            "mid_pct": mid_pct,
                            "pos_pct": pos_pct,
                        },
                    }
                )

            # ì†Œë¶„ë¥˜ í‰ê·  ê³„ì‚°
            sub_avg = round(sum(sub_scores) / len(sub_scores), 2) if sub_scores else None

            # ì†Œë¶„ë¥˜ ê·¸ë£¹ì„ subcategoriesì— ì¶”ê°€
            subcategories.append({
                "name": sub_category,
                "average": sub_avg,
                "items": sub_items,
                "item_count": len(sub_items)
            })

        # ì „ì²´ ì˜ì—­ í‰ê·  ê³„ì‚°
        cat_avg = round(sum(all_scores) / len(all_scores), 2) if all_scores else None
        ipo_avgs[big] = cat_avg

        categories.append(
            {
                "title": big,
                "name": big,
                "description": f"{big} ì˜ì—­ì— ëŒ€í•œ ì‘ë‹µ ê²°ê³¼ì…ë‹ˆë‹¤.",
                "average": cat_avg,
                "subcategories": subcategories,
                "items": [item for subcat in subcategories for item in subcat["items"]],  # í˜¸í™˜ì„±ì„ ìœ„í•´ í‰ë©´í™”ëœ itemsë„ ìœ ì§€
            }
        )

    input_avg = ipo_avgs.get("Input")
    process_avg = ipo_avgs.get("Process")
    output_avg = ipo_avgs.get("Output")

    summary_ipo_cards = [
        {"id": "input", "title": "Input", "score": input_avg, "grade": _grade(input_avg), "desc": "ë¦¬ì†ŒìŠ¤Â·ì—­ëŸ‰Â·ì •ë³´ íˆ¬ì… ìˆ˜ì¤€"},
        {"id": "process", "title": "Process", "score": process_avg, "grade": _grade(process_avg), "desc": "í˜‘ì—…Â·ì˜ì‚¬ì†Œí†µÂ·ë¦¬ë”ì‹­ ì‹¤í–‰"},
        {"id": "output", "title": "Output", "score": output_avg, "grade": _grade(output_avg), "desc": "ì„±ê³¼Â·ëª°ì…Â·ë¬¸í™” ì¸ì‹"},
    ]

    # -------------------------------
    #  ë¬¸í•­ ë‹¨ìœ„ ì ìˆ˜ ë¶„í¬ (ì°¨íŠ¸ìš©)
    #  â†’ Input / Process / Output ë³„ë¡œ êµ¬ê°„ ì •ë³´ë„ ê°™ì´ ë§Œë“ ë‹¤
    # -------------------------------
    line_labels = []
    our_scores = []
    benchmark_scores = []

    # ì˜ì—­ë³„ ì¸ë±ìŠ¤ ëª¨ìœ¼ê¸°
    area_index_map = {"Input": [], "Process": [], "Output": []}

    for _, row in idx.iterrows():
        col_name = str(row.get("í—¤ë”ëª…", "")).strip()
        label = str(row.get("ë¬¸í•­ëª…", col_name)).strip()
        if not label or not col_name or col_name not in df.columns:
            continue
        if not is_objective_column(df, col_name):
            continue

        num = to_num(df[col_name]).dropna()
        if num.empty:
            continue

        avg = float(num.mean())
        bm = max(0.0, min(5.0, avg - 0.25))

        # ì‹¤ì œë¡œ ì°¨íŠ¸ì— ë“¤ì–´ê°€ëŠ” ìœ„ì¹˜
        current_index = len(line_labels)

        line_labels.append(label)
        our_scores.append(round(avg, 2))
        benchmark_scores.append(round(bm, 2))

        # ì´ ë¬¸í•­ì´ ì–´ë–¤ IPO ì˜ì—­ì¸ì§€ ë¶™ì—¬ë‘ê¸°
        big_area = str(row.get("ëŒ€ë¶„ë¥˜_clean", "")).strip().lower()
        if "input" in big_area:
            area_index_map["Input"].append(current_index)
        elif "process" in big_area:
            area_index_map["Process"].append(current_index)
        elif "output" in big_area:
            area_index_map["Output"].append(current_index)

    # Chart.jsì—ì„œ ê·¸ë¦´ ìˆ˜ ìˆë„ë¡ êµ¬ê°„ì„ from/to ë¡œ ë³€í™˜
    segments = []
    for area_name, idx_list in area_index_map.items():
        if not idx_list:
            continue
        segments.append(
            {
                "name": area_name,
                "from": min(idx_list),
                "to": max(idx_list),
            }
        )

    summary_score_distribution = {
        "title": "ì§„ë‹¨ ì˜ì—­/í•­ëª©ë³„ ì ìˆ˜ ë¶„í¬",
        "labels": line_labels,
        "series": [
            {"name": "ë²¤ì¹˜ë§ˆí¬", "data": benchmark_scores, "style": "dashed"},
            {"name": "ìš°ë¦¬ ì¡°ì§", "data": our_scores, "style": "solid"},
        ],
        # Chart ì˜µì…˜ì—ì„œ ì“¸ ìˆ˜ ìˆë„ë¡ í•¨ê»˜ ë„˜ê¸´ë‹¤
        "segments": segments,
    }


    # íšŒì‚¬ë‹¨ìœ„ ì—¬ë¶€ íŒë‹¨ (ë¶€ì„œ/íŒ€ ì •ë³´ë¡œ ì—¬ëŸ¬ ê·¸ë£¹ì´ ìˆê±°ë‚˜ ì‘ë‹µìê°€ 10ëª… ì´ìƒì´ë©´ íšŒì‚¬ë‹¨ìœ„)
    team_columns = [col for col in df.columns if any(keyword in col.upper() for keyword in ['POS', 'DEPT', 'TEAM', 'ë¶€ì„œ', 'íŒ€'])]
    has_multiple_teams = len(team_columns) > 0 and len(df[team_columns[0]].dropna().unique()) > 1 if team_columns else False
    is_company_level = has_multiple_teams or len(df) >= 10  # ì—¬ëŸ¬ íŒ€ì´ ìˆê±°ë‚˜ ì‘ë‹µìê°€ 10ëª… ì´ìƒì´ë©´ íšŒì‚¬ë‹¨ìœ„

    # ì£¼ê´€ì‹ ì‘ë‹µì„ reference indexì— ë”°ë¼ êµ¬ì¡°í™”
    open_ended = build_structured_open_ended(df, is_company_level)

    summary = {
        "intro": "ë³¸ ë¦¬í¬íŠ¸ëŠ” ìµœê·¼ ì„¤ë¬¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¡°ì§ íš¨ê³¼ì„±ì„ IPO ê´€ì ì—ì„œ ì§„ë‹¨í•œ ê²°ê³¼ì…ë‹ˆë‹¤.",
        "sub_intro": "Inputâ€“Processâ€“Output 3ê°œ ì˜ì—­ì„ í‘œì¤€ í…œí”Œë¦¿ìœ¼ë¡œ ì‹œê°í™”í–ˆìŠµë‹ˆë‹¤.",
        "respondents": respondents,
        "response_rate": 100.0,
        "method": "5ì  ì²™ë„ ë¬¸í•­ í‰ê·  + index.xlsx êµ¬ì¡° ë°˜ì˜",
        "ipo": {
            "input": round(input_avg, 2) if input_avg is not None else None,
            "process": round(process_avg, 2) if process_avg is not None else None,
            "output": round(output_avg, 2) if output_avg is not None else None,
        },
        "ipo_cards": summary_ipo_cards,
        "score_distribution": summary_score_distribution,
        "improvement_priorities": [
            "ì ìˆ˜ê°€ ë‚®ì€ Input ì„¸ë¶€í•­ëª©ì„ 1ìˆœìœ„ë¡œ ê°œì„ ",
            "Process ì˜ì—­ ì¤‘ í˜‘ì—…Â·ì˜ì‚¬ì†Œí†µ í•­ëª©ì€ ì œë„í™” í•„ìš”",
            "Output ì˜ì—­ì—ì„œ ë°˜ë³µ ì–¸ê¸‰ëœ ì´ìŠˆëŠ” ë¦¬ë”ì‹­ ë¯¸íŒ… ì•ˆê±´í™”",
        ],
    }

    overview = {
        "purpose": "ë³¸ ë¦¬í¬íŠ¸ëŠ” ì¡°ì§íš¨ê³¼ì„±ì„ ë¹ ë¥´ê²Œ íŒŒì•…í•˜ê³  ê°œì„  í¬ì¸íŠ¸ë¥¼ ë„ì¶œí•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "background": [],
        "model_desc": "",
        "model_points": [],
    }

    return {
        "org_name": org_name,
        "organization_name": org_name,  # í…œí”Œë¦¿ í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
        "dept_name": dept_name,
        "report_date": datetime.now().strftime("%Y.%m.%d"),
        "respondents": respondents,
        "summary": summary,
        "overview": overview,
        "diagnostic": {"categories": categories},
        "open_ended": open_ended,
        "appendix": {
            "methodology": "index.xlsx ê¸°ì¤€ ë¬¸í•­ì„ 5ì  ì²™ë„ë¡œ ì§‘ê³„í•˜ê³ , ëŒ€ë¶„ë¥˜(IPO) í‰ê· ì„ ì‚°ì¶œí–ˆìŠµë‹ˆë‹¤.",
            "scoring_guide": "4.0 ì´ìƒ ìš°ìˆ˜, 3.4~3.9 ì–‘í˜¸, 3.0~3.3 ë³´í†µ, 3.0 ë¯¸ë§Œ ê°œì„  í•„ìš”ë¡œ í•´ì„í•©ë‹ˆë‹¤.",
        },
    }


# ================================
# 7) AI í•´ì„ ìºì‹œ ê´€ë¦¬ í•¨ìˆ˜ë“¤
# ================================
def get_cached_ai_analysis(org_name: str, data_hash: str) -> dict | None:
    """ì €ì¥ëœ AI ë¶„ì„ ê²°ê³¼ë¥¼ ì¡°íšŒ"""
    try:
        from database_models import get_session, Report
        import json
        import hashlib

        session = get_session()

        # ì¡°ì§ëª…ê³¼ ë°ì´í„° í•´ì‹œë¡œ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        existing_report = session.query(Report).filter_by(
            team_name=org_name,
            status='completed'
        ).first()

        if existing_report and existing_report.ai_analysis:
            stored_analysis = json.loads(existing_report.ai_analysis)
            # ë°ì´í„° í•´ì‹œê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            if stored_analysis.get('data_hash') == data_hash:
                return stored_analysis

        session.close()
        return None

    except Exception as e:
        print(f"AI ë¶„ì„ ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None

def save_ai_analysis(org_name: str, data_hash: str, ai_result: dict, report_data: dict = None):
    """AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        from database_models import get_session, Report, Organization
        import json

        session = get_session()

        # ì¡°ì§ ì¡°íšŒ ë˜ëŠ” ìƒì„±
        org = session.query(Organization).filter_by(name=org_name).first()
        if not org:
            org = Organization(name=org_name)
            session.add(org)
            session.flush()

        # ê¸°ì¡´ ë¦¬í¬íŠ¸ ì¡°íšŒ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
        report = session.query(Report).filter_by(
            organization_id=org.id,
            team_name=org_name
        ).first()

        if not report:
            report = Report(
                organization_id=org.id,
                team_name=org_name,
                report_type='organizational_effectiveness'
            )
            session.add(report)

        # AI ë¶„ì„ ê²°ê³¼ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
        ai_result['data_hash'] = data_hash
        ai_result['generated_at'] = datetime.now().isoformat()
        ai_result['org_name'] = org_name

        # ì €ì¥
        report.ai_analysis = json.dumps(ai_result, ensure_ascii=False)
        if report_data:
            report.report_data = json.dumps(report_data, ensure_ascii=False)
        report.status = 'completed'
        report.updated_at = datetime.now()

        session.commit()
        session.close()

        print(f"âœ… AI ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {org_name}")

    except Exception as e:
        print(f"AI ë¶„ì„ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")

def generate_data_hash(report: dict) -> str:
    """ë¦¬í¬íŠ¸ ë°ì´í„°ì˜ í•´ì‹œê°’ ìƒì„± (ìºì‹œ í‚¤ë¡œ ì‚¬ìš©)"""
    import hashlib
    import json

    # í•µì‹¬ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ í•´ì‹œ ìƒì„±
    key_data = {
        'org_name': report.get('org_name', ''),
        'respondents': report.get('respondents', 0),
        'summary': report.get('summary', {}),
        'open_ended': report.get('open_ended', {}),
        'diagnostic': report.get('diagnostic', {})
    }

    data_str = json.dumps(key_data, sort_keys=True, ensure_ascii=False)
    return hashlib.md5(data_str.encode()).hexdigest()

# 7) Gemini í•´ì„ (ì§„í–‰ ì½œë°±) - ìºì‹œ ê¸°ëŠ¥ ì¶”ê°€
# ================================
def run_ai_interpretation_gemini_from_report(report: dict, progress_update=None, force_regenerate=False) -> dict:
    """
    report -> (score / items / free_text / org_context / writer / reviewer / final)
    reviewerê°€ ë­”ê°€ë¥¼ ë‚¨ê¸°ë©´ ê·¸ê²Œ ìµœì¢…ì´ê³ , ì—†ìœ¼ë©´ writerê°€ ìµœì¢…ì´ë‹¤.
    """
    def step(i: int, msg: str):
        if callable(progress_update):
            progress_update(i, msg)

    # -------------------------------------------------
    # 0) ê³µí†µ ë°ì´í„° êº¼ë‚´ê¸° ë° ìºì‹œ í™•ì¸
    # -------------------------------------------------
    org_name = report.get("org_name") or "ì´ë¦„ ì—†ëŠ” ì¡°ì§"
    respondents = report.get("respondents") or 0
    summary = report.get("summary") or {}
    ipo = summary.get("ipo") or {}
    categories = (report.get("diagnostic") or {}).get("categories") or []
    open_ended = report.get("open_ended") or []

    # ë°ì´í„° í•´ì‹œ ìƒì„±
    data_hash = generate_data_hash(report)

    # ê°•ì œ ì¬ìƒì„±ì´ ì•„ë‹Œ ê²½ìš° ìºì‹œëœ ê²°ê³¼ í™•ì¸
    if not force_regenerate:
        step(0, "ê¸°ì¡´ AI ë¶„ì„ ê²°ê³¼ í™•ì¸ ì¤‘...")
        cached_result = get_cached_ai_analysis(org_name, data_hash)
        if cached_result:
            step(100, "ì €ì¥ëœ AI ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤")
            return cached_result

    # -------------------------------------------------
    # 1) IPO ì ìˆ˜ í•´ì„
    # -------------------------------------------------
    step(1, "IPO ì ìˆ˜ í•´ì„ ì¤‘...")
    loaded_score_prompt = load_prompt_file("gemini_score_ko.md")
    if loaded_score_prompt:
        # íŒŒì¼ì´ ìˆìœ¼ë©´ ê±°ê¸°ì— ì•ˆì „í•˜ê²Œ ë°ì´í„°ë§Œ ë§ë¶™ì¸ë‹¤
        base_score_prompt = (
            f"{loaded_score_prompt.rstrip()}\n\n"
            "[ë°ì´í„°]\n"
            f"ì¡°ì§ëª…: {org_name}\n"
            f"ì‘ë‹µììˆ˜: {respondents}\n"
            f"IPO ì ìˆ˜: {json.dumps(ipo, ensure_ascii=False)}"
        )
    else:
        # íŒŒì¼ ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        base_score_prompt = f"""{PROMPT_PREFIX}

[ì‘ì—…]
- ì•„ë˜ IPO ì ìˆ˜ë¥¼ ë³´ê³ , ì–´ëŠ ì˜ì—­ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ê³  ë‚®ì€ì§€ ì„¤ëª…í•˜ë¼.
- ì‘ë‹µìê°€ 30ëª… ë¯¸ë§Œì´ë©´ 'ì‹ ë¢°ë„ ì£¼ì˜' ë¬¸ì¥ì„ ë°˜ë“œì‹œ ì¶”ê°€í•˜ë¼.

[ë°ì´í„°]
ì¡°ì§ëª…: {org_name}
ì‘ë‹µììˆ˜: {respondents}
IPO ì ìˆ˜: {json.dumps(ipo, ensure_ascii=False)}
""".strip()

    score_result = call_gemini(base_score_prompt)

    # -------------------------------------------------
    # 2) ë¬¸í•­ë³„ ë‚®ì€ ë¬¸í•­
    #    â†’ ì—¬ê¸°ê°€ ì´ë²ˆì— ë¬¸ì œì˜€ë˜ ë¶€ë¶„
    # -------------------------------------------------
    step(2, "ë¬¸í•­ë³„ ê°œì„  í•­ëª© ì¶”ì¶œ ì¤‘...")

    # ì‹¤ì œ categories ë°ì´í„°ë¥¼ í¬í•¨í•œ í˜ì´ë¡œë“œ ìƒì„±
    item_payload = {
        "org_name": org_name,
        "respondents": respondents,
        "ipo": ipo,
        "categories": categories,  # ì‹¤ì œ ë¬¸í•­ êµ¬ì¡°ê°€ ì—¬ê¸° ë“¤ì–´ê°
    }

    loaded_item_prompt = load_prompt_file("gemini_item_ko.md")
    if loaded_item_prompt:
        if "<<<DATA>>>" in loaded_item_prompt:
            # ëª…ì‹œì  ìë¦¬í‘œì‹œìê°€ ìˆìœ¼ë©´ ì¹˜í™˜
            base_item_prompt = loaded_item_prompt.replace(
                "<<<DATA>>>",
                json.dumps(item_payload, ensure_ascii=False, indent=2)
            )
        else:
            # ìë¦¬í‘œì‹œìê°€ ì—†ìœ¼ë©´ JSONì„ ë°˜ë“œì‹œ ë’¤ì— ë¶™ì„
            base_item_prompt = (
                f"{loaded_item_prompt.rstrip()}\n\n"
                "[ë°ì´í„°]\n"
                f"{json.dumps(item_payload, ensure_ascii=False, indent=2)}"
            )
    else:
        # í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì•„ì˜ˆ ì—†ì„ ë•Œë§Œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        base_item_prompt = f"""{PROMPT_PREFIX}

[ì‘ì—…]
- ì•„ë˜ categories ì•ˆì—ì„œ 3.0 ë¯¸ë§Œì´ê±°ë‚˜ ì˜ì—­ í‰ê· ë³´ë‹¤ 0.3p ì´ìƒ ë‚®ì€ ë¬¸í•­ì„ ì°¾ì•„ë¼.
- í—¤ë”ëª…ì´ ì›ì‹œê°’ì´ë©´ 'NEED_CONFIRMATION: ì›ë³¸í—¤ë”ëª…'ìœ¼ë¡œ ë‚¨ê²¨ë¼.
- ê²°ê³¼ëŠ” ë²ˆí˜¸ ëª©ë¡ìœ¼ë¡œë§Œ ì¨ë¼.

[ë°ì´í„°]
{json.dumps(item_payload, ensure_ascii=False, indent=2)}
""".strip()

    item_result = call_gemini(base_item_prompt)

    # -------------------------------------------------
    # 3) ì£¼ê´€ì‹ ë©”íƒ€
    # -------------------------------------------------
    step(3, "ì£¼ê´€ì‹ ì‘ë‹µ ìš”ì•½ ì¤‘...")

    free_payload = {
        "org_name": org_name,
        "respondents": respondents,
        "open_ended": open_ended,
    }

    loaded_free_prompt = load_prompt_file("gemini_free_ko.md")
    if loaded_free_prompt:
        if "<<<DATA>>>" in loaded_free_prompt:
            base_free_prompt = loaded_free_prompt.replace(
                "<<<DATA>>>",
                json.dumps(free_payload, ensure_ascii=False)
            )
        else:
            base_free_prompt = (
                f"{loaded_free_prompt.rstrip()}\n\n"
                "[ì£¼ê´€ì‹]\n"
                f"{json.dumps(open_ended, ensure_ascii=False)}"
            )
    else:
        base_free_prompt = f"""{PROMPT_PREFIX}

[ì‘ì—…]
- ì£¼ê´€ì‹ ì‘ë‹µì—ì„œ ì¡°ì§ ê·œëª¨/í˜„ì¥ ì´ìŠˆ/ë¦¬ë”ì‹­ ì´ìŠˆ/ì¤‘ë³µ ë¶ˆë§Œì„ ë½‘ì•„ì„œ ì„¤ëª…í•˜ë¼.
- ê°œì¸ì •ë³´ë‚˜ íŠ¹ì •ì¸ì„ ìœ ì¶”í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì€ 'ì‹ë³„ì •ë³´ ì œê±° í•„ìš”'ë¡œ ë‚¨ê²¨ë¼.

[ì£¼ê´€ì‹]
{json.dumps(open_ended, ensure_ascii=False)}
""".strip()

    free_result = call_gemini(base_free_prompt)

    # -------------------------------------------------
    # 4) ì¡°ì§ ì»¨í…ìŠ¤íŠ¸ (NO40, ì¡°ì§ëª…, ì—…ì¢… ì¶”ì •)
    # -------------------------------------------------
    step(4, "ì¡°ì§ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ ì¤‘...")

    no40_text = _extract_no40_from_open(open_ended)
    industry_guess = _guess_industry_from_name(org_name)

    orgctx_payload = {
        "org_name": org_name,
        "industry_guess": industry_guess,
        "respondents": respondents,
        "no40_text": no40_text,
    }

    loaded_orgctx_prompt = load_prompt_file("gemini_orgctx_ko.md")
    if loaded_orgctx_prompt:
        # placeholder ìˆìœ¼ë©´ ì¹˜í™˜
        base_orgctx_prompt = loaded_orgctx_prompt
        base_orgctx_prompt = base_orgctx_prompt.replace("<<<ORG_NAME>>>", org_name)
        base_orgctx_prompt = base_orgctx_prompt.replace("<<<INDUSTRY>>>", industry_guess)
        base_orgctx_prompt = base_orgctx_prompt.replace("<<<RESPONDENTS>>>", str(respondents))
        base_orgctx_prompt = base_orgctx_prompt.replace("<<<NO40>>>", no40_text)
        # í˜¹ì‹œ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë’¤ì— ë¶™ì´ê¸°
        if "<<<ORG_NAME>>>" not in loaded_orgctx_prompt and "<<<NO40>>>" not in loaded_orgctx_prompt:
            base_orgctx_prompt = (
                f"{loaded_orgctx_prompt.rstrip()}\n\n"
                f"[ì¡°ì§ì •ë³´]\n- ì¡°ì§ëª…: {org_name}\n- ì¶”ì • ì‚°ì—…/ì§ë¬´: {industry_guess}\n- ì‘ë‹µììˆ˜: {respondents}\n\n"
                f"[NO40(ì¡°ì§íŠ¹ì„±) ì‘ë‹µ]\n{no40_text}"
            )
    else:
        base_orgctx_prompt = f"""{PROMPT_PREFIX}

# ì—­í• 
- ë‹¹ì‹ ì€ ì¡°ì§ì§„ë‹¨ ê²°ê³¼ë¥¼ í•´ì„í•  ë•Œ ì°¸ê³ í•  â€˜ì¡°ì§ì  ë§¥ë½â€™ë§Œ ì‘ì„±í•˜ëŠ” HR ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
- ì ìˆ˜, ì§€í‘œ, ì˜ì—­(InputÂ·ProcessÂ·Output) ë“±ì€ ì–¸ê¸‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì¡°ì§ëª…ê³¼ ì£¼ê´€ì‹ NO40(ì¡°ì§íŠ¹ì„±) ì‘ë‹µë§Œ ê·¼ê±°ë¡œ ì„œìˆ í•©ë‹ˆë‹¤.

# ì‘ì„± ê·œì¹™
- 3~5ë¬¸ì¥ í•˜ë‚˜ì˜ ë‹¨ë½.
- ë¶ˆë¦¿, í‘œ, ì½”ë“œë¸”ë¡ ê¸ˆì§€.
- â€œì´ ì¡°ì§ì€ â€¦í•œ í™˜ê²½ì´ë¯€ë¡œ ì´ëŸ° ì‘ë‹µì´ ë‚˜ì˜¬ ìˆ˜ ìˆë‹¤â€ ìˆ˜ì¤€ì˜ ë§¥ë½ë§Œ ì”ë‹ˆë‹¤.
- ì‘ë‹µììˆ˜ê°€ 30ëª… ë¯¸ë§Œì´ë©´ ë§ˆì§€ë§‰ì— ìœ ì˜ë¬¸ ì¶”ê°€.

[ì¡°ì§ì •ë³´]
- ì¡°ì§ëª…: {org_name}
- ì¶”ì • ì‚°ì—…/ì§ë¬´: {industry_guess}
- ì‘ë‹µììˆ˜: {respondents}

[NO40(ì¡°ì§íŠ¹ì„±) ì‘ë‹µ]
{no40_text}
""".strip()

    orgctx_result = call_gemini(base_orgctx_prompt)

    # -------------------------------------------------
    # 5) ì„ì›ìš”ì•½ (ì‹¤ì œ ì¨ë¨¹ì„ ë³¸ë¬¸)
    # -------------------------------------------------
    step(5, "ì„ì›ìš© ìš”ì•½ ì‘ì„± ì¤‘...")

    writer_payload = {
        "score_analysis": _clean_ai_text(score_result),
        "low_items": _clean_ai_text(item_result),
        "free_text": _clean_ai_text(free_result),
        "org_context": _clean_ai_text(orgctx_result),
    }

    loaded_writer_prompt = load_prompt_file("gemini_writer_ko.md")
    if loaded_writer_prompt:
        if "<<<SCORE>>>" in loaded_writer_prompt:
            base_writer_prompt = (
                loaded_writer_prompt
                .replace("<<<SCORE>>>", writer_payload["score_analysis"])
                .replace("<<<ITEMS>>>", writer_payload["low_items"])
                .replace("<<<FREE>>>", writer_payload["free_text"])
                .replace("<<<ORGCTX>>>", writer_payload["org_context"])
            )
        else:
            base_writer_prompt = (
                f"{loaded_writer_prompt.rstrip()}\n\n"
                "[ì°¸ê³ 1: ì ìˆ˜ í•´ì„]\n"
                f"{writer_payload['score_analysis']}\n\n"
                "[ì°¸ê³ 2: ë‚®ì€ ë¬¸í•­]\n"
                f"{writer_payload['low_items']}\n\n"
                "[ì°¸ê³ 3: ì£¼ê´€ì‹(ì¡°ì§ ë©”íƒ€)]\n"
                f"{writer_payload['free_text']}\n\n"
                "[ì°¸ê³ 4: ì¡°ì§ ì»¨í…ìŠ¤íŠ¸]\n"
                f"{writer_payload['org_context']}"
            )
    else:
        base_writer_prompt = f"""{PROMPT_PREFIX}

[ì‘ì—…]
- ì§€ê¸ˆê¹Œì§€ ìƒì„±ëœ 4ê°œ ê²°ê³¼ë¥¼ í•©ì³ì„œ ì„ì›ìš© ìš”ì•½ì„ 1~1.5p ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±í•˜ë¼.
- êµ¬ì¡°ëŠ” ë°˜ë“œì‹œ Input â†’ Process â†’ Output ìˆœì„œë¥¼ ì§€ì¼œë¼.
- í‘œë‚˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ëŠ” ë§Œë“¤ì§€ ë§ê³  ìì—°ì–´ ì„œìˆ ë¡œ ì“´ë‹¤.
- 'ì´ëŠ”', 'ì´ë²ˆ'ê³¼ ê°™ì€ í‘œí˜„ì€ ì¤„ì—¬ë¼.

[ì°¸ê³ 1: ì ìˆ˜ í•´ì„]
{writer_payload['score_analysis']}

[ì°¸ê³ 2: ë‚®ì€ ë¬¸í•­]
{writer_payload['low_items']}

[ì°¸ê³ 3: ì£¼ê´€ì‹(ì¡°ì§ ë©”íƒ€)]
{writer_payload['free_text']}

[ì°¸ê³ 4: ì¡°ì§ ì»¨í…ìŠ¤íŠ¸]
{writer_payload['org_context']}
""".strip()

    writer_result = call_gemini(base_writer_prompt)

    # -------------------------------------------------
    # 6) ë¦¬ë·°ì–´(ê²€ì—´)
    # -------------------------------------------------
    step(6, "AI ì‚°ì¶œë¬¼ ì ê²€ ì¤‘...")

    loaded_reviewer_prompt = load_prompt_file("gemini_reviewer_ko.md")
    if loaded_reviewer_prompt:
        base_reviewer_prompt = (
            f"{loaded_reviewer_prompt.rstrip()}\n\n"
            "[ì„ì›ìš”ì•½]\n"
            f"{writer_result}"
        )
    else:
        base_reviewer_prompt = f"""{PROMPT_PREFIX}

[ì‘ì—…]
- ì•„ë˜ ì„ì›ìš”ì•½ì´ ì› ë°ì´í„°ì— ì—†ëŠ” ìˆ«ì/ì¡°ì§ëª…/ë‚ ì§œë¥¼ ë§Œë“¤ì—ˆëŠ”ì§€ë§Œ ì ê²€í•˜ë¼.
- ë¬¸ì œ ìˆìœ¼ë©´ 'ìˆ˜ì¹˜ ê²€ì¦ í•„ìš”', 'ì‹ë³„ì •ë³´ ì œê±° í•„ìš”'ë§Œ ì¨ë¼.
- ë³´ê³ ì„œì— ê·¸ëŒ€ë¡œ ë…¸ì¶œë˜ë©´ ì•ˆ ë˜ëŠ” í‘œí˜„ì€ 'ë‚´ë¶€ ê²€ì—´ìš©'ì´ë¼ê³  ëª…ì‹œí•˜ë¼.
- ì—¬ê¸°ì„œëŠ” ìƒˆë¡œìš´ ë³¸ë¬¸ì„ ë‹¤ì‹œ ì“°ì§€ ì•ŠëŠ”ë‹¤.

[ì„ì›ìš”ì•½]
{writer_result}
""".strip()

    reviewer_result = call_gemini(base_reviewer_prompt)

    step(7, "ì™„ë£Œ")

    # -------------------------------------------------
    # 7) ê²°ê³¼ ì •ë¦¬
    # -------------------------------------------------
    # reviewerê°€ ìˆìœ¼ë©´ reviewer, ì—†ìœ¼ë©´ writer
    final_result = (reviewer_result or "").strip() or (writer_result or "").strip()

    # ë¬¸í•­ë³„ ë¹„ì–´ ìˆìœ¼ë©´ ìµœì†Œ ì•ˆë‚´ë¬¸
    items_clean = _clean_ai_text(item_result)
    if not items_clean.strip():
        items_clean = (
            "â€¢ (ìë™ ìƒì„± ì‹¤íŒ¨) ì ìˆ˜ê°€ 3.0 ë¯¸ë§Œì´ê±°ë‚˜ IPO í‰ê· ë³´ë‹¤ 0.3p ì´ìƒ ë‚®ì€ ë¬¸í•­ì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.\n"
            "â€¢ index.xlsxì˜ ëŒ€ë¶„ë¥˜/í—¤ë”ëª…ì´ ì„¤ë¬¸ ê²°ê³¼ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ì ê²€í•˜ì„¸ìš”."
        )

    # AI ë¶„ì„ ê²°ê³¼ êµ¬ì„±
    ai_analysis_result = {
        "score": _clean_ai_text(score_result),
        "items": items_clean,
        "free_text": _clean_ai_text(free_result),
        "org_context": _clean_ai_text(orgctx_result),
        "writer": _clean_ai_text(writer_result),
        "reviewer": _clean_ai_text(reviewer_result),
        "final": _clean_ai_text(final_result),
    }

    # AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    try:
        save_ai_analysis(org_name, data_hash, ai_analysis_result, report)
    except Exception as e:
        print(f"AI ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    return ai_analysis_result

# ================================
# 8) HTML ë Œë”
# ================================
def render_web_html(report: dict, ai_result: dict | None = None) -> str:
    """
    report.html ì´ reviewer ì²´í¬ë¦¬ìŠ¤íŠ¸ê¹Œì§€ ê·¸ëŒ€ë¡œ ë¿Œë¦¬ëŠ” ë¬¸ì œë¥¼ ë§‰ê¸° ìœ„í•´
    ì—¬ê¸°ì„œ í•œ ë²ˆ ì •ë¦¬í•´ì„œ ë„˜ê²¨ì¤€ë‹¤.
    """
    env = Environment(
        loader=FileSystemLoader(str(TEMPLATE_DIR)),
        autoescape=select_autoescape(["html", "xml"]),
    )
    css_path = BASE_DIR / "static" / "css" / "report.css"
    inline_css = css_path.read_text(encoding="utf-8") if css_path.exists() else ""

    # í•­ìƒ ì•ˆì „í•œ AI ê°ì²´ ë³´ì¥
    cleaned_ai = {}
    if ai_result:
        cleaned_ai = {
            "score": ai_result.get("score", ""),
            "items": ai_result.get("items", ""),
            "free_text": ai_result.get("free_text", ""),  # ì£¼ê´€ì‹ ë¶„ì„ì„ ë³„ë„ë¡œ í¬í•¨
            "org_context": ai_result.get("org_context") or ai_result.get("free_text", "") or "",
            "writer": ai_result.get("writer") or ai_result.get("final") or "",
            "reviewer": "",  # ë¬¸ì„œì— ë¦¬ë·°ì–´ ë…¸ì¶œ ì•ˆí•¨
        }

    # í•­ìƒ report.summary.aiì— ì•ˆì „í•œ AI ê°ì²´ ì£¼ì…
    report.setdefault("summary", {})
    if "summary" not in report:
        report["summary"] = {}
    report["summary"]["ai"] = cleaned_ai

    tmpl = env.get_template("report.html")
    html = tmpl.render(
        report=report,
        inline_css=inline_css,
        ai_result=cleaned_ai,  # ì •ë¦¬ëœ ë²„ì „ ì „ë‹¬
        use_tailwind=True,
    )
    return html


# ================================
# 9) Gmail ì „ì†¡
# ================================
def send_gmail_with_attachment(
    gmail_address: str,
    app_password: str,
    recipient: str,
    subject: str,
    body: str,
    attachment_bytes: bytes,
    attachment_name: str = "report.pdf",
):
    smtp_host = "smtp.gmail.com"
    smtp_port = 587

    msg = MIMEMultipart()
    msg["From"] = gmail_address
    msg["To"] = recipient
    msg["Subject"] = subject

    msg.attach(MIMEText(body, "plain", "utf-8"))

    part = MIMEBase("application", "octet-stream")
    part.set_payload(attachment_bytes)
    encoders.encode_base64(part)
    part.add_header("Content-Disposition", f'attachment; filename="{attachment_name}"')
    msg.attach(part)

    # ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ SMTP ì—°ê²°
    for attempt in range(3):
        try:
            # ì—°ê²° ì‹œë„ - ë” ê¸´ íƒ€ì„ì•„ì›ƒê³¼ ë‹¤ì–‘í•œ ì„¤ì • ì‹œë„
            timeouts = [30, 45, 60]
            timeout = timeouts[attempt % len(timeouts)]

            server = smtplib.SMTP(smtp_host, smtp_port, timeout=timeout)
            server.set_debuglevel(0)  # ë””ë²„ê·¸ ë¡œê·¸ ë¹„í™œì„±í™”

            try:
                server.starttls()
                server.login(gmail_address, app_password)
                server.send_message(msg)
                server.quit()
                return  # ì„±ê³µí•˜ë©´ í•¨ìˆ˜ ì¢…ë£Œ
            finally:
                try:
                    server.quit()
                except:
                    pass

        except Exception as e:
            if attempt < 2:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´
                import time
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                continue
            else:
                # SMTP_SSLë¡œ ì‹œë„í•´ë³´ê¸°
                try:
                    server = smtplib.SMTP_SSL(smtp_host, 465, timeout=30)
                    server.login(gmail_address, app_password)
                    server.send_message(msg)
                    server.quit()
                    return
                except Exception as ssl_e:
                    raise Exception(f"SMTP ì„œë²„ ì—°ê²° ì‹¤íŒ¨ (SMTP/SMTP_SSL ëª¨ë‘ ì‹¤íŒ¨): ì›ë³¸ ì˜¤ë¥˜: {str(e)}, SSL ì˜¤ë¥˜: {str(ssl_e)}")
        
# ================================================
# ë²¤ì¹˜ë§ˆí¬ ì„¤ì • ê´€ë ¨ í—¬í¼ í•¨ìˆ˜
# ================================================
def get_benchmark_scores_for_labels(labels):
    """ê´€ë¦¬ì ì„¤ì •ì—ì„œ ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ë¥¼ ê°€ì ¸ì™€ì„œ labels ìˆœì„œì— ë§ê²Œ ë°˜í™˜"""
    import streamlit as st

    # ê¸°ë³¸ ë²¤ì¹˜ë§ˆí¬ ê°’ë“¤
    default_benchmarks = {
        "ëª©ì ê²½ì˜": 3.2,
        "êµ¬ì„±ì›ì¸ì‹": 3.1,
        "ì§€ì›ì²´ê³„": 3.0,
        "ë„ì „ì¶”ì§„": 3.3,
        "ì‹¤í–‰ë ¥": 3.4,
        "ì†Œí†µí˜‘ë ¥": 3.2,
        "ì„±ê³¼ì°½ì¶œ": 3.5,
        "êµ¬ì„±ì›ë§Œì¡±": 3.1,
        "ê²½ìŸë ¥í™•ë³´": 3.3
    }

    # ì„¸ì…˜ì—ì„œ ë²¤ì¹˜ë§ˆí¬ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    benchmark_settings = st.session_state.get("benchmark_settings", default_benchmarks)

    # labels ìˆœì„œì— ë§ì¶° ì ìˆ˜ ë°°ì—´ ìƒì„±
    benchmark_scores = []
    for label in labels:
        score = benchmark_settings.get(label)
        if score is not None:
            benchmark_scores.append(float(score))
        else:
            # ë ˆì´ë¸”ì´ ì„¤ì •ì— ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 3.2 ì‚¬ìš©
            benchmark_scores.append(3.2)

    return benchmark_scores

# ================================================
# ì ìˆ˜ ë¶„í¬(ì°¨íŠ¸)ìš© êµ¬ì¡°ë¥¼ reportì— ë¶™ì—¬ì£¼ëŠ” í—¬í¼
# ================================================
def attach_score_distribution(
    report: dict,
    df: pd.DataFrame | None = None,
    index_df: pd.DataFrame | None = None,
) -> dict:
    """
    - ë¨¼ì € build_report ê°€ ë§Œë“¤ì–´ì¤€ ë¶„í¬(report.summary.score_distribution)ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ 'ê¸°ë³¸ê°’'ìœ¼ë¡œ ë‘”ë‹¤.
    - df ì—ì„œ ì˜ì—­/ì ìˆ˜ë¥¼ ë½‘ì„ ìˆ˜ ìˆì„ ë•Œë§Œ ë®ì–´ì“´ë‹¤.
    - í…œí”Œë¦¿ì—ì„œ ì“°ëŠ” dist.segments ë„ ì—¬ê¸°ì„œ ë§Œë“¤ì–´ì„œ ë‚´ë ¤ì¤€ë‹¤.
    """
    if report is None:
        report = {}
    report.setdefault("summary", {})

    # 0) build_report ê°€ ì´ë¯¸ ë„£ì–´ì¤€ ê°’ ê¸°ì–µ
    existing_dist = report["summary"].get("score_distribution")

    # 1) df ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ê°’ ê·¸ëŒ€ë¡œ
    if df is None or df.empty:
        if existing_dist:
            return report
        report["summary"]["score_distribution"] = {
            "title": "ì§„ë‹¨ ì˜ì—­/í•­ëª©ë³„ ì ìˆ˜ ë¶„í¬",
            "labels": [],
            "series": [
                {"name": "benchmark", "data": []},
                {"name": "our", "data": []},
            ],
            "segments": [],
        }
        return report

    # 2) df ì—ì„œ ì˜ì—­/ì ìˆ˜ë¥¼ ì¶”ë¡ í•´ ë³¸ë‹¤
    cols = df.columns.tolist()
    area_col = None
    for c in ["ì˜ì—­", "ëŒ€ì˜ì—­", "factor", "domain", "section"]:
        if c in cols:
            area_col = c
            break

    score_col = None
    for c in ["ì ìˆ˜", "score", "value", "avg_score"]:
        if c in cols:
            score_col = c
            break

    # 2-1) ëª»ì°¾ìœ¼ë©´ ê¸°ì¡´ ë¶„í¬ ìœ ì§€
    if area_col is None or score_col is None:
        if existing_dist:
            # ê¸°ì¡´ ê²ƒë§Œ segments ë³´ê°•
            existing_dist.setdefault("segments", [])
            report["summary"]["score_distribution"] = existing_dist
            return report
        # ê¸°ì¡´ ê²ƒë„ ì—†ìœ¼ë©´ ìµœì†Œ êµ¬ì¡°
        report["summary"]["score_distribution"] = {
            "title": "ì§„ë‹¨ ì˜ì—­/í•­ëª©ë³„ ì ìˆ˜ ë¶„í¬",
            "labels": [],
            "series": [
                {"name": "benchmark", "data": []},
                {"name": "our", "data": []},
            ],
            "segments": [],
        }
        return report

    # 3) ì—¬ê¸°ê¹Œì§€ ì™”ìœ¼ë©´ df ê¸°ë°˜ìœ¼ë¡œ ì°¨íŠ¸ ìƒì„±
    area_grp = df.groupby(area_col)[score_col].mean().round(2)
    labels = area_grp.index.tolist()
    our_scores = area_grp.values.tolist()

    # ë²¤ì¹˜ë§ˆí¬ ìˆìœ¼ë©´
    if "benchmark" in cols:
        bench_grp = df.groupby(area_col)["benchmark"].mean().round(2)
        benchmark_scores = [float(bench_grp.get(lbl, 0)) for lbl in labels]
    else:
        # ê´€ë¦¬ì ì„¤ì •ì—ì„œ ë²¤ì¹˜ë§ˆí¬ ê°€ì ¸ì˜¤ê¸°
        benchmark_scores = get_benchmark_scores_for_labels(labels)
        if not benchmark_scores:
            benchmark_scores = [max(s - 0.2, 0) for s in our_scores]

    # 4) segments ê³„ì‚° (Input / Process / Output 3ë“±ë¶„)
    segments: list[dict] = []
    if index_df is not None and not index_df.empty:
        # index.xlsx ë¥¼ í†µí•´ ë¬¸í•­ ìˆœì„œì™€ ëŒ€ë¶„ë¥˜ë¥¼ ì•Œ ìˆ˜ ìˆì„ ë•Œ
        idx = index_df.copy()
        idx["ëŒ€ë¶„ë¥˜_clean"] = (
            idx.get("ëŒ€ë¶„ë¥˜", "")
            .astype(str)
            .str.strip()
            .str.replace(r"\s+", " ", regex=True)
        )
        # labels ìˆœì„œë¥¼ ê¸°ì¤€ìœ¼ë¡œ from/to ê³„ì‚°
        def _seg_bounds(seg_name: str):
            start = None
            end = None
            for i, lbl in enumerate(labels):
                # lbl ì´ index_df ì˜ ë¬¸í•­ëª…ê³¼ 1:1 ì¼ì¹˜í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë‹ˆ contains ë¡œ
                match_rows = idx[idx["ë¬¸í•­ëª…"].astype(str).str.contains(lbl, na=False)]
                if not match_rows.empty:
                    big = match_rows.iloc[0]["ëŒ€ë¶„ë¥˜_clean"]
                    if seg_name.lower() in big.lower():
                        if start is None:
                            start = i
                        end = i
            return start, end

        for name in ["Input", "Process", "Output"]:
            s, e = _seg_bounds(name)
            if s is not None and e is not None:
                segments.append({"name": name, "from": s, "to": e})
    else:
        # index_dfë„ ì—†ìœ¼ë©´ 3êµ¬ê°„ìœ¼ë¡œ ê· ë“± ë¶„í• 
        n = len(labels)
        if n > 0:
            one = max(n // 3, 1)
            segments = [
                {"name": "Input", "from": 0, "to": min(one - 1, n - 1)},
                {"name": "Process", "from": one, "to": min(one * 2 - 1, n - 1)},
                {"name": "Output", "from": one * 2, "to": n - 1},
            ]

    report["summary"]["score_distribution"] = {
        "title": "ì§„ë‹¨ ì˜ì—­/í•­ëª©ë³„ ì ìˆ˜ ë¶„í¬",
        "labels": labels,
        "series": [
            {"name": "ë²¤ì¹˜ë§ˆí¬", "data": benchmark_scores},
            {"name": "ìš°ë¦¬ ì¡°ì§", "data": our_scores},
        ],
        "segments": segments,
    }
    return report

    # 2) ìš°ë¦¬ ì¡°ì§ ì ìˆ˜ ì§‘ê³„
    area_grp = df.groupby(area_col)[score_col].mean().round(2)
    labels = area_grp.index.tolist()
    our_scores = area_grp.values.tolist()

    # 3) ë²¤ì¹˜ë§ˆí¬ ìˆìœ¼ë©´ ë¶™ì´ëŠ” ë¡œì§ (ë²¤ì¹˜ë§ˆí¬ ì»¬ëŸ¼ì´ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ë°©ì–´ì ìœ¼ë¡œ)
    benchmark_scores = []
    if "benchmark" in cols:
        bench_grp = df.groupby(area_col)["benchmark"].mean().round(2)
        # labels ìˆœì„œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        benchmark_scores = [float(bench_grp.get(lbl, 0)) for lbl in labels]
    else:
        # ê´€ë¦¬ì ì„¤ì •ì—ì„œ ë²¤ì¹˜ë§ˆí¬ ê°€ì ¸ì˜¤ê¸°
        benchmark_scores = get_benchmark_scores_for_labels(labels)
        if not benchmark_scores:
            # ì„¤ì •ì´ ì—†ìœ¼ë©´ 0ì´ ì•„ë‹Œ ê·¼ì‚¬ê°’ìœ¼ë¡œ ì±„ì›Œë†“ëŠ” ê²Œ ì°¨íŠ¸ê°€ ëœ ê¹¨ì§
            benchmark_scores = [max(s - 0.2, 0) for s in our_scores]

    report["summary"]["score_distribution"] = {
        "title": "ì§„ë‹¨ ì˜ì—­/í•­ëª©ë³„ ì ìˆ˜ ë¶„í¬",
        "labels": labels,
        "series": [
            {"name": "benchmark", "data": benchmark_scores},
            {"name": "our", "data": our_scores},
        ],
    }
    return report

# ================================
# 10) main
# ================================
def main():
    st.set_page_config(
        page_title="AI ê¸°ë°˜ ë¦¬í¬íŠ¸ ì¶œë ¥ ë° ë©”ì¼ë§ ìë™í™” ì‹œìŠ¤í…œ",
        layout="wide",
        initial_sidebar_state="expanded",
    )
    inject_global_styles()

    # ì„¸ì…˜ ì´ˆê¸°í™”
    if "active_menu" not in st.session_state:
        st.session_state["active_menu"] = "upload"
    if "admin_mode" not in st.session_state:
        st.session_state["admin_mode"] = False
    if "admin_authenticated" not in st.session_state:
        st.session_state["admin_authenticated"] = False
    if "uploaded_df" not in st.session_state:
        st.session_state["uploaded_df"] = None
        st.session_state["data_source"] = None
    if "pdf_bytes" not in st.session_state:
        st.session_state["pdf_bytes"] = None
    if "ai_result" not in st.session_state:
        st.session_state["ai_result"] = None

    # ë©€í‹° ë¦¬í¬íŠ¸ ê´€ë ¨ ì„¸ì…˜ ìƒíƒœ
    if "report_type" not in st.session_state:
        st.session_state["report_type"] = "ì „ì²´"
    if "group_column" not in st.session_state:
        st.session_state["group_column"] = None
    if "reports" not in st.session_state:
        st.session_state["reports"] = {}
    if "selected_team" not in st.session_state:
        st.session_state["selected_team"] = None
    if "grouped_data" not in st.session_state:
        st.session_state["grouped_data"] = {}

    # PDF ê´€ë ¨ ì„¸ì…˜ ìƒíƒœ
    if "pdf_results" not in st.session_state:
        st.session_state["pdf_results"] = {}
    if "zip_bytes" not in st.session_state:
        st.session_state["zip_bytes"] = None

    index_df = load_index()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown('<div class="sb-title">ìˆœì„œëŒ€ë¡œ ì§„í–‰í•´ì£¼ì„¸ìš”!</div>', unsafe_allow_html=True)

        def sb_item(key: str, label: str, desc: str = ""):
            active = st.session_state["active_menu"] == key
            completed = is_step_completed(key)

            # í´ë˜ìŠ¤ ê²°ì •
            item_class = ""
            if active:
                item_class = "active"
            elif completed:
                item_class = "completed"

            # í´ë¦­ ê°€ëŠ¥í•œ ë²„íŠ¼ìœ¼ë¡œ êµ¬í˜„
            if st.button(f"{get_step_number(key)}. {label}", key=f"menu_{key}", help=desc, width='stretch'):
                st.session_state["active_menu"] = key
                st.rerun()

        def get_step_number(key: str) -> str:
            steps = {"upload": "1", "report": "2", "pdf": "3", "email": "4"}
            return steps.get(key, "")

        def is_step_completed(key: str) -> bool:
            if key == "upload":
                return st.session_state.get("reports") is not None
            elif key == "report":
                # ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°ëŠ” ì‹¤ì œë¡œ ë¯¸ë¦¬ë³´ê¸° í˜ì´ì§€ë¥¼ ë°©ë¬¸í–ˆì„ ë•Œë§Œ ì™„ë£Œë¡œ í‘œì‹œ
                return (st.session_state.get("reports") is not None and
                        st.session_state.get("viewed_report", False))
            elif key == "pdf":
                return st.session_state.get("pdf_bytes") is not None or st.session_state.get("zip_bytes") is not None
            elif key == "email":
                return False  # ì´ë©”ì¼ì€ ì™„ë£Œ ìƒíƒœë¥¼ ë”°ë¡œ ê´€ë¦¬í•˜ì§€ ì•ŠìŒ
            return False

        sb_item("upload", "íŒŒì¼ ì—…ë¡œë“œ & ë¦¬í¬íŠ¸ ìƒì„±", "CSV/Excel íŒŒì¼ ì—…ë¡œë“œ í›„ ë¦¬í¬íŠ¸ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤")
        sb_item("report", "ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°", "ìƒì„±ëœ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        sb_item("pdf", "PDF ìƒì„±", "ë¦¬í¬íŠ¸ë¥¼ PDFë¡œ ì €ì¥í•©ë‹ˆë‹¤")
        sb_item("email", "ì´ë©”ì¼ ë°œì†¡", "ì™„ì„±ëœ ë¦¬í¬íŠ¸ë¥¼ ì´ë©”ì¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤")

        # ê´€ë¦¬ì ëª¨ë“œ ì¸ì¦
        st.markdown("---")

        if not st.session_state["admin_authenticated"]:
            # ê´€ë¦¬ì ë¡œê·¸ì¸
            st.markdown("**ğŸ”§ ê´€ë¦¬ì ëª¨ë“œ**")

            with st.expander("ê´€ë¦¬ì ë¡œê·¸ì¸", expanded=False):
                admin_password = st.text_input(
                    "ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸",
                    type="password",
                    placeholder="ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                    help="ê´€ë¦¬ì ê¸°ëŠ¥ì— ì ‘ê·¼í•˜ë ¤ë©´ ì˜¬ë°”ë¥¸ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
                )

                col1, col2 = st.columns([1, 1])
                with col1:
                    if st.button("ğŸ”“ ë¡œê·¸ì¸", key="admin_login"):
                        if admin_password == ADMIN_PASSWORD:
                            st.session_state["admin_authenticated"] = True
                            st.session_state["admin_mode"] = True
                            st.session_state["active_menu"] = "admin_db"
                            st.success("âœ… ê´€ë¦¬ì ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.cache_data.clear()
                            st.rerun()
                        else:
                            st.error("âŒ ì˜ëª»ëœ ë¹„ë°€ë²ˆí˜¸ì…ë‹ˆë‹¤.")

        else:
            # ê´€ë¦¬ì ë¡œê·¸ì•„ì›ƒ
            st.markdown("**ğŸ”§ ê´€ë¦¬ì ëª¨ë“œ (ì¸ì¦ë¨)**")
            if st.button("ğŸ”’ ë¡œê·¸ì•„ì›ƒ", key="admin_logout"):
                st.session_state["admin_authenticated"] = False
                st.session_state["admin_mode"] = False
                st.session_state["active_menu"] = "upload"
                st.success("ê´€ë¦¬ì ëª¨ë“œì—ì„œ ë¡œê·¸ì•„ì›ƒë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()

        # ê´€ë¦¬ì ë©”ë‰´ í‘œì‹œ
        if st.session_state["admin_authenticated"] and st.session_state["admin_mode"]:
            st.markdown("**ê´€ë¦¬ì ë„êµ¬**")
            sb_item("admin_db", "ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬", "ì¡°ì§, ë¦¬í¬íŠ¸, PDF ìƒì„± ì´ë ¥ ê´€ë¦¬")
            sb_item("admin_benchmark", "ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ì„¤ì •", "ì˜ì—­ë³„ ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ ê´€ë¦¬")
            sb_item("admin_branding", "ğŸ¨ ë¸Œëœë”© ì„¤ì •", "ì¡°ì§ë³„ ë¸Œëœë”© ìƒ‰ìƒ, ë¡œê³  ì„¤ì •")
            sb_item("admin_email", "ğŸ“§ ì´ë©”ì¼ ì´ë ¥", "ì´ë©”ì¼ ë°œì†¡ ë¡œê·¸ ë° í†µê³„ í™•ì¸")

        with st.expander("ì‹œìŠ¤í…œ ì§„ë‹¨", expanded=False):
            st.write("- google-genai ì„¤ì¹˜ ì—¬ë¶€:", _HAS_GENAI)
            st.write("- GOOGLE_API_KEY ì„¤ì • ì—¬ë¶€:", bool(GOOGLE_API_KEY))
            if st.session_state["admin_authenticated"] and st.session_state["admin_mode"]:
                try:
                    import psutil
                    memory = psutil.virtual_memory()
                    st.write(f"- ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {memory.percent:.1f}% ({memory.available/1024**3:.1f}GB ì‚¬ìš©ê°€ëŠ¥)")
                except ImportError:
                    st.write("- ë©”ëª¨ë¦¬ ì •ë³´: psutil ë¯¸ì„¤ì¹˜")

                # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
                try:
                    from database_models import get_session
                    session = get_session()
                    session.close()
                    st.write("- ë°ì´í„°ë² ì´ìŠ¤: âœ… ì—°ê²° ì„±ê³µ")
                except Exception as e:
                    st.write(f"- ë°ì´í„°ë² ì´ìŠ¤: âŒ ì—°ê²° ì‹¤íŒ¨ ({str(e)[:50]}...)")

    # ìƒë‹¨ í—¤ë”
    st.markdown(
        f"""
        <div class="page-header">
            <div class="page-header-title">AI ê¸°ë°˜ ë¦¬í¬íŠ¸ ì¶œë ¥ ë° ë©”ì¼ë§ ìë™í™” ì‹œìŠ¤í…œ</div>
            <div class="page-header-right">{datetime.now().strftime('%Y-%m-%d %H:%M')}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    # ---------- (1) ì—…ë¡œë“œ ----------
    if st.session_state["active_menu"] == "upload":
        st.markdown("##### ê²°ê³¼ íŒŒì¼ ì—…ë¡œë“œ ë° ê²€ì¦")

        st.markdown(
            """
            <div class="guide-card">
                <div class="guide-card-title">ì‚¬ìš© ë°©ë²•</div>
                <div class="guide-card-desc">
                    1) ì§„ë‹¨ ê²°ê³¼ ì—‘ì…€(.xlsx)ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.<br>
                    2) ëˆ„ë½/ì¶”ê°€ ì»¬ëŸ¼ì„ í™•ì¸í•©ë‹ˆë‹¤.<br>
                    3) íŒŒì¼ì´ ì—†ìœ¼ë©´ â€˜ìƒ˜í”Œ ë°ì´í„°ë¡œ ì§„í–‰â€™ì„ ëˆŒëŸ¬ í™”ë©´ì„ ë¨¼ì € í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )

        uploaded = st.file_uploader(
            "ğŸ“Š ì¡°ì§ íš¨ê³¼ì„± ì§„ë‹¨ ê²°ê³¼ íŒŒì¼ ì—…ë¡œë“œ",
            type=["xlsx", "xls", "csv"],
            label_visibility="collapsed",
            help="ì—‘ì…€ íŒŒì¼(.xlsx, .xls) ë˜ëŠ” CSV íŒŒì¼(.csv)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        )

        bc1, bc2, _ = st.columns([0.19, 0.19, 0.62])
        with bc1:
            use_sample = st.button("ìƒ˜í”Œ ë°ì´í„°ë¡œ ì§„í–‰")
        with bc2:
            clear_data = st.button("ë°ì´í„° ì´ˆê¸°í™”")

        if uploaded is not None:
            df, source = load_data(uploaded)
            st.session_state["uploaded_df"] = df
            st.session_state["data_source"] = "uploaded"
            st.session_state["ai_result"] = None
        elif use_sample:
            df, source = load_data(None)
            st.session_state["uploaded_df"] = df
            st.session_state["data_source"] = "sample"
            st.session_state["ai_result"] = None
        elif clear_data:
            st.session_state["uploaded_df"] = None
            st.session_state["data_source"] = None
            st.session_state["ai_result"] = None

        df = st.session_state["uploaded_df"]
        source = st.session_state["data_source"]

        if df is None:
            st.info("ì—…ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì˜¬ë¦¬ê±°ë‚˜ 'ìƒ˜í”Œ ë°ì´í„°ë¡œ ì§„í–‰'ì„ ëˆŒëŸ¬ ì‹œì‘í•˜ì„¸ìš”.")
            return

        # ë°ì´í„°ì—ì„œ ì¡°ì§ëª… ìë™ ì¶”ì¶œ
        detected_org_info = extract_organization_info(df)


        # ê°„ë‹¨í•œ ë¦¬í¬íŠ¸ ìƒì„± ì„¤ì •
        st.subheader("ğŸ“Š ë¦¬í¬íŠ¸ ìƒì„± ì„¤ì •")
        col1, col2 = st.columns(2)
        with col1:
            report_type = st.selectbox(
                "ë¦¬í¬íŠ¸ ìƒì„± ë°©ì‹",
                ["ì „ì²´ ì¡°ì§", "íŒ€ë³„ ë¶„ì„"],
                index=0,
                help="ì „ì²´ ì¡°ì§: í†µí•© ë¦¬í¬íŠ¸ / íŒ€ë³„ ë¶„ì„: ê°œë³„ ë¦¬í¬íŠ¸"
            )

        group_column = None
        with col2:
            if report_type == "íŒ€ë³„ ë¶„ì„":
                possible_columns = [col for col in df.columns if any(keyword in col.upper() for keyword in ['POS', 'DEPT', 'TEAM', 'ë¶€ì„œ', 'íŒ€'])]
                if possible_columns:
                    group_column = st.selectbox(
                        "íŒ€ êµ¬ë¶„ ì»¬ëŸ¼",
                        possible_columns,
                        help="íŒ€ë³„ êµ¬ë¶„ì— ì‚¬ìš©í•  ì»¬ëŸ¼"
                    )

        # ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ì„ ì„ íƒ ì˜ì—­ ë°”ë¡œ ì•„ë˜ì— ë°°ì¹˜
        if st.button("âœ… ë¦¬í¬íŠ¸ ìƒì„±", type="primary", key="main_generate_btn", width='stretch'):
            # ë‚´ë¶€ì ìœ¼ë¡œëŠ” ê¸°ì¡´ "ì „ì²´"/"íŒ€ë³„" í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            internal_report_type = "ì „ì²´" if report_type == "ì „ì²´ ì¡°ì§" else "íŒ€ë³„"

            st.session_state["report_type"] = internal_report_type
            st.session_state["group_column"] = group_column
            st.session_state["detected_org_info"] = detected_org_info

            if internal_report_type == "íŒ€ë³„" and not group_column:
                st.error("íŒ€ë³„ ë¦¬í¬íŠ¸ ìƒì„±ì„ ìœ„í•´ì„œëŠ” ê·¸ë£¹ ê¸°ì¤€ ì»¬ëŸ¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
                return

            with st.spinner("ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
                try:
                    print(f"DEBUG: ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ - íƒ€ì…: {internal_report_type}, ê·¸ë£¹ ì»¬ëŸ¼: {group_column}")

                    # ë°ì´í„° ê·¸ë£¹í•‘
                    grouped_data = group_data_by_unit(df, internal_report_type, group_column)
                    st.session_state["grouped_data"] = grouped_data
                    print(f"DEBUG: ë°ì´í„° ê·¸ë£¹í•‘ ì™„ë£Œ - ê·¸ë£¹ ìˆ˜: {len(grouped_data)}")

                    # ë¦¬í¬íŠ¸ ìƒì„± (ê°ì§€ëœ ì¡°ì§ ì •ë³´ ì „ë‹¬)
                    index_df = load_index()
                    print(f"DEBUG: ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ - í–‰ ìˆ˜: {len(index_df)}")

                    reports = build_multiple_reports(grouped_data, index_df, detected_org_info["company"], detected_org_info["department"])
                    print(f"DEBUG: ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ - ë¦¬í¬íŠ¸ ìˆ˜: {len(reports)}")

                    st.session_state["reports"] = reports
                    st.session_state["active_menu"] = "report"
                    print(f"DEBUG: ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ - active_menu: {st.session_state['active_menu']}")

                    st.success(f"ë¦¬í¬íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ({len(reports)}ê°œ)")
                    print("DEBUG: st.rerun() í˜¸ì¶œ")
                    st.rerun()
                except Exception as e:
                    print(f"ERROR: ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
                    st.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        st.markdown("###### ğŸ“„ ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì‹ë³„ì •ë³´ ë§ˆìŠ¤í‚¹)")
        df_to_show = mask_df_for_preview(df)
        st.dataframe(df_to_show.head(30).astype(str), width="stretch")

        v = validate_df(df, index_df)
        c1, c2 = st.columns(2)
        with c1:
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            st.markdown('<div class="info-card-head">ë°ì´í„° ìƒíƒœ</div>', unsafe_allow_html=True)
            st.markdown('<div class="info-card-body">', unsafe_allow_html=True)
            st.write(f"- ë°ì´í„° ì†ŒìŠ¤: **{source}**")
            st.write(f"- í–‰(Row): **{len(df)}**")
            st.write(f"- ì»¬ëŸ¼(Column): **{len(df.columns)}**")
            st.markdown("</div></div>", unsafe_allow_html=True)
        with c2:
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            st.markdown('<div class="info-card-head">ì»¬ëŸ¼ ê²€ì¦ ê²°ê³¼</div>', unsafe_allow_html=True)
            st.markdown('<div class="info-card-body">', unsafe_allow_html=True)
            st.write(f"- ê¸°ëŒ€ ì»¬ëŸ¼: **{v['expected_count']}ê°œ**")
            st.write(f"- ì‹¤ì œ ì»¬ëŸ¼: **{v['actual_count']}ê°œ**")
            st.write("- ëˆ„ë½ ì»¬ëŸ¼:")
            st.write(v["missing"] if v["missing"] else "ì—†ìŒ")
            st.write("- ì¶”ê°€ ì»¬ëŸ¼:")
            st.write(v["extra"] if v["extra"] else "ì—†ìŒ")
            st.markdown("</div></div>", unsafe_allow_html=True)


    # ---------- (2) ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸° ----------
    elif st.session_state["active_menu"] == "report":
        st.markdown("##### ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°")

        # ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸° í˜ì´ì§€ ë°©ë¬¸ ì‹œ í”Œë˜ê·¸ ì„¤ì •
        st.session_state["viewed_report"] = True

        df = st.session_state["uploaded_df"]
        if df is None:
            st.warning("ë¨¼ì € ì²«ë²ˆì§¸ ë©”ë‰´ì—ì„œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.")
            return

        reports = st.session_state.get("reports", {})
        print(f"DEBUG: ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸° - reports í‚¤ ì¡´ì¬: {'reports' in st.session_state}")
        print(f"DEBUG: ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸° - reports íƒ€ì…: {type(reports)}")
        print(f"DEBUG: ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸° - reports ê¸¸ì´: {len(reports)}")
        print(f"DEBUG: ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸° - reports í‚¤ë“¤: {list(reports.keys()) if reports else 'None'}")
        if not reports:
            st.warning("ë¨¼ì € ì²«ë²ˆì§¸ ë©”ë‰´ì—ì„œ ë¦¬í¬íŠ¸ ì„¤ì •ì„ ì™„ë£Œí•´ ì£¼ì„¸ìš”.")
            return

        # íŒ€ ì„ íƒ UI (ì—¬ëŸ¬ ë¦¬í¬íŠ¸ê°€ ìˆëŠ” ê²½ìš°)
        selected_team = None
        if len(reports) > 1:
            st.markdown("###### ì¡°íšŒí•  ë¦¬í¬íŠ¸ ì„ íƒ")

            # íŒ€ ëª©ë¡ ì •ë ¬ (ê°€ë‚˜ë‹¤ìˆœ)
            team_names = sorted(reports.keys())

            # íŒ€ ì •ë³´ í‘œì‹œ
            team_info = []
            for team_name in team_names:
                team_df = st.session_state["grouped_data"].get(team_name)
                count = len(team_df) if team_df is not None else 0
                team_info.append(f"{team_name} ({count}ëª…)")

            selected_team = st.selectbox(
                "ë¦¬í¬íŠ¸ ì„ íƒ",
                team_names,
                index=team_names.index(st.session_state.get("selected_team", team_names[0])) if st.session_state.get("selected_team") in team_names else 0,
                format_func=lambda x: f"{x} ({len(st.session_state['grouped_data'].get(x, []))}ëª…)",
                help="ë¯¸ë¦¬ë³´ê¸°í•  ë¦¬í¬íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )

            if selected_team != st.session_state.get("selected_team"):
                st.session_state["selected_team"] = selected_team
                # íŒ€ì´ ë°”ë€Œë©´ AI ê²°ê³¼ ì´ˆê¸°í™”
                st.session_state["ai_result"] = None

            st.caption(f"ì´ {len(reports)}ê°œì˜ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            selected_team = list(reports.keys())[0]
            st.session_state["selected_team"] = selected_team

        # ì„ íƒëœ ë¦¬í¬íŠ¸ ê°€ì ¸ì˜¤ê¸°
        report = reports[selected_team]
        selected_df = st.session_state["grouped_data"][selected_team]

        # AI í•´ì„ ë²„íŠ¼ (íŒ€ë³„ë¡œ ê°œë³„ ê´€ë¦¬) - ìºì‹œ ê¸°ëŠ¥ ì¶”ê°€
        ai_key = f"ai_result_{selected_team}"
        if ai_key not in st.session_state:
            st.session_state[ai_key] = None

        # ìºì‹œëœ AI ë¶„ì„ ê²°ê³¼ í™•ì¸
        data_hash = generate_data_hash(report)
        cached_ai_result = get_cached_ai_analysis(selected_team, data_hash)

        top_c1, top_c2, top_c3 = st.columns([0.25, 0.25, 0.25])

        with top_c1:
            if cached_ai_result:
                # ì´ë¯¸ ì €ì¥ëœ AI í•´ì„ì´ ìˆëŠ” ê²½ìš°
                load_cached = st.button(f"ì €ì¥ëœ AI í•´ì„ ë¶ˆëŸ¬ì˜¤ê¸°", key=f"load_cached_{selected_team}")
                if load_cached:
                    st.session_state[ai_key] = cached_ai_result
                    st.toast(f"'{selected_team}' ì €ì¥ëœ AI í•´ì„ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤", icon="ğŸ“‚")
                    st.rerun()
                st.caption("âœ… ì´ì „ì— ìƒì„±ëœ AI í•´ì„ì´ ìˆìŠµë‹ˆë‹¤")
            else:
                run_ai = st.button(f"AI í•´ì„ ìƒì„±í•˜ê¸°", key=f"ai_btn_{selected_team}")

        with top_c2:
            if cached_ai_result or st.session_state[ai_key]:
                run_ai_force = st.button(f"AI í•´ì„ ì¬ìƒì„±", key=f"ai_btn_force_{selected_team}")
                st.caption("â€» ìƒˆë¡œìš´ AI í•´ì„ì„ ê°•ì œë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            elif len(reports) > 1:
                run_all_ai = st.button("ì „ì²´ íŒ€ AI í•´ì„", key="ai_btn_all")
                st.caption("â€» ëª¨ë“  íŒ€ì˜ AI í•´ì„ì„ ì¼ê´„ ìƒì„±í•©ë‹ˆë‹¤.")

        with top_c3:
            if len(reports) > 1 and (cached_ai_result or st.session_state[ai_key]):
                run_all_ai = st.button("ì „ì²´ íŒ€ AI í•´ì„", key="ai_btn_all_2")
                st.caption("â€» ëª¨ë“  íŒ€ì˜ AI í•´ì„ì„ ì¼ê´„ ìƒì„±í•©ë‹ˆë‹¤.")

        # ê°œë³„ íŒ€ AI í•´ì„ ìƒì„± (ì‹ ê·œ ìƒì„±)
        if 'run_ai' in locals() and run_ai:
            st.session_state[ai_key] = None
            progress = st.progress(0)
            progress_text = st.empty()
            log_box = st.empty()

            def on_progress(step: int, msg: str):
                pct = min(max(int(step / 7 * 100), 0), 100)
                progress.progress(pct)
                progress_text.markdown(f"**{pct}% ì§„í–‰ ì¤‘:** {msg}")
                log_box.markdown(f"ìµœê·¼ ë‹¨ê³„: {msg}")

            with st.spinner(f"'{selected_team}' AI í•´ì„ ìƒì„± ì¤‘..."):
                ai_result = run_ai_interpretation_gemini_from_report(
                    report, progress_update=on_progress, force_regenerate=False
                )
            st.session_state[ai_key] = ai_result
            st.toast(f"'{selected_team}' AI í•´ì„ ìƒì„± ì™„ë£Œ", icon="âœ…")

        # ê°œë³„ íŒ€ AI í•´ì„ ì¬ìƒì„± (ê°•ì œ ì¬ìƒì„±)
        if 'run_ai_force' in locals() and run_ai_force:
            st.session_state[ai_key] = None
            progress = st.progress(0)
            progress_text = st.empty()
            log_box = st.empty()

            def on_progress(step: int, msg: str):
                pct = min(max(int(step / 7 * 100), 0), 100)
                progress.progress(pct)
                progress_text.markdown(f"**{pct}% ì§„í–‰ ì¤‘:** {msg}")
                log_box.markdown(f"ìµœê·¼ ë‹¨ê³„: {msg}")

            with st.spinner(f"'{selected_team}' AI í•´ì„ ì¬ìƒì„± ì¤‘..."):
                ai_result = run_ai_interpretation_gemini_from_report(
                    report, progress_update=on_progress, force_regenerate=True
                )
            st.session_state[ai_key] = ai_result
            st.toast(f"'{selected_team}' AI í•´ì„ ì¬ìƒì„± ì™„ë£Œ", icon="ğŸ”„")

        # ì „ì²´ íŒ€ AI í•´ì„ ìƒì„±
        if len(reports) > 1 and 'run_all_ai' in locals() and run_all_ai:
            progress = st.progress(0)
            progress_text = st.empty()

            total_teams = len(reports)
            for i, (team_name, team_report) in enumerate(reports.items()):
                ai_key_team = f"ai_result_{team_name}"
                progress.progress((i + 1) / total_teams)
                progress_text.markdown(f"**{team_name}** AI í•´ì„ ìƒì„± ì¤‘... ({i+1}/{total_teams})")

                with st.spinner(f"'{team_name}' AI í•´ì„ ìƒì„± ì¤‘..."):
                    ai_result = run_ai_interpretation_gemini_from_report(team_report)
                st.session_state[ai_key_team] = ai_result

            st.toast(f"ì „ì²´ {total_teams}ê°œ íŒ€ AI í•´ì„ ìƒì„± ì™„ë£Œ", icon="âœ…")

        # í˜„ì¬ ì„ íƒëœ íŒ€ì˜ AI ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        ai_raw = _normalize_ai_result(st.session_state.get(ai_key))
        ai_raw = materialize_ai_placeholders(ai_raw, report)

        # ì ìˆ˜ ë¶„í¬ ì£¼ì…
        report = attach_score_distribution(report, selected_df, index_df)

        # HTML ë¯¸ë¦¬ë³´ê¸° ìƒì„±
        html_preview = render_web_html(
            report,
            ai_result=ai_raw if _has_ai_result(ai_raw) else None,
        )

        # ë¦¬í¬íŠ¸ ì œëª© í‘œì‹œ
        if len(reports) > 1:
            st.markdown(f"**í˜„ì¬ í‘œì‹œ ì¤‘:** {selected_team}")

        st.markdown(
            '<div class="preview-container" style="margin-top:0.75rem;">',
            unsafe_allow_html=True,
        )
        st.components.v1.html(html_preview, height=900, scrolling=True)
        st.markdown("</div>", unsafe_allow_html=True)

        # AI í•´ì„ ê²°ê³¼ í¸ì§‘ ê¸°ëŠ¥ (ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸° ë’¤ì— ìœ„ì¹˜)
        if ai_raw and _has_ai_result(ai_raw):
            st.divider()
            st.markdown("### ğŸ“ AI í•´ì„ ê²°ê³¼ ê²€í†  ë° í¸ì§‘")

            # í¸ì§‘ ëª¨ë“œ í† ê¸€
            edit_mode_key = f"edit_mode_{selected_team}"
            if edit_mode_key not in st.session_state:
                st.session_state[edit_mode_key] = False

            col1, col2, col3 = st.columns([0.2, 0.2, 0.6])
            with col1:
                if st.button("âœï¸ í¸ì§‘ ëª¨ë“œ", key=f"edit_btn_{selected_team}"):
                    st.session_state[edit_mode_key] = not st.session_state[edit_mode_key]

            with col2:
                if st.session_state[edit_mode_key]:
                    if st.button("ğŸ’¾ í¸ì§‘ ë‚´ìš© ì €ì¥", key=f"save_btn_{selected_team}"):
                        # í¸ì§‘ëœ ë‚´ìš©ì„ ì €ì¥
                        data_hash = generate_data_hash(report)
                        save_ai_analysis(selected_team, data_hash, ai_raw, report)
                        st.session_state[edit_mode_key] = False
                        st.toast("í¸ì§‘ ë‚´ìš©ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!", icon="ğŸ’¾")
                        st.rerun()

            # AI í•´ì„ ê²°ê³¼ í‘œì‹œ/í¸ì§‘
            if st.session_state[edit_mode_key]:
                st.info("ğŸ”§ í¸ì§‘ ëª¨ë“œ: AI í•´ì„ ê²°ê³¼ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìˆ˜ì • í›„ 'í¸ì§‘ ë‚´ìš© ì €ì¥'ì„ í´ë¦­í•˜ì„¸ìš”.")

                # ê° ì„¹ì…˜ë³„ í¸ì§‘ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì˜ì—­
                ai_raw["final"] = st.text_area(
                    "ğŸ“„ ìµœì¢… ì„ì› ìš”ì•½",
                    value=ai_raw.get("final", ""),
                    height=200,
                    key=f"edit_final_{selected_team}",
                    help="ì´ ë‚´ìš©ì´ ë¦¬í¬íŠ¸ì˜ ë©”ì¸ ë¶„ì„ ê²°ê³¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤."
                )

                with st.expander("ğŸ” ì„¸ë¶€ ë¶„ì„ ê²°ê³¼ í¸ì§‘", expanded=False):
                    ai_raw["score"] = st.text_area(
                        "ğŸ“Š ì ìˆ˜ í•´ì„",
                        value=ai_raw.get("score", ""),
                        height=150,
                        key=f"edit_score_{selected_team}"
                    )

                    ai_raw["items"] = st.text_area(
                        "ğŸ“‹ ë‚®ì€ ì ìˆ˜ ë¬¸í•­ ë¶„ì„",
                        value=ai_raw.get("items", ""),
                        height=150,
                        key=f"edit_items_{selected_team}"
                    )

                    ai_raw["free_text"] = st.text_area(
                        "ğŸ’¬ ì£¼ê´€ì‹ ì‘ë‹µ ë¶„ì„",
                        value=ai_raw.get("free_text", ""),
                        height=150,
                        key=f"edit_free_text_{selected_team}"
                    )

            else:
                # ì½ê¸° ì „ìš© ëª¨ë“œ
                st.markdown("#### ğŸ“„ ìµœì¢… AI ë¶„ì„ ê²°ê³¼")
                if ai_raw.get("final"):
                    st.markdown(ai_raw["final"])
                else:
                    st.info("AI ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ 'AI í•´ì„ ìƒì„±í•˜ê¸°'ë¥¼ í´ë¦­í•˜ì„¸ìš”.")

                with st.expander("ğŸ” ì„¸ë¶€ ë¶„ì„ ê²°ê³¼ ë³´ê¸°", expanded=False):
                    if ai_raw.get("score"):
                        st.markdown("**ğŸ“Š ì ìˆ˜ í•´ì„:**")
                        st.markdown(ai_raw["score"])

                    if ai_raw.get("items"):
                        st.markdown("**ğŸ“‹ ë‚®ì€ ì ìˆ˜ ë¬¸í•­ ë¶„ì„:**")
                        st.markdown(ai_raw["items"])

                    if ai_raw.get("free_text"):
                        st.markdown("**ğŸ’¬ ì£¼ê´€ì‹ ì‘ë‹µ ë¶„ì„:**")
                        st.markdown(ai_raw["free_text"])

    # ---------- (3) PDF ìƒì„± ----------
    elif st.session_state["active_menu"] == "pdf":
        st.markdown("##### PDF ìƒì„±")

        df = st.session_state["uploaded_df"]
        if df is None:
            st.warning("ë¨¼ì € ì²«ë²ˆì§¸ ë©”ë‰´ì—ì„œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.")
            return

        reports = st.session_state.get("reports", {})
        if not reports:
            st.warning("ë¨¼ì € ì²«ë²ˆì§¸ ë©”ë‰´ì—ì„œ ë¦¬í¬íŠ¸ ì„¤ì •ì„ ì™„ë£Œí•´ ì£¼ì„¸ìš”.")
            return

        org_name = get_organization_name_from_reports(reports)

        st.markdown('<div id="export-view">', unsafe_allow_html=True)

        # ë‹¤ì¤‘ ë¦¬í¬íŠ¸ì¸ ê²½ìš°
        if len(reports) > 1:
            col_individual, col_batch = st.columns(2)

            # ê°œë³„ PDF ë‹¤ìš´ë¡œë“œ
            with col_individual:
                st.markdown('<div class="export-card">', unsafe_allow_html=True)
                st.markdown('<div class="export-card-head">ğŸ“„ ê°œë³„ PDF ë‹¤ìš´ë¡œë“œ</div>', unsafe_allow_html=True)
                st.markdown('<div class="export-card-body">', unsafe_allow_html=True)

                team_names = sorted(reports.keys())
                selected_team_for_pdf = st.selectbox(
                    "ë‹¤ìš´ë¡œë“œí•  íŒ€ ì„ íƒ",
                    team_names,
                    key="pdf_team_select"
                )

                if st.button("ê°œë³„ PDF ìƒì„±", key="individual_pdf"):
                    with st.spinner(f"'{selected_team_for_pdf}' PDF ìƒì„± ì¤‘..."):
                        single_report = {selected_team_for_pdf: reports[selected_team_for_pdf]}
                        pdf_result = generate_multiple_pdfs(single_report)

                        if pdf_result and selected_team_for_pdf in pdf_result:
                            pdf_bytes = pdf_result[selected_team_for_pdf]
                            safe_team_name = selected_team_for_pdf.replace("/", "_").replace("\\", "_")
                            filename = f"{safe_team_name}_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨.pdf"

                            st.success("PDF ìƒì„± ì™„ë£Œ!")
                            st.download_button(
                                "ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ",
                                data=pdf_bytes,
                                file_name=filename,
                                mime="application/pdf",
                                key="download_individual_pdf"
                            )

                st.markdown("</div></div>", unsafe_allow_html=True)

            # ì „ì²´ ZIP ë‹¤ìš´ë¡œë“œ
            with col_batch:
                st.markdown('<div class="export-card">', unsafe_allow_html=True)
                st.markdown('<div class="export-card-head">ğŸ“¦ ì „ì²´ íŒ€ ZIP ë‹¤ìš´ë¡œë“œ</div>', unsafe_allow_html=True)
                st.markdown('<div class="export-card-body">', unsafe_allow_html=True)

                st.markdown(f"ì´ {len(reports)}ê°œ íŒ€ì˜ PDFë¥¼ ì¼ê´„ ìƒì„±í•©ë‹ˆë‹¤.")

                # ì„±ëŠ¥ ì˜µì…˜
                with st.expander("âš™ï¸ ì„±ëŠ¥ ì„¤ì •", expanded=False):
                    # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
                    use_parallel = st.checkbox("ë³‘ë ¬ ì²˜ë¦¬ ì‚¬ìš©", value=len(reports) > 3, help="3ê°œ ì´ìƒ íŒ€ì—ì„œ ì¶”ì²œ")
                    if use_parallel:
                        max_workers = st.slider("ë³‘ë ¬ ì‘ì—…ì ìˆ˜", min_value=1, max_value=8, value=3, help="CPU ì½”ì–´ ìˆ˜ì— ë”°ë¼ ì¡°ì ˆ")
                    else:
                        max_workers = 1

                    # ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
                    st.markdown("**ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •**")
                    batch_size = st.selectbox("ë°°ì¹˜ í¬ê¸°", options=[5, 10, 20, 50], index=1, help="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ")

                    memory_monitoring = st.checkbox("ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í™œì„±í™”", value=True, help="ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì ")
                    aggressive_cleanup = st.checkbox("ì ê·¹ì  ë©”ëª¨ë¦¬ ì •ë¦¬", value=True, help="ê° ë°°ì¹˜ í›„ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰")

                    # í˜„ì¬ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´ í‘œì‹œ
                    try:
                        import psutil
                        memory = psutil.virtual_memory()
                        st.info(f"ğŸ’¾ í˜„ì¬ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬: {memory.available/1024**3:.1f}GB ì‚¬ìš© ê°€ëŠ¥ (ì „ì²´: {memory.total/1024**3:.1f}GB)")
                    except ImportError:
                        st.info("ğŸ’¾ ë©”ëª¨ë¦¬ ì •ë³´ë¥¼ ë³´ë ¤ë©´ psutil ì„¤ì¹˜ í•„ìš”: pip install psutil")

                if st.button("ì „ì²´ PDF ìƒì„±", key="batch_pdf"):
                    progress_bar = st.progress(0)
                    progress_text = st.empty()
                    performance_stats = st.empty()

                    import time
                    start_time = time.time()

                    with st.spinner("ì „ì²´ íŒ€ PDF ìƒì„± ì¤‘..."):
                        total_teams = len(reports)
                        pdf_results = {}

                        if use_parallel and total_teams > 1:
                            # ë³‘ë ¬ ë°°ì¹˜ ì²˜ë¦¬
                            progress_text.text(f"ë³‘ë ¬ ì²˜ë¦¬ë¡œ {total_teams}ê°œ íŒ€ PDF ìƒì„± ì‹œì‘ (ë³‘ë ¬ë„: {max_workers})")

                            # ë°°ì¹˜ë³„ë¡œ ì²˜ë¦¬
                            team_items = list(reports.items())
                            processed_count = 0

                            for batch_start in range(0, total_teams, batch_size):
                                batch_start_time = time.time()
                                batch_end = min(batch_start + batch_size, total_teams)
                                batch_reports = dict(team_items[batch_start:batch_end])

                                progress_text.text(f"ë°°ì¹˜ {batch_start//batch_size + 1} ì²˜ë¦¬ ì¤‘... ({batch_start+1}-{batch_end}/{total_teams})")

                                # ë³‘ë ¬ ë°°ì¹˜ ì²˜ë¦¬
                                batch_results = generate_multiple_pdfs_parallel(batch_reports, max_workers=max_workers)
                                pdf_results.update(batch_results)

                                processed_count += len(batch_results)
                                progress_percentage = processed_count / total_teams
                                progress_bar.progress(progress_percentage)

                                # ì‹¤ì‹œê°„ ì„±ëŠ¥ í†µê³„
                                elapsed_time = time.time() - start_time
                                batch_time = time.time() - batch_start_time
                                avg_time_per_team = elapsed_time / processed_count if processed_count > 0 else 0
                                estimated_total_time = avg_time_per_team * total_teams
                                remaining_time = estimated_total_time - elapsed_time

                                # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
                                memory_info = ""
                                if memory_monitoring:
                                    try:
                                        import psutil
                                        memory = psutil.virtual_memory()
                                        memory_info = f"""
                                        **ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:**
                                        - ì‚¬ìš© ì¤‘: {(memory.total - memory.available)/1024**3:.1f}GB ({memory.percent:.1f}%)
                                        - ì‚¬ìš© ê°€ëŠ¥: {memory.available/1024**3:.1f}GB
                                        """
                                    except ImportError:
                                        memory_info = "\n**ğŸ’¾ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§:** psutil ë¯¸ì„¤ì¹˜"

                                performance_stats.markdown(f"""
                                **ğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ í†µê³„:**
                                - ì§„í–‰ë¥ : {progress_percentage:.1%} ({processed_count}/{total_teams})
                                - ê²½ê³¼ì‹œê°„: {elapsed_time:.1f}ì´ˆ
                                - ì´ë²ˆ ë°°ì¹˜: {batch_time:.1f}ì´ˆ ({len(batch_results)}ê°œ íŒ€)
                                - í‰ê·  íŒ€ë‹¹ ì‹œê°„: {avg_time_per_team:.1f}ì´ˆ
                                - ì˜ˆìƒ ì´ ì†Œìš”ì‹œê°„: {estimated_total_time:.1f}ì´ˆ
                                - ì˜ˆìƒ ë‚¨ì€ì‹œê°„: {max(0, remaining_time):.1f}ì´ˆ
                                - ì²˜ë¦¬ ì†ë„: {processed_count/elapsed_time:.1f} íŒ€/ì´ˆ
                                {memory_info}
                                """)

                                # ë©”ëª¨ë¦¬ ì •ë¦¬
                                if aggressive_cleanup:
                                    import gc
                                    gc.collect()
                                    if memory_monitoring:
                                        try:
                                            import psutil
                                            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 80% ì´ìƒì´ë©´ ê²½ê³ 
                                            memory = psutil.virtual_memory()
                                            if memory.percent > 80:
                                                st.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤ ({memory.percent:.1f}%). ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
                                        except ImportError:
                                            pass

                        else:
                            # ìˆœì°¨ ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
                            for i, (team_name, report) in enumerate(reports.items()):
                                progress_percentage = (i + 1) / total_teams
                                progress_bar.progress(progress_percentage)
                                progress_text.text(f"'{team_name}' PDF ìƒì„± ì¤‘... ({i+1}/{total_teams})")

                                # ì‹¤ì‹œê°„ ì„±ëŠ¥ í†µê³„ (ìˆœì°¨ ì²˜ë¦¬)
                                elapsed_time = time.time() - start_time
                                avg_time_per_team = elapsed_time / (i + 1)
                                estimated_total_time = avg_time_per_team * total_teams
                                remaining_time = estimated_total_time - elapsed_time

                                # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ (ìˆœì°¨ ì²˜ë¦¬)
                                memory_info = ""
                                if memory_monitoring:
                                    try:
                                        import psutil
                                        memory = psutil.virtual_memory()
                                        memory_info = f"""
                                        **ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:**
                                        - ì‚¬ìš© ì¤‘: {(memory.total - memory.available)/1024**3:.1f}GB ({memory.percent:.1f}%)
                                        - ì‚¬ìš© ê°€ëŠ¥: {memory.available/1024**3:.1f}GB
                                        """
                                    except ImportError:
                                        memory_info = "\n**ğŸ’¾ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§:** psutil ë¯¸ì„¤ì¹˜"

                                performance_stats.markdown(f"""
                                **ğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ í†µê³„:**
                                - ì§„í–‰ë¥ : {progress_percentage:.1%} ({i+1}/{total_teams})
                                - ê²½ê³¼ì‹œê°„: {elapsed_time:.1f}ì´ˆ
                                - í‰ê·  íŒ€ë‹¹ ì‹œê°„: {avg_time_per_team:.1f}ì´ˆ
                                - ì˜ˆìƒ ì´ ì†Œìš”ì‹œê°„: {estimated_total_time:.1f}ì´ˆ
                                - ì˜ˆìƒ ë‚¨ì€ì‹œê°„: {max(0, remaining_time):.1f}ì´ˆ
                                - ì²˜ë¦¬ ì†ë„: {(i+1)/elapsed_time:.1f} íŒ€/ì´ˆ
                                {memory_info}
                                """)

                                single_report = {team_name: report}
                                single_pdf_result = generate_multiple_pdfs(single_report)

                                if single_pdf_result and team_name in single_pdf_result:
                                    pdf_results[team_name] = single_pdf_result[team_name]

                        if pdf_results:
                            # ìµœì¢… ì„±ëŠ¥ í†µê³„
                            total_elapsed_time = time.time() - start_time
                            final_avg_time_per_team = total_elapsed_time / len(pdf_results)
                            final_processing_speed = len(pdf_results) / total_elapsed_time

                            performance_stats.markdown(f"""
                            **âœ… ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸:**
                            - ì´ ì²˜ë¦¬ì‹œê°„: {total_elapsed_time:.1f}ì´ˆ ({total_elapsed_time/60:.1f}ë¶„)
                            - ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ PDF: {len(pdf_results)}ê°œ
                            - í‰ê·  íŒ€ë‹¹ ì²˜ë¦¬ì‹œê°„: {final_avg_time_per_team:.1f}ì´ˆ
                            - ì „ì²´ ì²˜ë¦¬ ì†ë„: {final_processing_speed:.1f} íŒ€/ì´ˆ
                            - ì²˜ë¦¬ ëª¨ë“œ: {'ë³‘ë ¬ ì²˜ë¦¬' if use_parallel and total_teams > 1 else 'ìˆœì°¨ ì²˜ë¦¬'}
                            {f'- ë³‘ë ¬ ì‘ì—…ì ìˆ˜: {max_workers}ê°œ' if use_parallel and total_teams > 1 else ''}
                            {f'- ë°°ì¹˜ í¬ê¸°: {batch_size}' if use_parallel and total_teams > 1 else ''}
                            """)

                            # ZIP ìƒì„±
                            zip_bytes = create_zip_from_pdfs(pdf_results, org_name)
                            st.session_state["pdf_results"] = pdf_results
                            st.session_state["zip_bytes"] = zip_bytes

                            st.success(f"ì „ì²´ {len(pdf_results)}ê°œ íŒ€ PDF ìƒì„± ì™„ë£Œ! (ì´ {total_elapsed_time:.1f}ì´ˆ ì†Œìš”)")
                            zip_filename = f"{org_name}_ì „ì²´íŒ€_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨_{datetime.now().strftime('%Y%m%d')}.zip"

                            st.download_button(
                                "ğŸ“¥ ZIP ë‹¤ìš´ë¡œë“œ",
                                data=zip_bytes,
                                file_name=zip_filename,
                                mime="application/zip",
                                key="download_zip"
                            )
                        else:
                            # ìƒì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ì œê³µ
                            st.error("ğŸš« PDF ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                            # ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ ë° ê°€ì´ë“œ
                            if len(reports) == 0:
                                st.warning("ğŸ“‹ ìƒì„±í•  ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.")
                            else:
                                failed_teams = [team for team in reports.keys() if team not in pdf_results]
                                if failed_teams:
                                    st.warning(f"âš ï¸ ë‹¤ìŒ íŒ€ë“¤ì˜ PDF ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {', '.join(failed_teams[:5])}")
                                    if len(failed_teams) > 5:
                                        st.info(f"... ì™¸ {len(failed_teams) - 5}ê°œ íŒ€")

                                # í•´ê²° ë°©ë²• ì œì•ˆ
                                with st.expander("ğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ë²•", expanded=False):
                                    st.markdown("""
                                    **ë‹¤ìŒ ë°©ë²•ë“¤ì„ ì‹œë„í•´ ë³´ì„¸ìš”:**

                                    1. **ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œ**
                                       - ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš” (í˜„ì¬: {batch_size}ê°œ â†’ 5ê°œ ì´í•˜)
                                       - ë³‘ë ¬ ì‘ì—…ì ìˆ˜ë¥¼ ì¤„ì—¬ë³´ì„¸ìš” (í˜„ì¬: {max_workers}ê°œ â†’ 1-2ê°œ)
                                       - ì ê·¹ì  ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ í™œì„±í™”í•´ ì£¼ì„¸ìš”

                                    2. **ë°ì´í„° ë¬¸ì œ**
                                       - CSV íŒŒì¼ì˜ ë°ì´í„° í˜•ì‹ì„ í™•ì¸í•´ ì£¼ì„¸ìš”
                                       - íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ëœ íŒ€ëª…ì´ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”

                                    3. **ì‹œìŠ¤í…œ ë¬¸ì œ**
                                       - ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”
                                       - ë‹¤ë¥¸ ë¸Œë¼ìš°ì €ì—ì„œ ì‹œë„í•´ ë³´ì„¸ìš”

                                    4. **ê°œë³„ PDF ìƒì„±**
                                       - ì „ì²´ ìƒì„± ëŒ€ì‹  ê°œë³„ íŒ€ PDFë¥¼ í•˜ë‚˜ì”© ìƒì„±í•´ ë³´ì„¸ìš”
                                    """.format(batch_size=batch_size, max_workers=max_workers))

                                    # ì‹œìŠ¤í…œ ì •ë³´
                                    try:
                                        import psutil
                                        memory = psutil.virtual_memory()
                                        st.info(f"í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {memory.percent:.1f}% (ì‚¬ìš©ê°€ëŠ¥: {memory.available/1024**3:.1f}GB)")
                                    except ImportError:
                                        st.info("ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´ë¥¼ í™•ì¸í•˜ë ¤ë©´ psutilì„ ì„¤ì¹˜í•´ ì£¼ì„¸ìš”: pip install psutil")

                # ì´ë¯¸ ìƒì„±ëœ ZIPì´ ìˆëŠ” ê²½ìš°
                elif st.session_state.get("zip_bytes"):
                    zip_filename = f"{org_name}_ì „ì²´íŒ€_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨_{datetime.now().strftime('%Y%m%d')}.zip"
                    st.download_button(
                        "ğŸ“¥ ZIP ë‹¤ìš´ë¡œë“œ",
                        data=st.session_state["zip_bytes"],
                        file_name=zip_filename,
                        mime="application/zip",
                        key="download_existing_zip"
                    )

                st.markdown("</div></div>", unsafe_allow_html=True)

        else:
            # ë‹¨ì¼ ë¦¬í¬íŠ¸ì¸ ê²½ìš° (ê¸°ì¡´ ë°©ì‹)
            col_pdf, col_mail = st.columns(2)

            with col_pdf:
                st.markdown('<div class="export-card">', unsafe_allow_html=True)
                st.markdown('<div class="export-card-head">ğŸ“„ PDF ë§Œë“¤ê¸°</div>', unsafe_allow_html=True)
                st.markdown('<div class="export-card-body">', unsafe_allow_html=True)

                team_name = list(reports.keys())[0]
                report = reports[team_name]

                # AI ê²°ê³¼ ì²˜ë¦¬
                ai_key = f"ai_result_{team_name}"
                current_ai = _normalize_ai_result(st.session_state.get(ai_key))
                current_ai = materialize_ai_placeholders(current_ai, report)

                if st.button("PDF ë§Œë“¤ê¸°", key="single_pdf"):
                    with st.spinner("PDF ìƒì„± ì¤‘..."):
                        single_report = {team_name: report}
                        pdf_result = generate_multiple_pdfs(single_report)

                        if pdf_result and team_name in pdf_result:
                            pdf_bytes = pdf_result[team_name]
                            st.session_state["pdf_bytes"] = pdf_bytes
                            st.success("PDFê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

                            filename = f"{org_name}_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨.pdf"
                            st.download_button(
                                "ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ",
                                data=pdf_bytes,
                                file_name=filename,
                                mime="application/pdf",
                                key="download_single_pdf"
                            )

                elif st.session_state.get("pdf_bytes"):
                    filename = f"{org_name}_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨.pdf"
                    st.download_button(
                        "ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ",
                        data=st.session_state["pdf_bytes"],
                        file_name=filename,
                        mime="application/pdf",
                        key="download_existing_single_pdf"
                    )

                st.markdown("</div></div>", unsafe_allow_html=True)


        st.markdown("</div>", unsafe_allow_html=True)

    # ---------- (4) ì´ë©”ì¼ ë°œì†¡ ----------
    elif st.session_state["active_menu"] == "email":
        st.markdown("##### ì´ë©”ì¼ ë°œì†¡")

        df = st.session_state["uploaded_df"]
        if df is None:
            st.warning("ë¨¼ì € ì²«ë²ˆì§¸ ë©”ë‰´ì—ì„œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.")
            return

        reports = st.session_state.get("reports", {})
        if not reports:
            st.warning("ë¨¼ì € ì²«ë²ˆì§¸ ë©”ë‰´ì—ì„œ ë¦¬í¬íŠ¸ ì„¤ì •ì„ ì™„ë£Œí•´ ì£¼ì„¸ìš”.")
            return

        st.markdown('<div id="email-view">', unsafe_allow_html=True)

        # ì´ë©”ì¼ ë°œì†¡ UI êµ¬í˜„
        st.markdown('<div class="export-card">', unsafe_allow_html=True)
        st.markdown('<div class="export-card-head">âœ‰ï¸ ì´ë©”ì¼ ë°œì†¡</div>', unsafe_allow_html=True)
        st.markdown('<div class="export-card-body">', unsafe_allow_html=True)

        # Gmail ì„¤ì • - í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ê±°ë‚˜ ì‚¬ìš©ì ì…ë ¥
        env_gmail = os.getenv("SMTP_EMAIL", "")
        env_password = os.getenv("SMTP_PASSWORD", "")

        if env_gmail and env_password:
            st.info(f"âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ Gmail ì„¤ì •ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤: {env_gmail}")
            gmail_address = env_gmail
            gmail_app_pw = env_password

            with st.expander("Gmail ì„¤ì • ë³€ê²½ (ì„ íƒì‚¬í•­)"):
                gmail_address = st.text_input(
                    "ë‹¤ë¥¸ Gmail ì£¼ì†Œ ì‚¬ìš©",
                    value=env_gmail,
                    key="email_gmail_address_override",
                    placeholder="sender@gmail.com"
                )
                gmail_app_pw = st.text_input(
                    "ë‹¤ë¥¸ Gmail ì•± ë¹„ë°€ë²ˆí˜¸ ì‚¬ìš©",
                    value="",
                    key="email_gmail_password_override",
                    type="password",
                    help="Google ê³„ì • > ë³´ì•ˆ > ì•± ë¹„ë°€ë²ˆí˜¸ì—ì„œ ë°œê¸‰"
                )
                if not gmail_app_pw:  # ìƒˆ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ ê°’ ì‚¬ìš©
                    gmail_app_pw = env_password
        else:
            st.warning("âš ï¸ í™˜ê²½ë³€ìˆ˜ì— SMTP ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            gmail_address = st.text_input(
                "ë°œì†¡ì Gmail ì£¼ì†Œ",
                key="email_gmail_address",
                placeholder="sender@gmail.com"
            )
            gmail_app_pw = st.text_input(
                "Gmail ì•± ë¹„ë°€ë²ˆí˜¸",
                key="email_gmail_password",
                type="password",
                help="Google ê³„ì • > ë³´ì•ˆ > ì•± ë¹„ë°€ë²ˆí˜¸ì—ì„œ ë°œê¸‰"
            )

        st.markdown("---")

        if len(reports) > 1:
            # ë‹¤ì¤‘ ë¦¬í¬íŠ¸ ì´ë©”ì¼ ë°œì†¡
            teams = sorted(reports.keys())
            email_mapping = create_email_mapping_ui(teams)

            # ê³µí†µ ë©”ì¼ ì„¤ì •
            subject = st.text_input(
                "ë©”ì¼ ì œëª©",
                value="ì¡°ì§íš¨ê³¼ì„± ì§„ë‹¨ ë¦¬í¬íŠ¸",
                key="batch_email_subject"
            )
            body = st.text_area(
                "ë©”ì¼ ë‚´ìš©",
                value="ì²¨ë¶€ëœ PDFë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.",
                key="batch_email_body",
                height=100
            )

            # ZIP íŒŒì¼ ë°œì†¡ ì˜µì…˜
            st.markdown("---")
            st.markdown("##### ğŸ“¦ ë°œì†¡ ë°©ì‹ ì„ íƒ")

            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("ğŸ“§ ê°œë³„ ë°œì†¡", key="individual_email_send", use_container_width=True):
                    if not gmail_address or not gmail_app_pw:
                        st.error("Gmail ì£¼ì†Œì™€ ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                    elif not email_mapping:
                        st.error("ì´ë©”ì¼ ë§¤í•‘ì„ ì„¤ì •í•´ ì£¼ì„¸ìš”.")
                    else:
                        with st.spinner("PDF ìƒì„± ë° ê°œë³„ ì´ë©”ì¼ ë°œì†¡ ì¤‘..."):
                            try:
                                success_count = send_batch_emails_with_reports(
                                    reports=reports,
                                    email_mapping=email_mapping,
                                    gmail_address=gmail_address,
                                    gmail_password=gmail_app_pw,
                                    subject=subject,
                                    body=body
                                )
                                st.success(f"âœ… {success_count}ê°œ íŒ€ì— ê°œë³„ ì´ë©”ì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡í–ˆìŠµë‹ˆë‹¤!")
                            except Exception as e:
                                st.error(f"ê°œë³„ ì´ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

            with col2:
                zip_recipient = st.text_input(
                    "ZIP íŒŒì¼ ìˆ˜ì‹ ì ì´ë©”ì¼",
                    key="zip_recipient_email",
                    placeholder="manager@company.com",
                    help="ëª¨ë“  íŒ€ì˜ PDFë¥¼ ZIP íŒŒì¼ë¡œ ë¬¶ì–´ì„œ í•œ ë²ˆì— ë°œì†¡"
                )

                if st.button("ğŸ“¦ ZIP íŒŒì¼ ë°œì†¡", key="zip_email_send", use_container_width=True):
                    if not gmail_address or not gmail_app_pw:
                        st.error("Gmail ì£¼ì†Œì™€ ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                    elif not zip_recipient:
                        st.error("ZIP íŒŒì¼ ìˆ˜ì‹ ì ì´ë©”ì¼ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                    else:
                        with st.spinner("PDF ìƒì„± ë° ZIP íŒŒì¼ ì´ë©”ì¼ ë°œì†¡ ì¤‘..."):
                            try:
                                success_count = send_batch_emails_with_reports(
                                    reports=reports,
                                    email_mapping={},  # ZIP ëª¨ë“œì—ì„œëŠ” ë¶ˆí•„ìš”
                                    gmail_address=gmail_address,
                                    gmail_password=gmail_app_pw,
                                    subject=subject,
                                    body=body,
                                    send_as_zip=True,
                                    zip_recipient=zip_recipient
                                )
                                if success_count > 0:
                                    st.success(f"âœ… {zip_recipient}ë¡œ ZIP íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡í–ˆìŠµë‹ˆë‹¤!")
                                else:
                                    st.error("ZIP íŒŒì¼ ë°œì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            except Exception as e:
                                st.error(f"ZIP íŒŒì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        else:
            # ë‹¨ì¼ ë¦¬í¬íŠ¸ ì´ë©”ì¼ ë°œì†¡
            team_name = list(reports.keys())[0]

            to_email = st.text_input(
                "ë°›ëŠ” ì‚¬ëŒ ì´ë©”ì¼",
                key="single_email_recipient",
                placeholder="recipient@example.com"
            )
            subject = st.text_input(
                "ë©”ì¼ ì œëª©",
                value=f"{team_name} ì¡°ì§íš¨ê³¼ì„± ì§„ë‹¨ ë¦¬í¬íŠ¸",
                key="single_email_subject"
            )
            body = st.text_area(
                "ë©”ì¼ ë‚´ìš©",
                value=f"{team_name} íŒ€ì˜ ì¡°ì§íš¨ê³¼ì„± ì§„ë‹¨ ë¦¬í¬íŠ¸ë¥¼ ì²¨ë¶€í•©ë‹ˆë‹¤.",
                key="single_email_body",
                height=100
            )

            if st.button("ğŸ“§ ì´ë©”ì¼ ë°œì†¡", key="single_email_send"):
                if not gmail_address or not gmail_app_pw:
                    st.error("Gmail ì£¼ì†Œì™€ ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                elif not to_email:
                    st.error("ë°›ëŠ” ì‚¬ëŒ ì´ë©”ì¼ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("PDF ìƒì„± ë° ì´ë©”ì¼ ë°œì†¡ ì¤‘..."):
                        try:
                            # ë¨¼ì € PDF ìƒì„± í…ŒìŠ¤íŠ¸
                            st.info("PDF ìƒì„± ì¤‘...")
                            pdf_results = generate_multiple_pdfs(reports)

                            if not pdf_results:
                                st.error("âŒ PDF ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ ë°ì´í„°ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
                                return

                            if team_name not in pdf_results:
                                st.error(f"âŒ '{team_name}' íŒ€ì˜ PDF ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                                return

                            st.info("ì´ë©”ì¼ ë°œì†¡ ì¤‘...")

                            # ê°œë³„ PDF ìƒì„± ë° ì´ë©”ì¼ ë°œì†¡
                            single_report = {team_name: reports[team_name]}
                            pdf_result = generate_multiple_pdfs(single_report)

                            if team_name not in pdf_result:
                                st.error(f"âŒ '{team_name}' íŒ€ì˜ PDF ì¬ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                                return

                            pdf_bytes = pdf_result[team_name]
                            safe_team_name = team_name.replace("/", "_").replace("\\", "_")
                            filename = f"{safe_team_name}_ì¡°ì§íš¨ê³¼ì„±ì§„ë‹¨.pdf"

                            # ì§ì ‘ ì´ë©”ì¼ ë°œì†¡
                            result = send_email_with_attachment(
                                to_emails=[to_email],
                                subject=subject,
                                body=body,
                                attachment_data=pdf_bytes,
                                attachment_filename=filename,
                                sender_email=gmail_address,
                                sender_password=gmail_app_pw
                            )

                            if result["success"]:
                                st.success(f"âœ… {to_email}ë¡œ ì´ë©”ì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡í–ˆìŠµë‹ˆë‹¤!")
                            else:
                                st.error(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {result['message']}")
                        except Exception as e:
                            st.error(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                            st.info("ğŸ’¡ Gmail ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”. ì¼ë°˜ ë¹„ë°€ë²ˆí˜¸ë¡œëŠ” ë°œì†¡ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        st.markdown("</div></div>", unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)

    # ---------- Phase C: ê´€ë¦¬ì í˜ì´ì§€ë“¤ ----------
    elif st.session_state["active_menu"] == "admin_db":
        if not st.session_state["admin_authenticated"]:
            st.error("âŒ ê´€ë¦¬ì ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ê´€ë¦¬ì ë¡œê·¸ì¸ì„ í•´ì£¼ì„¸ìš”.")
            return
        render_admin_database_page()

    elif st.session_state["active_menu"] == "admin_benchmark":
        if not st.session_state["admin_authenticated"]:
            st.error("âŒ ê´€ë¦¬ì ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ê´€ë¦¬ì ë¡œê·¸ì¸ì„ í•´ì£¼ì„¸ìš”.")
            return
        render_admin_benchmark_page()

    elif st.session_state["active_menu"] == "admin_branding":
        if not st.session_state["admin_authenticated"]:
            st.error("âŒ ê´€ë¦¬ì ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ê´€ë¦¬ì ë¡œê·¸ì¸ì„ í•´ì£¼ì„¸ìš”.")
            return
        render_admin_branding_page()

    elif st.session_state["active_menu"] == "admin_email":
        if not st.session_state["admin_authenticated"]:
            st.error("âŒ ê´€ë¦¬ì ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ê´€ë¦¬ì ë¡œê·¸ì¸ì„ í•´ì£¼ì„¸ìš”.")
            return
        render_admin_email_page()


def render_admin_database_page():
    """ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í˜ì´ì§€"""
    st.markdown("##### ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬")

    try:
        from database_models import get_session, Organization, Report, PDFGeneration, EmailLog
        import pandas as pd

        session = get_session()

        # í†µê³„ ì¹´ë“œ
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            org_count = session.query(Organization).count()
            st.metric("ì¡°ì§ ìˆ˜", org_count)

        with col2:
            report_count = session.query(Report).count()
            st.metric("ë¦¬í¬íŠ¸ ìˆ˜", report_count)

        with col3:
            pdf_count = session.query(PDFGeneration).filter(PDFGeneration.status == 'completed').count()
            st.metric("ìƒì„±ëœ PDF", pdf_count)

        with col4:
            email_count = session.query(EmailLog).filter(EmailLog.status == 'sent').count()
            st.metric("ë°œì†¡ëœ ì´ë©”ì¼", email_count)

        # íƒ­ìœ¼ë¡œ ê° í…Œì´ë¸” ê´€ë¦¬
        tab1, tab2, tab3, tab4, tab5 = st.tabs(["ì¡°ì§ ê´€ë¦¬", "ë¦¬í¬íŠ¸ ì´ë ¥", "PDF ìƒì„± ì´ë ¥", "ë¡œê·¸ ëª¨ë‹ˆí„°ë§", "ì‹œìŠ¤í…œ ì„¤ì •"])

        with tab1:
            st.subheader("ì¡°ì§ ê´€ë¦¬")

            # ì¡°ì§ ëª©ë¡ í‘œì‹œ
            organizations = session.query(Organization).all()
            if organizations:
                org_data = []
                for org in organizations:
                    org_data.append({
                        "ID": org.id,
                        "ì¡°ì§ëª…": org.name,
                        "ê·¸ë£¹ëª…": org.group_name or "-",
                        "ì—°ë½ì²˜": org.contact_email or "-",
                        "ìƒì„±ì¼": org.created_at.strftime("%Y-%m-%d") if org.created_at else "-",
                        "ë¦¬í¬íŠ¸ ìˆ˜": len(org.reports)
                    })

                df_orgs = pd.DataFrame(org_data)
                st.dataframe(df_orgs, use_container_width=True)

                # ì¡°ì§ ì¶”ê°€ í¼
                with st.expander("â• ìƒˆ ì¡°ì§ ì¶”ê°€"):
                    new_org_name = st.text_input("ì¡°ì§ëª…")
                    new_group_name = st.text_input("ê·¸ë£¹ëª… (ì„ íƒ)")
                    new_contact_email = st.text_input("ì—°ë½ì²˜ ì´ë©”ì¼ (ì„ íƒ)")

                    if st.button("ì¡°ì§ ì¶”ê°€"):
                        if new_org_name:
                            new_org = Organization(
                                name=new_org_name,
                                group_name=new_group_name if new_group_name else None,
                                contact_email=new_contact_email if new_contact_email else None
                            )
                            session.add(new_org)
                            session.commit()
                            st.success(f"ì¡°ì§ '{new_org_name}'ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.rerun()
                        else:
                            st.error("ì¡°ì§ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.info("ë“±ë¡ëœ ì¡°ì§ì´ ì—†ìŠµë‹ˆë‹¤.")

        with tab2:
            st.subheader("ë¦¬í¬íŠ¸ ìƒì„± ì´ë ¥")

            reports = session.query(Report).order_by(Report.created_at.desc()).limit(100).all()
            if reports:
                report_data = []
                for report in reports:
                    report_data.append({
                        "ID": report.id,
                        "ì¡°ì§ëª…": report.organization.name if report.organization else "-",
                        "íŒ€ëª…": report.team_name or "-",
                        "ìœ í˜•": report.report_type,
                        "ìƒíƒœ": report.status,
                        "ì‘ë‹µì ìˆ˜": report.respondent_count,
                        "ìƒì„±ì¼": report.created_at.strftime("%Y-%m-%d %H:%M") if report.created_at else "-"
                    })

                df_reports = pd.DataFrame(report_data)
                st.dataframe(df_reports, use_container_width=True)

            else:
                st.info("ìƒì„±ëœ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with tab3:
            st.subheader("PDF ìƒì„± ì´ë ¥")

            pdfs = session.query(PDFGeneration).order_by(PDFGeneration.created_at.desc()).limit(100).all()
            if pdfs:
                pdf_data = []
                for pdf in pdfs:
                    report_info = f"{pdf.report.organization.name if pdf.report and pdf.report.organization else 'Unknown'} - {pdf.report.team_name if pdf.report else 'Unknown'}"
                    pdf_data.append({
                        "ID": pdf.id,
                        "ë¦¬í¬íŠ¸": report_info,
                        "íŒŒì¼ëª…": pdf.pdf_filename or "-",
                        "í¬ê¸°(MB)": round(pdf.pdf_size / 1024 / 1024, 2) if pdf.pdf_size else "-",
                        "ìƒì„±ì‹œê°„(ì´ˆ)": pdf.generation_time or "-",
                        "ìƒíƒœ": pdf.status,
                        "ìƒì„±ì¼": pdf.created_at.strftime("%Y-%m-%d %H:%M") if pdf.created_at else "-"
                    })

                df_pdfs = pd.DataFrame(pdf_data)
                st.dataframe(df_pdfs, use_container_width=True)

            else:
                st.info("ìƒì„±ëœ PDFê°€ ì—†ìŠµë‹ˆë‹¤.")

        with tab4:
            st.subheader("ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§")

            # ë¡œê·¸ í•„í„° ì˜µì…˜
            col1, col2, col3 = st.columns(3)

            with col1:
                log_type_filter = st.selectbox(
                    "ë¡œê·¸ íƒ€ì…",
                    ["ì „ì²´", "PDF ìƒì„±", "ì´ë©”ì¼ ë°œì†¡"],
                    key="log_type_filter"
                )

            with col2:
                log_limit = st.number_input(
                    "í‘œì‹œí•  ë¡œê·¸ ìˆ˜",
                    min_value=10,
                    max_value=500,
                    value=50,
                    key="log_limit"
                )

            with col3:
                auto_refresh = st.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ (5ì´ˆ)", value=False)

            if auto_refresh:
                time.sleep(5)
                st.rerun()

            # ë¡œê·¸ ì¡°íšŒ
            try:
                from logging_utils import get_recent_logs

                # ë¡œê·¸ íƒ€ì… ë§¤í•‘
                log_type_map = {
                    "ì „ì²´": None,
                    "PDF ìƒì„±": "pdf",
                    "ì´ë©”ì¼ ë°œì†¡": "email"
                }

                logs = get_recent_logs(
                    log_type=log_type_map[log_type_filter],
                    limit=log_limit
                )

                if logs:
                    # ë¡œê·¸ í†µê³„
                    st.markdown("#### ğŸ“Š ë¡œê·¸ í†µê³„")
                    col1, col2, col3, col4 = st.columns(4)

                    pdf_logs = [l for l in logs if l["type"] == "pdf_generation"]
                    email_logs = [l for l in logs if l["type"] == "email_send"]

                    with col1:
                        st.metric("ì´ ë¡œê·¸ ìˆ˜", len(logs))

                    with col2:
                        pdf_success = len([l for l in pdf_logs if l["status"] == "completed"])
                        st.metric("PDF ì„±ê³µë¥ ", f"{(pdf_success/len(pdf_logs)*100) if pdf_logs else 0:.1f}%")

                    with col3:
                        email_success = len([l for l in email_logs if l["status"] == "sent"])
                        st.metric("ì´ë©”ì¼ ì„±ê³µë¥ ", f"{(email_success/len(email_logs)*100) if email_logs else 0:.1f}%")

                    with col4:
                        if pdf_logs:
                            avg_time = sum([l.get("generation_time", 0) for l in pdf_logs if l.get("generation_time")]) / len(pdf_logs)
                            st.metric("í‰ê·  ìƒì„±ì‹œê°„", f"{avg_time:.1f}ì´ˆ")
                        else:
                            st.metric("í‰ê·  ìƒì„±ì‹œê°„", "N/A")

                    st.markdown("#### ğŸ“‹ ìµœê·¼ ë¡œê·¸")

                    # ë¡œê·¸ í…Œì´ë¸” ìƒì„±
                    log_data = []
                    for log in logs:
                        if log["type"] == "pdf_generation":
                            log_data.append({
                                "ì‹œê°„": log["created_at"].strftime("%m-%d %H:%M:%S") if log["created_at"] else "-",
                                "íƒ€ì…": "ğŸ“„ PDF",
                                "ìƒíƒœ": "âœ… ì™„ë£Œ" if log["status"] == "completed" else "âŒ ì‹¤íŒ¨" if log["status"] == "failed" else "ğŸ”„ ì§„í–‰ì¤‘",
                                "ëŒ€ìƒ": f"{log['report_info']['organization']} - {log['report_info']['team_name']}",
                                "íŒŒì¼ëª…": log["filename"] or "-",
                                "í¬ê¸°": f"{log['size_mb']:.1f}MB" if log['size_mb'] else "-",
                                "ì†Œìš”ì‹œê°„": f"{log['generation_time']}ì´ˆ" if log["generation_time"] else "-",
                                "ì˜¤ë¥˜": log["error_message"][:50] + "..." if log["error_message"] and len(log["error_message"]) > 50 else log["error_message"] or "-"
                            })
                        else:  # email_send
                            log_data.append({
                                "ì‹œê°„": log["created_at"].strftime("%m-%d %H:%M:%S") if log["created_at"] else "-",
                                "íƒ€ì…": "ğŸ“§ ì´ë©”ì¼",
                                "ìƒíƒœ": "âœ… ì™„ë£Œ" if log["status"] == "sent" else "âŒ ì‹¤íŒ¨" if log["status"] == "failed" else "ğŸ”„ ì§„í–‰ì¤‘",
                                "ëŒ€ìƒ": f"ìˆ˜ì‹ ì {log['recipient_count']}ëª…",
                                "íŒŒì¼ëª…": log["subject"][:30] + "..." if len(log["subject"]) > 30 else log["subject"],
                                "í¬ê¸°": f"ì„±ê³µ: {log['sent_count']}, ì‹¤íŒ¨: {log['failed_count']}",
                                "ì†Œìš”ì‹œê°„": log["sent_at"].strftime("%m-%d %H:%M") if log["sent_at"] else "-",
                                "ì˜¤ë¥˜": log["error_message"][:50] + "..." if log["error_message"] and len(log["error_message"]) > 50 else log["error_message"] or "-"
                            })

                    if log_data:
                        df_logs = pd.DataFrame(log_data)
                        st.dataframe(df_logs, use_container_width=True, height=400)

                        # ë¡œê·¸ ë‹¤ìš´ë¡œë“œ
                        csv_data = df_logs.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="ğŸ“¥ ë¡œê·¸ CSV ë‹¤ìš´ë¡œë“œ",
                            data=csv_data,
                            file_name=f"logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                    else:
                        st.info("í‘œì‹œí•  ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

                    # ì‹¤ì‹œê°„ ë¡œê·¸ ìƒì„¸ë³´ê¸°
                    st.markdown("#### ğŸ” ë¡œê·¸ ìƒì„¸ë³´ê¸°")
                    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
                        st.rerun()

                    # ìµœê·¼ ì˜¤ë¥˜ ë¡œê·¸ë§Œ í‘œì‹œ
                    error_logs = [l for l in logs if l["status"] in ["failed", "error"]]
                    if error_logs:
                        st.markdown("##### âš ï¸ ìµœê·¼ ì˜¤ë¥˜ ë¡œê·¸")
                        for error_log in error_logs[:5]:
                            with st.expander(f"âŒ {error_log['type']} ì˜¤ë¥˜ - {error_log['created_at'].strftime('%m-%d %H:%M') if error_log['created_at'] else 'Unknown'}"):
                                st.json(error_log)

                else:
                    st.info("ì¡°íšŒëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

            except Exception as e:
                st.error(f"ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                st.info("logging_utils.py ëª¨ë“ˆê³¼ ë¡œê·¸ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

        with tab5:
            st.subheader("ì‹œìŠ¤í…œ ì„¤ì • ë° ê´€ë¦¬")

            # ì‹œìŠ¤í…œ í†µê³„ ì„¹ì…˜
            st.markdown("#### ğŸ“Š ì‹œìŠ¤í…œ í†µê³„")
            try:
                from admin_utils import get_system_stats, analyze_system_performance

                stats = get_system_stats()
                perf = analyze_system_performance()

                # ê¸°ë³¸ í†µê³„ ì¹´ë“œ
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric("ì´ ì¡°ì§ ìˆ˜", stats.get("organizations", 0))
                    st.metric("ì´ ë¦¬í¬íŠ¸ ìˆ˜", stats.get("reports", 0))

                with col2:
                    st.metric("ìƒì„±ëœ PDF", stats.get("pdf_generated", 0))
                    st.metric("ë°œì†¡ëœ ì´ë©”ì¼", stats.get("emails_sent", 0))

                with col3:
                    recent_reports = stats.get("recent_reports", 0)
                    st.metric("ìµœê·¼ 30ì¼ ë¦¬í¬íŠ¸", recent_reports)
                    recent_pdfs = stats.get("recent_pdfs", 0)
                    st.metric("ìµœê·¼ 30ì¼ PDF", recent_pdfs)

                with col4:
                    avg_time = stats.get("avg_pdf_generation_time", 0)
                    st.metric("í‰ê·  PDF ìƒì„±ì‹œê°„", f"{avg_time:.2f}ì´ˆ")
                    total_size = stats.get("total_pdf_size_mb", 0)
                    st.metric("ì´ PDF í¬ê¸°", f"{total_size:.1f}MB")

                # ì„±ëŠ¥ ë¶„ì„
                st.markdown("#### âš¡ ì„±ëŠ¥ ë¶„ì„")
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("**PDF ìƒì„± ì„±ëŠ¥**")
                    pdf_perf = perf.get("pdf_performance", {})
                    st.text(f"â€¢ ì´ ìƒì„± ìˆ˜: {pdf_perf.get('total_generated', 0)}")
                    st.text(f"â€¢ í‰ê·  ì‹œê°„: {pdf_perf.get('avg_time', 0):.2f}ì´ˆ")
                    st.text(f"â€¢ ìµœì†Œ ì‹œê°„: {pdf_perf.get('min_time', 0):.2f}ì´ˆ")
                    st.text(f"â€¢ ìµœëŒ€ ì‹œê°„: {pdf_perf.get('max_time', 0):.2f}ì´ˆ")
                    st.text(f"â€¢ ì´ í¬ê¸°: {pdf_perf.get('total_size_mb', 0):.1f}MB")

                with col2:
                    st.markdown("**ì´ë©”ì¼ ë°œì†¡ ì„±ëŠ¥**")
                    email_perf = perf.get("email_performance", {})
                    st.text(f"â€¢ ì´ ë°œì†¡ ìˆ˜: {email_perf.get('total_sent', 0)}")
                    st.text(f"â€¢ ì„±ê³µë¥ : {email_perf.get('success_rate', 0):.1f}%")
                    st.text(f"â€¢ í‰ê·  ìˆ˜ì‹ ì: {email_perf.get('avg_recipients', 0):.1f}ëª…")

                    st.markdown("**ë°ì´í„°ë² ì´ìŠ¤**")
                    db_size = perf.get("database_size", 0)
                    st.text(f"â€¢ í¬ê¸°: {db_size:.2f}MB")

            except Exception as e:
                st.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

            st.markdown("---")

            # ë°ì´í„° ê´€ë¦¬ ì„¹ì…˜
            st.markdown("#### ğŸ—‚ï¸ ë°ì´í„° ê´€ë¦¬")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**ë°ì´í„° ë‚´ë³´ë‚´ê¸°**")

                # ì¡°ì§ ì„ íƒ (ì „ì²´ ë˜ëŠ” íŠ¹ì • ì¡°ì§)
                export_options = ["ì „ì²´ ë°ì´í„°"]
                organizations = session.query(Organization).all()
                for org in organizations:
                    export_options.append(f"{org.name} (ID: {org.id})")

                selected_export = st.selectbox("ë‚´ë³´ë‚¼ ë°ì´í„° ì„ íƒ", export_options)

                if st.button("ğŸ“Š Excelë¡œ ë‚´ë³´ë‚´ê¸°"):
                    try:
                        from admin_utils import export_data_to_excel

                        # ì„ íƒëœ ì¡°ì§ ID ì¶”ì¶œ
                        org_id = None
                        if selected_export != "ì „ì²´ ë°ì´í„°":
                            org_id = int(selected_export.split("ID: ")[1].split(")")[0])

                        with st.spinner("Excel íŒŒì¼ ìƒì„± ì¤‘..."):
                            filename = export_data_to_excel(org_id)

                        # ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ
                        with open(filename, "rb") as file:
                            st.download_button(
                                label="ğŸ“¥ Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                                data=file.read(),
                                file_name=filename,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )

                        st.success(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")

                    except Exception as e:
                        st.error(f"Excel ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")

                # ë°ì´í„° ì •ë¦¬
                st.markdown("**ë°ì´í„° ì •ë¦¬**")
                cleanup_days = st.number_input("ë©°ì¹  ì´ì „ ë°ì´í„° ì‚­ì œ", min_value=30, max_value=365, value=90)

                if st.button("ğŸ§¹ ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬", type="secondary"):
                    try:
                        from admin_utils import clean_old_data

                        with st.spinner("ë°ì´í„° ì •ë¦¬ ì¤‘..."):
                            counts = clean_old_data(cleanup_days)

                        st.success(f"""
                        ë°ì´í„° ì •ë¦¬ ì™„ë£Œ:
                        - ë¦¬í¬íŠ¸: {counts['reports']}ê°œ ì‚­ì œ
                        - PDF: {counts['pdfs']}ê°œ ì‚­ì œ
                        - ì´ë©”ì¼: {counts['emails']}ê°œ ì‚­ì œ
                        """)

                    except Exception as e:
                        st.error(f"ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")

            with col2:
                st.markdown("**ë°±ì—… ë° ë³µì›**")

                # ë°±ì—… ìƒì„±
                if st.button("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…"):
                    try:
                        from admin_utils import backup_database

                        with st.spinner("ë°±ì—… ìƒì„± ì¤‘..."):
                            backup_path = backup_database()

                        # ë°±ì—… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì œê³µ
                        with open(backup_path, "rb") as file:
                            st.download_button(
                                label="ğŸ“¥ ë°±ì—… íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                                data=file.read(),
                                file_name=backup_path,
                                mime="application/octet-stream"
                            )

                        st.success(f"ë°±ì—…ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {backup_path}")

                    except Exception as e:
                        st.error(f"ë°±ì—… ì‹¤íŒ¨: {e}")

                # ë³µì›
                st.markdown("**ë³µì›**")
                uploaded_backup = st.file_uploader("ë°±ì—… íŒŒì¼ ì„ íƒ", type=['db'])

                if uploaded_backup and st.button("ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ë³µì›", type="secondary"):
                    try:
                        from admin_utils import restore_database
                        import tempfile

                        # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ì €ì¥
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.db') as tmp_file:
                            tmp_file.write(uploaded_backup.getvalue())
                            tmp_path = tmp_file.name

                        with st.spinner("ë°ì´í„°ë² ì´ìŠ¤ ë³µì› ì¤‘..."):
                            success = restore_database(tmp_path)

                        if success:
                            st.success("ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.warning("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ë³€ê²½ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”.")
                        else:
                            st.error("ë°ì´í„°ë² ì´ìŠ¤ ë³µì›ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                        import os
                        os.unlink(tmp_path)

                    except Exception as e:
                        st.error(f"ë³µì› ì‹¤íŒ¨: {e}")

            st.markdown("---")

            # ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´
            st.markdown("#### ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´")
            try:
                import os
                db_url = os.getenv('DATABASE_URL', 'sqlite:///./report_system.db')
                st.text(f"ì—°ê²° URL: {db_url}")

                # í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜
                tables_info = {
                    "Organizations": session.query(Organization).count(),
                    "Reports": session.query(Report).count(),
                    "PDF Generations": session.query(PDFGeneration).count(),
                    "Email Logs": session.query(EmailLog).count(),
                }

                col1, col2 = st.columns(2)
                items = list(tables_info.items())

                with col1:
                    for i in range(0, len(items), 2):
                        table, count = items[i]
                        st.text(f"â€¢ {table}: {count:,}ê°œ")

                with col2:
                    for i in range(1, len(items), 2):
                        if i < len(items):
                            table, count = items[i]
                            st.text(f"â€¢ {table}: {count:,}ê°œ")

            except Exception as e:
                st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        session.close()

    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
        st.info("database_models.py íŒŒì¼ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")


def render_admin_branding_page():
    """ë¸Œëœë”© ì„¤ì • ê´€ë¦¬ í˜ì´ì§€"""
    st.markdown("##### ğŸ¨ ë¸Œëœë”© ì„¤ì • ê´€ë¦¬")

    try:
        from database_models import get_session, Organization, BrandingConfig
        import pandas as pd

        session = get_session()

        # ì¡°ì§ ì„ íƒ
        organizations = session.query(Organization).all()
        if not organizations:
            st.warning("ë¸Œëœë”©ì„ ì„¤ì •í•  ì¡°ì§ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì—ì„œ ì¡°ì§ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return

        org_names = {org.name: org.id for org in organizations}
        selected_org_name = st.selectbox("ì¡°ì§ ì„ íƒ", list(org_names.keys()))
        selected_org_id = org_names[selected_org_name]

        # í˜„ì¬ ë¸Œëœë”© ì„¤ì • ì¡°íšŒ
        current_branding = session.query(BrandingConfig).filter(
            BrandingConfig.organization_id == selected_org_id,
            BrandingConfig.is_active == True
        ).first()

        st.markdown("---")

        # ë¸Œëœë”© ì„¤ì • í¼
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ìƒ‰ìƒ ì„¤ì •")

            primary_color = st.color_picker(
                "ì£¼ ìƒ‰ìƒ (Primary)",
                value=current_branding.primary_color if current_branding else "#0f4fa8",
                help="ë¦¬í¬íŠ¸ì˜ ë©”ì¸ ìƒ‰ìƒ"
            )

            secondary_color = st.color_picker(
                "ë³´ì¡° ìƒ‰ìƒ (Secondary)",
                value=current_branding.secondary_color if current_branding else "#10b981",
                help="ì°¨íŠ¸ ë° ë³´ì¡° ìš”ì†Œ ìƒ‰ìƒ"
            )

            accent_color = st.color_picker(
                "ê°•ì¡° ìƒ‰ìƒ (Accent)",
                value=current_branding.accent_color if current_branding else "#f97316",
                help="ë²„íŠ¼ ë° ê°•ì¡° ìš”ì†Œ ìƒ‰ìƒ"
            )

        with col2:
            st.subheader("í°íŠ¸ ë° ê¸°íƒ€ ì„¤ì •")

            font_family = st.selectbox(
                "í°íŠ¸",
                options=["Inter", "Noto Sans KR", "Pretendard", "Arial", "Helvetica"],
                index=0 if not current_branding else ["Inter", "Noto Sans KR", "Pretendard", "Arial", "Helvetica"].index(current_branding.font_family) if current_branding.font_family in ["Inter", "Noto Sans KR", "Pretendard", "Arial", "Helvetica"] else 0
            )

            config_name = st.text_input(
                "ì„¤ì • ì´ë¦„",
                value=current_branding.config_name if current_branding else "default"
            )

        # ìƒ‰ìƒ ë¯¸ë¦¬ë³´ê¸°
        st.subheader("ìƒ‰ìƒ ë¯¸ë¦¬ë³´ê¸°")
        st.markdown(f"""
        <div style="display: flex; gap: 1rem; margin: 1rem 0;">
            <div style="width: 60px; height: 60px; background: {primary_color}; border-radius: 8px; display: flex; align-items: center; justify-content: center; color: white; font-weight: bold;">Primary</div>
            <div style="width: 60px; height: 60px; background: {secondary_color}; border-radius: 8px; display: flex; align-items: center; justify-content: center; color: white; font-weight: bold;">Secondary</div>
            <div style="width: 60px; height: 60px; background: {accent_color}; border-radius: 8px; display: flex; align-items: center; justify-content: center; color: white; font-weight: bold;">Accent</div>
        </div>
        """, unsafe_allow_html=True)

        # ì €ì¥ ë²„íŠ¼
        if st.button("ë¸Œëœë”© ì„¤ì • ì €ì¥", type="primary"):
            try:
                # ê¸°ì¡´ í™œì„± ì„¤ì • ë¹„í™œì„±í™”
                session.query(BrandingConfig).filter(
                    BrandingConfig.organization_id == selected_org_id,
                    BrandingConfig.is_active == True
                ).update({BrandingConfig.is_active: False})

                # ìƒˆ ë¸Œëœë”© ì„¤ì • ìƒì„±
                new_branding = BrandingConfig(
                    organization_id=selected_org_id,
                    config_name=config_name,
                    primary_color=primary_color,
                    secondary_color=secondary_color,
                    accent_color=accent_color,
                    font_family=font_family,
                    is_active=True
                )

                session.add(new_branding)
                session.commit()

                st.success(f"'{selected_org_name}' ì¡°ì§ì˜ ë¸Œëœë”© ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()

            except Exception as e:
                session.rollback()
                st.error(f"ë¸Œëœë”© ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")

        # ë¸Œëœë”© ì´ë ¥
        st.markdown("---")
        st.subheader("ë¸Œëœë”© ì„¤ì • ì´ë ¥")

        branding_history = session.query(BrandingConfig).filter(
            BrandingConfig.organization_id == selected_org_id
        ).order_by(BrandingConfig.created_at.desc()).all()

        if branding_history:
            history_data = []
            for branding in branding_history:
                history_data.append({
                    "ì„¤ì •ëª…": branding.config_name,
                    "ì£¼ ìƒ‰ìƒ": branding.primary_color,
                    "ë³´ì¡° ìƒ‰ìƒ": branding.secondary_color,
                    "ê°•ì¡° ìƒ‰ìƒ": branding.accent_color,
                    "í°íŠ¸": branding.font_family,
                    "í™œì„±": "âœ…" if branding.is_active else "âŒ",
                    "ìƒì„±ì¼": branding.created_at.strftime("%Y-%m-%d %H:%M") if branding.created_at else "-"
                })

            df_history = pd.DataFrame(history_data)
            st.dataframe(df_history, use_container_width=True)
        else:
            st.info("ë¸Œëœë”© ì„¤ì • ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")

        session.close()

    except Exception as e:
        st.error(f"ë¸Œëœë”© ì„¤ì • í˜ì´ì§€ ì˜¤ë¥˜: {e}")


def render_admin_benchmark_page():
    """ë²¤ì¹˜ë§ˆí¬ ì„¤ì • ê´€ë¦¬ í˜ì´ì§€"""
    st.markdown("##### ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ ì„¤ì •")

    # ê¸°ë³¸ ë²¤ì¹˜ë§ˆí¬ ê°’ë“¤ (ì˜ì—­ë³„)
    default_benchmarks = {
        "ëª©ì ê²½ì˜": 3.2,
        "êµ¬ì„±ì›ì¸ì‹": 3.1,
        "ì§€ì›ì²´ê³„": 3.0,
        "ë„ì „ì¶”ì§„": 3.3,
        "ì‹¤í–‰ë ¥": 3.4,
        "ì†Œí†µí˜‘ë ¥": 3.2,
        "ì„±ê³¼ì°½ì¶œ": 3.5,
        "êµ¬ì„±ì›ë§Œì¡±": 3.1,
        "ê²½ìŸë ¥í™•ë³´": 3.3
    }

    # í˜„ì¬ ì„¤ì •ëœ ë²¤ì¹˜ë§ˆí¬ ë¶ˆëŸ¬ì˜¤ê¸° (ì„¸ì…˜ì—ì„œ)
    if "benchmark_settings" not in st.session_state:
        st.session_state["benchmark_settings"] = default_benchmarks.copy()

    st.info("ğŸ“‹ **ì‚¬ìš©ë²•**: ê° ì˜ì—­ë³„ ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”. ì´ ê°’ë“¤ì€ ë¦¬í¬íŠ¸ì˜ ë¹„êµ ê¸°ì¤€ì„ ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

    # ì˜ì—­ë³„ ë²¤ì¹˜ë§ˆí¬ ì„¤ì •
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("**Input ì˜ì—­**")
        st.session_state["benchmark_settings"]["ëª©ì ê²½ì˜"] = st.number_input(
            "ëª©ì ê²½ì˜",
            min_value=1.0,
            max_value=5.0,
            value=st.session_state["benchmark_settings"]["ëª©ì ê²½ì˜"],
            step=0.1,
            key="bench_ëª©ì ê²½ì˜"
        )
        st.session_state["benchmark_settings"]["êµ¬ì„±ì›ì¸ì‹"] = st.number_input(
            "êµ¬ì„±ì›ì¸ì‹",
            min_value=1.0,
            max_value=5.0,
            value=st.session_state["benchmark_settings"]["êµ¬ì„±ì›ì¸ì‹"],
            step=0.1,
            key="bench_êµ¬ì„±ì›ì¸ì‹"
        )
        st.session_state["benchmark_settings"]["ì§€ì›ì²´ê³„"] = st.number_input(
            "ì§€ì›ì²´ê³„",
            min_value=1.0,
            max_value=5.0,
            value=st.session_state["benchmark_settings"]["ì§€ì›ì²´ê³„"],
            step=0.1,
            key="bench_ì§€ì›ì²´ê³„"
        )

    with col2:
        st.markdown("**Process ì˜ì—­**")
        st.session_state["benchmark_settings"]["ë„ì „ì¶”ì§„"] = st.number_input(
            "ë„ì „ì¶”ì§„",
            min_value=1.0,
            max_value=5.0,
            value=st.session_state["benchmark_settings"]["ë„ì „ì¶”ì§„"],
            step=0.1,
            key="bench_ë„ì „ì¶”ì§„"
        )
        st.session_state["benchmark_settings"]["ì‹¤í–‰ë ¥"] = st.number_input(
            "ì‹¤í–‰ë ¥",
            min_value=1.0,
            max_value=5.0,
            value=st.session_state["benchmark_settings"]["ì‹¤í–‰ë ¥"],
            step=0.1,
            key="bench_ì‹¤í–‰ë ¥"
        )
        st.session_state["benchmark_settings"]["ì†Œí†µí˜‘ë ¥"] = st.number_input(
            "ì†Œí†µí˜‘ë ¥",
            min_value=1.0,
            max_value=5.0,
            value=st.session_state["benchmark_settings"]["ì†Œí†µí˜‘ë ¥"],
            step=0.1,
            key="bench_ì†Œí†µí˜‘ë ¥"
        )

    with col3:
        st.markdown("**Output ì˜ì—­**")
        st.session_state["benchmark_settings"]["ì„±ê³¼ì°½ì¶œ"] = st.number_input(
            "ì„±ê³¼ì°½ì¶œ",
            min_value=1.0,
            max_value=5.0,
            value=st.session_state["benchmark_settings"]["ì„±ê³¼ì°½ì¶œ"],
            step=0.1,
            key="bench_ì„±ê³¼ì°½ì¶œ"
        )
        st.session_state["benchmark_settings"]["êµ¬ì„±ì›ë§Œì¡±"] = st.number_input(
            "êµ¬ì„±ì›ë§Œì¡±",
            min_value=1.0,
            max_value=5.0,
            value=st.session_state["benchmark_settings"]["êµ¬ì„±ì›ë§Œì¡±"],
            step=0.1,
            key="bench_êµ¬ì„±ì›ë§Œì¡±"
        )
        st.session_state["benchmark_settings"]["ê²½ìŸë ¥í™•ë³´"] = st.number_input(
            "ê²½ìŸë ¥í™•ë³´",
            min_value=1.0,
            max_value=5.0,
            value=st.session_state["benchmark_settings"]["ê²½ìŸë ¥í™•ë³´"],
            step=0.1,
            key="bench_ê²½ìŸë ¥í™•ë³´"
        )

    st.markdown("---")

    # ì•¡ì…˜ ë²„íŠ¼ë“¤
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        if st.button("ğŸ’¾ ì„¤ì • ì €ì¥", type="primary"):
            st.success("âœ… ë²¤ì¹˜ë§ˆí¬ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()

    with col2:
        if st.button("ğŸ”„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”"):
            st.session_state["benchmark_settings"] = default_benchmarks.copy()
            st.success("âœ… ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()

    with col3:
        if st.button("ğŸ“Š ë¯¸ë¦¬ë³´ê¸°"):
            st.session_state["show_benchmark_preview"] = True

    with col4:
        if st.button("ğŸ“¥ CSV ë‚´ë³´ë‚´ê¸°"):
            import pandas as pd
            df = pd.DataFrame(list(st.session_state["benchmark_settings"].items()),
                            columns=['ì˜ì—­', 'ë²¤ì¹˜ë§ˆí¬ì ìˆ˜'])
            csv = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="benchmark_settings.csv",
                mime="text/csv"
            )

    # ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
    if st.session_state.get("show_benchmark_preview", False):
        st.markdown("---")
        st.markdown("**ğŸ“Š í˜„ì¬ ë²¤ì¹˜ë§ˆí¬ ì„¤ì • ë¯¸ë¦¬ë³´ê¸°**")

        import pandas as pd
        preview_df = pd.DataFrame(list(st.session_state["benchmark_settings"].items()),
                                columns=['ì˜ì—­', 'ë²¤ì¹˜ë§ˆí¬ì ìˆ˜'])

        # ì˜ì—­ë³„ ê·¸ë£¹í•‘
        input_areas = ["ëª©ì ê²½ì˜", "êµ¬ì„±ì›ì¸ì‹", "ì§€ì›ì²´ê³„"]
        process_areas = ["ë„ì „ì¶”ì§„", "ì‹¤í–‰ë ¥", "ì†Œí†µí˜‘ë ¥"]
        output_areas = ["ì„±ê³¼ì°½ì¶œ", "êµ¬ì„±ì›ë§Œì¡±", "ê²½ìŸë ¥í™•ë³´"]

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**Input ì˜ì—­**")
            input_df = preview_df[preview_df['ì˜ì—­'].isin(input_areas)]
            st.dataframe(input_df, hide_index=True)
            st.metric("í‰ê· ", f"{input_df['ë²¤ì¹˜ë§ˆí¬ì ìˆ˜'].mean():.2f}")

        with col2:
            st.markdown("**Process ì˜ì—­**")
            process_df = preview_df[preview_df['ì˜ì—­'].isin(process_areas)]
            st.dataframe(process_df, hide_index=True)
            st.metric("í‰ê· ", f"{process_df['ë²¤ì¹˜ë§ˆí¬ì ìˆ˜'].mean():.2f}")

        with col3:
            st.markdown("**Output ì˜ì—­**")
            output_df = preview_df[preview_df['ì˜ì—­'].isin(output_areas)]
            st.dataframe(output_df, hide_index=True)
            st.metric("í‰ê· ", f"{output_df['ë²¤ì¹˜ë§ˆí¬ì ìˆ˜'].mean():.2f}")


def render_admin_email_page():
    """ì´ë©”ì¼ ì´ë ¥ ê´€ë¦¬ í˜ì´ì§€"""
    st.markdown("##### ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ì´ë ¥")

    try:
        from database_models import get_session, EmailLog, Report
        import pandas as pd
        import json

        session = get_session()

        # í†µê³„ ì¹´ë“œ
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            total_emails = session.query(EmailLog).count()
            st.metric("ì´ ë°œì†¡ ì´ë ¥", total_emails)

        with col2:
            sent_emails = session.query(EmailLog).filter(EmailLog.status == 'sent').count()
            st.metric("ì„±ê³µì  ë°œì†¡", sent_emails)

        with col3:
            failed_emails = session.query(EmailLog).filter(EmailLog.status == 'failed').count()
            st.metric("ë°œì†¡ ì‹¤íŒ¨", failed_emails)

        with col4:
            success_rate = (sent_emails / total_emails * 100) if total_emails > 0 else 0
            st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")

        # í•„í„° ì˜µì…˜
        st.subheader("í•„í„° ë° ê²€ìƒ‰")
        col1, col2, col3 = st.columns(3)

        with col1:
            status_filter = st.selectbox("ìƒíƒœ", ["ì „ì²´", "sending", "sent", "failed"])

        with col2:
            date_range = st.date_input("ë‚ ì§œ ë²”ìœ„", value=[], help="ë‚ ì§œë¥¼ ì„ íƒí•˜ì—¬ í•„í„°ë§")

        with col3:
            search_email = st.text_input("ì´ë©”ì¼ ê²€ìƒ‰", placeholder="ìˆ˜ì‹ ì ì´ë©”ì¼ ê²€ìƒ‰")

        # ì´ë©”ì¼ ë¡œê·¸ ì¡°íšŒ
        query = session.query(EmailLog).order_by(EmailLog.created_at.desc())

        # í•„í„° ì ìš©
        if status_filter != "ì „ì²´":
            query = query.filter(EmailLog.status == status_filter)

        if search_email:
            query = query.filter(EmailLog.recipient_emails.contains(search_email))

        email_logs = query.limit(100).all()

        if email_logs:
            st.subheader("ì´ë©”ì¼ ë°œì†¡ ì´ë ¥")

            email_data = []
            for email_log in email_logs:
                # JSON í˜•íƒœì˜ ìˆ˜ì‹ ì ì´ë©”ì¼ì„ íŒŒì‹±
                try:
                    recipients = json.loads(email_log.recipient_emails) if email_log.recipient_emails else []
                    recipients_str = ", ".join(recipients) if isinstance(recipients, list) else str(recipients)
                except:
                    recipients_str = email_log.recipient_emails or "-"

                email_data.append({
                    "ID": email_log.id,
                    "ì œëª©": email_log.subject or "-",
                    "ìˆ˜ì‹ ì": recipients_str[:50] + "..." if len(recipients_str) > 50 else recipients_str,
                    "ì²¨ë¶€íŒŒì¼": email_log.attachment_filename or "-",
                    "ì²¨ë¶€í¬ê¸°(MB)": round(email_log.attachment_size / 1024 / 1024, 2) if email_log.attachment_size else "-",
                    "ìƒíƒœ": email_log.status,
                    "ì„±ê³µ ìˆ˜": email_log.sent_count or 0,
                    "ì‹¤íŒ¨ ìˆ˜": email_log.failed_count or 0,
                    "ë°œì†¡ì¼": email_log.sent_at.strftime("%Y-%m-%d %H:%M") if email_log.sent_at else "-",
                    "ìƒì„±ì¼": email_log.created_at.strftime("%Y-%m-%d %H:%M") if email_log.created_at else "-"
                })

            df_emails = pd.DataFrame(email_data)
            st.dataframe(df_emails, use_container_width=True)

            # ìƒì„¸ ì •ë³´ ë³´ê¸°
            if st.checkbox("ìƒì„¸ ì •ë³´ í‘œì‹œ"):
                selected_email_id = st.selectbox("ì´ë©”ì¼ ì„ íƒ", [log.id for log in email_logs])
                selected_email = next((log for log in email_logs if log.id == selected_email_id), None)

                if selected_email:
                    st.subheader(f"ì´ë©”ì¼ ìƒì„¸ ì •ë³´ (ID: {selected_email_id})")

                    col1, col2 = st.columns(2)

                    with col1:
                        st.text(f"ì œëª©: {selected_email.subject or '-'}")
                        st.text(f"ìƒíƒœ: {selected_email.status}")
                        st.text(f"ì„±ê³µ/ì‹¤íŒ¨: {selected_email.sent_count}/{selected_email.failed_count}")
                        st.text(f"ì²¨ë¶€íŒŒì¼: {selected_email.attachment_filename or '-'}")

                    with col2:
                        st.text(f"ë°œì†¡ì¼: {selected_email.sent_at or '-'}")
                        st.text(f"ìƒì„±ì¼: {selected_email.created_at or '-'}")

                        if selected_email.error_message:
                            st.text_area("ì˜¤ë¥˜ ë©”ì‹œì§€", selected_email.error_message, height=100)

                    # ìˆ˜ì‹ ì ëª©ë¡
                    try:
                        recipients = json.loads(selected_email.recipient_emails) if selected_email.recipient_emails else []
                        if recipients:
                            st.subheader("ìˆ˜ì‹ ì ëª©ë¡")
                            for i, recipient in enumerate(recipients, 1):
                                st.text(f"{i}. {recipient}")
                    except:
                        st.text(f"ìˆ˜ì‹ ì: {selected_email.recipient_emails or '-'}")

            # í†µê³„ ì°¨íŠ¸
            if email_logs:
                st.subheader("ë°œì†¡ í†µê³„")

                # ì¼ë³„ ë°œì†¡ í†µê³„
                daily_stats = {}
                for log in email_logs:
                    if log.created_at:
                        date_str = log.created_at.strftime("%Y-%m-%d")
                        if date_str not in daily_stats:
                            daily_stats[date_str] = {"sent": 0, "failed": 0}

                        if log.status == "sent":
                            daily_stats[date_str]["sent"] += 1
                        elif log.status == "failed":
                            daily_stats[date_str]["failed"] += 1

                if daily_stats:
                    chart_data = pd.DataFrame.from_dict(daily_stats, orient='index')
                    st.bar_chart(chart_data)

        else:
            st.info("ì´ë©”ì¼ ë°œì†¡ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")

        session.close()

    except Exception as e:
        st.error(f"ì´ë©”ì¼ ì´ë ¥ í˜ì´ì§€ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main()
